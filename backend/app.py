from flask import Flask, request, jsonify, Response
import numpy as np
import os
import logging
import sys
from datetime import datetime
from feature_extractor import get_feature_extractor, DINOv2FeatureExtractor
from database import db
from config import config
import requests
import json
from flask_cors import CORS
import queue
import threading
import time
from urllib.parse import quote

# åœ¨åº”ç”¨å¯åŠ¨æ—¶ä»æ•°æ®åº“åŠ è½½ç³»ç»Ÿé…ç½®
def load_system_config():
    """ä»æ•°æ®åº“åŠ è½½ç³»ç»Ÿé…ç½®åˆ°å†…å­˜"""
    # åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰loggerï¼Œå› ä¸ºæ­¤æ—¶å…¨å±€loggerå¯èƒ½è¿˜æ²¡æœ‰åˆå§‹åŒ–
    import logging
    func_logger = logging.getLogger(__name__)

    try:
        sys_config = db.get_system_config()
        config.DOWNLOAD_THREADS = sys_config['download_threads']
        config.FEATURE_EXTRACT_THREADS = sys_config['feature_extract_threads']
        config.DISCORD_SIMILARITY_THRESHOLD = sys_config['discord_similarity_threshold']
        config.DISCORD_CHANNEL_ID = sys_config['discord_channel_id']
        config.CNFANS_CHANNEL_ID = sys_config['cnfans_channel_id']
        config.ACBUY_CHANNEL_ID = sys_config['acbuy_channel_id']

        # åŠ è½½å…¨å±€å›å¤å»¶è¿Ÿé…ç½®
        reply_config = db.get_global_reply_config()
        config.GLOBAL_REPLY_MIN_DELAY = reply_config['min_delay']
        config.GLOBAL_REPLY_MAX_DELAY = reply_config['max_delay']

        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¾›æœºå™¨äººä½¿ç”¨ï¼‰
        discord_channel_id = sys_config['discord_channel_id']
        if discord_channel_id:
            os.environ['DISCORD_CHANNEL_ID'] = discord_channel_id

        func_logger.info("ç³»ç»Ÿé…ç½®å·²ä»æ•°æ®åº“åŠ è½½")
        func_logger.info(f"ä¸‹è½½çº¿ç¨‹: {config.DOWNLOAD_THREADS}")
        func_logger.info(f"ç‰¹å¾æå–çº¿ç¨‹: {config.FEATURE_EXTRACT_THREADS}")
        func_logger.info(f"Discordç›¸ä¼¼åº¦é˜ˆå€¼: {config.DISCORD_SIMILARITY_THRESHOLD} ({config.DISCORD_SIMILARITY_THRESHOLD*100:.0f}%)")
        func_logger.info(f"å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®ä¸º: {config.GLOBAL_REPLY_MIN_DELAY}-{config.GLOBAL_REPLY_MAX_DELAY}ç§’")
        func_logger.info(f"Discordé¢‘é“ID: {discord_channel_id or 'æœªè®¾ç½®(ç›‘å¬æ‰€æœ‰é¢‘é“)'}")
    except Exception as e:
        func_logger.warning(f"åŠ è½½ç³»ç»Ÿé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")

# åŠ è½½ç³»ç»Ÿé…ç½®
load_system_config()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

# åˆ›å»ºæ—¥å¿—é˜Ÿåˆ—ç”¨äºå®æ—¶æµå¼ä¼ è¾“
log_queue = queue.Queue()
log_clients = []

# å­˜å‚¨æ‰€æœ‰æ—¥å¿—çš„åˆ—è¡¨ï¼Œç”¨äºAPIæŸ¥è¯¢
all_logs = []

class QueueHandler(logging.Handler):
    """è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œå°†æ—¥å¿—å‘é€åˆ°é˜Ÿåˆ—"""
    def emit(self, record):
        try:
            # è¿‡æ»¤æ‰HTTPè¯·æ±‚æ—¥å¿—å’Œä¸é‡è¦çš„ç³»ç»Ÿæ—¥å¿—
            if self._should_filter_log(record):
                return

            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'level': record.levelname,
                'message': self.format(record),
                'module': record.module,
                'func': record.funcName
            }

            # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨ï¼ˆé™åˆ¶å¤§å°ï¼‰
            all_logs.append(log_entry)
            if len(all_logs) > 200:  # æœ€å¤šä¿å­˜200æ¡æ—¥å¿—
                all_logs.pop(0)

            log_queue.put(log_entry)

            # é€šçŸ¥æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
            for client_queue in log_clients[:]:  # å¤åˆ¶åˆ—è¡¨ä»¥é¿å…ä¿®æ”¹æ—¶çš„é—®é¢˜
                try:
                    client_queue.put(log_entry)
                except:
                    # å¦‚æœå®¢æˆ·ç«¯é˜Ÿåˆ—å·²æ»¡æˆ–æ–­å¼€ï¼Œç§»é™¤å®ƒ
                    if client_queue in log_clients:
                        log_clients.remove(client_queue)
        except Exception as e:
            print(f"æ—¥å¿—é˜Ÿåˆ—é”™è¯¯: {e}")

    def _should_filter_log(self, record):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰è¿™æ¡æ—¥å¿—"""
        # è¿‡æ»¤Werkzeugçš„HTTPè¯·æ±‚æ—¥å¿—
        if record.module == '_internal':
            return True

        # è¿‡æ»¤åŒ…å«HTTPè¯·æ±‚æ¨¡å¼çš„æ—¥å¿—
        message = self.format(record)
        if any(pattern in message for pattern in [
            '"GET ', '"POST ', '"PUT ', '"DELETE ',
            'HTTP/1.1"', 'HTTP/1.0"',
            'werkzeug',
            '127.0.0.1 - -',  # è¿‡æ»¤è®¿é—®æ—¥å¿—
        ]):
            return True

        # è¿‡æ»¤ä¸€äº›ä¸é‡è¦çš„ç³»ç»Ÿæ—¥å¿—
        if record.module in ['urllib3', 'requests', 'aiohttp']:
            return True

        # å¯¹äºæœªçŸ¥æ¨¡å—ï¼Œåªæ˜¾ç¤ºWARNINGçº§åˆ«ä»¥ä¸Šçš„æ—¥å¿—
        if record.levelno < logging.WARNING and record.module not in [
            '__main__',  # ä¸»ç¨‹åºæ—¥å¿—
            'app',       # Flaskåº”ç”¨æ—¥å¿—
            'database',  # æ•°æ®åº“æ“ä½œæ—¥å¿—
            'bot',       # Discordæœºå™¨äººæ—¥å¿—
            'weidian_scraper',  # å¾®åº—çˆ¬è™«æ—¥å¿—
            'feature_extractor', # ç‰¹å¾æå–æ—¥å¿—
            'vector_engine',      # å‘é‡å¼•æ“æ—¥å¿—
            'migrate_data',       # æ•°æ®è¿ç§»æ—¥å¿—
            'test_search_debug'   # æµ‹è¯•è„šæœ¬æ—¥å¿—
        ]:
            return True

        return False

# åˆ›å»ºé˜Ÿåˆ—å¤„ç†å™¨å¹¶æ·»åŠ åˆ°æ ¹æ—¥å¿—å™¨
queue_handler = QueueHandler()
queue_handler.setLevel(logging.INFO)
logging.getLogger().addHandler(queue_handler)

# è®¾ç½®å…¶ä»–æ—¥å¿—å™¨çš„çº§åˆ«
logging.getLogger('werkzeug').setLevel(logging.WARNING)  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('requests').setLevel(logging.WARNING)
logging.getLogger('aiohttp').setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

# æœºå™¨äººç›¸å…³å˜é‡
bot_clients = []
bot_tasks = []

# AIæ¨¡å‹é¢„åŠ è½½å˜é‡
feature_extractor = None

# é¢„åŠ è½½AIæ¨¡å‹å’Œå‘é‡å¼•æ“
def preload_ai_models():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½AIæ¨¡å‹å’Œå‘é‡å¼•æ“ï¼Œé¿å…æ¯æ¬¡æ“ä½œéƒ½é‡æ–°åˆå§‹åŒ–"""
    global feature_extractor
    # åœ¨è¿™ä¸ªé˜¶æ®µloggerå¯èƒ½è¿˜æ²¡åˆå§‹åŒ–ï¼Œä½¿ç”¨print
    try:
        print("ğŸš€ å¼€å§‹é¢„åŠ è½½AIæ¨¡å‹...")
        feature_extractor = DINOv2FeatureExtractor()
        print("âœ… AIæ¨¡å‹é¢„åŠ è½½å®Œæˆ")

        print("ğŸš€ å¼€å§‹é¢„åŠ è½½FAISSå‘é‡å¼•æ“...")
        from vector_engine import get_vector_engine
        vector_engine = get_vector_engine()
        print("âœ… FAISSå‘é‡å¼•æ“é¢„åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ é¢„åŠ è½½å¤±è´¥: {e}")
        feature_extractor = None

preload_ai_models()

app = Flask(__name__)
CORS(app, origins=["http://localhost:3000"], supports_credentials=True)

def extract_features(image_path):
    """ä½¿ç”¨é¢„åŠ è½½çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æå–å›¾åƒç‰¹å¾"""
    global feature_extractor
    try:
        if feature_extractor is None:
            logger.error("AIæ¨¡å‹æœªé¢„åŠ è½½ï¼Œæ— æ³•æå–ç‰¹å¾")
            return None

        features = feature_extractor.extract_feature(image_path)
        # å¦‚æœç‰¹å¾æå–å¤±è´¥ï¼Œè¿”å› Noneï¼ˆä¸Šå±‚å°†å¤„ç†å¹¶è¿”å›é”™è¯¯ï¼‰
        if features is None:
            logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {image_path}")
            return None

        return features

    except Exception as e:
        logger.error(f"ç‰¹å¾æå–å¼‚å¸¸: {e}")
        return None

@app.route('/search_similar', methods=['POST'])
def search_similar():
    """æœç´¢ç›¸ä¼¼å›¾åƒ - ä½¿ç”¨ FAISS HNSW"""
    try:
        if 'image' not in request.files:
            return jsonify({'error': 'No image provided'}), 400

        image_file = request.files['image']
        threshold = float(request.form.get('threshold', 0.6))  # DINOv2éœ€è¦æ›´é«˜çš„é˜ˆå€¼
        limit = int(request.form.get('limit', 5))  # è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª

        # è°ƒè¯•ä¿¡æ¯
        print(f"DEBUG: Received threshold: {threshold}")
        print(f"DEBUG: Form data: {list(request.form.keys())}")

        # ä¿å­˜æŸ¥è¯¢å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
        import uuid
        temp_filename = f"{uuid.uuid4()}.jpg"
        image_path = f"/tmp/{temp_filename}"
        image_file.save(image_path)

        try:
            # æå–ç‰¹å¾ (ä½¿ç”¨ DINOv2 + YOLOv8)
            query_features = extract_features(image_path)

            if query_features is None:
                return jsonify({'error': 'Feature extraction failed'}), 500

            # ä½¿ç”¨ FAISS HNSW å‘é‡æœç´¢
            print(f"DEBUG: Searching with threshold: {threshold}, vector length: {len(query_features)}")
            # ä¸´æ—¶å°†é˜ˆå€¼è®¾ä¸º0ï¼Œç¡®ä¿èƒ½è¿”å›ç»“æœè¿›è¡Œè°ƒè¯•
            debug_threshold = max(0.0, threshold)  # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°
            results = db.search_similar_images(query_features, limit=limit, threshold=debug_threshold)
            print(f"DEBUG: Search results count: {len(results) if results else 0}")
            if results:
                print(f"DEBUG: Best match similarity: {results[0]['similarity']}")
            print(f"DEBUG: Total indexed images: {db.get_total_indexed_images()}")

            response_data = {
                'success': False,
                'message': f'æœªæ‰¾åˆ°ç›¸ä¼¼åº¦è¶…è¿‡{threshold*100:.0f}%çš„å•†å“',
                'searchTime': datetime.now().isoformat(),
                'debugInfo': {
                    'totalIndexedImages': db.get_total_indexed_images(),
                    'threshold': threshold,
                    'searchedVectors': len(results) if results else 0
                }
            }

            if results:
                # å¤„ç†å¤šä¸ªæœç´¢ç»“æœ
                processed_results = []
                for i, result in enumerate(results):
                    # è·å–å®Œæ•´äº§å“ä¿¡æ¯
                    product_info = db._get_product_info_by_id(result['id'])

                    result_data = {
                        'rank': i + 1,
                        'similarity': float(result['similarity']),
                        'imageIndex': result['image_index'],
                        'matchedImage': f"/api/image/{result['id']}/{result['image_index']}",
                        'product': {
                            'id': result['id'],
                            'title': product_info['title'] if product_info else result.get('title', ''),
                            'englishTitle': product_info.get('english_title', ''),
                            'weidianUrl': product_info['product_url'] if product_info else result.get('product_url', ''),
                            'cnfansUrl': product_info.get('cnfans_url', ''),
                            'ruleEnabled': product_info.get('ruleEnabled', True) if product_info else True,
                            'images': [f"/api/image/{result['id']}/{j}" for j in range(10)]  # é¢„ä¼°å›¾ç‰‡æ•°é‡
                        }
                    }
                    processed_results.append(result_data)

                # ä¿å­˜æœ€ä½³åŒ¹é…çš„æœç´¢å†å²
                if processed_results:
                    best_match = processed_results[0]
                    db.add_search_history(
                        query_image_path=image_path,
                        matched_product_id=best_match['product']['id'],
                        matched_image_index=best_match['imageIndex'],
                        similarity=best_match['similarity'],
                        threshold=threshold
                    )

                response_data = {
                    'success': True,
                    'results': processed_results,
                    'totalResults': len(processed_results),
                    'searchTime': datetime.now().isoformat(),
                    'debugInfo': {
                        'totalIndexedImages': db.get_total_indexed_images(),
                        'threshold': threshold,
                        'limit': limit,
                        'searchedVectors': len(results) if results else 0
                    }
                }

            return jsonify(response_data)

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(image_path):
                os.unlink(image_path)

    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/scrape', methods=['POST'])
def scrape_product():
    """æŠ“å–å•†å“å¹¶å»ºç«‹ç´¢å¼•"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        # æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼ï¼šå®Œæ•´URLæˆ–å•†å“ID
        url = data.get('url')
        weidian_id = data.get('weidianId')

        if not url and not weidian_id:
            return jsonify({'error': 'URL or weidianId is required'}), 400

        # å¦‚æœæä¾›äº†weidianIdï¼Œæ„é€ URL
        if weidian_id and not url:
            url = f"https://weidian.com/item.html?itemID={weidian_id}"

        # éªŒè¯URLæ ¼å¼
        if 'weidian.com' not in url:
            return jsonify({'error': 'åªæ”¯æŒå¾®åº—å•†å“é“¾æ¥'}), 400

        logger.info(f"å¼€å§‹æŠ“å–å•†å“: {url}")

        # æ£€æŸ¥å•†å“æ˜¯å¦å·²å­˜åœ¨
        existing = db.get_product_by_url(url)
        if existing:
            return jsonify({'error': 'å•†å“å·²å­˜åœ¨', 'existing': True}), 409

        # ä½¿ç”¨çœŸæ­£çš„çˆ¬è™«
        from weidian_scraper import get_weidian_scraper
        scraper = get_weidian_scraper()

        # æŠ“å–å•†å“ä¿¡æ¯
        product_info = scraper.scrape_product_info(url)

        if not product_info:
            return jsonify({'error': 'å•†å“ä¿¡æ¯æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®'}), 500

        # ç”Ÿæˆacbuyé“¾æ¥
        acbuy_url = ''
        if product_info['weidian_url']:
            # ä»weidian_urlä¸­æå–itemID
            import re
            item_id_match = re.search(r'itemID=(\d+)', product_info['weidian_url'])
            if item_id_match:
                item_id = item_id_match.group(1)
                # æ„å»ºacbuyé“¾æ¥
                encoded_url = product_info['weidian_url'].replace(':', '%3A').replace('/', '%2F').replace('?', '%3F').replace('=', '%3D').replace('&', '%26')
                acbuy_url = f'https://www.acbuy.com/product?url={encoded_url}&id={item_id}&source=WD'

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨å…¨å±€å»¶è¿Ÿé…ç½®ï¼‰
        product_id = db.insert_product({
            'product_url': product_info['weidian_url'],
            'title': product_info['title'],
            'description': product_info['description'],
            'english_title': product_info.get('english_title') or '',
            'cnfans_url': product_info.get('cnfans_url') or '',
            'acbuy_url': acbuy_url,
            'ruleEnabled': True  # é»˜è®¤å¯ç”¨è‡ªåŠ¨å›å¤è§„åˆ™
        })

        # ä¸‹è½½å›¾ç‰‡å¹¶å»ºç«‹å‘é‡ç´¢å¼•
        if product_info['images']:
            logger.info(f"ä¸‹è½½ {len(product_info['images'])} å¼ å›¾ç‰‡å¹¶å»ºç«‹ç´¢å¼•")

            # åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•
            import os
            images_dir = os.path.join(os.path.dirname(__file__), 'data', 'scraped_images', product_info['id'])
            os.makedirs(images_dir, exist_ok=True)

            # ä¸‹è½½å›¾ç‰‡
            saved_image_paths = scraper.download_images(
                product_info['images'],
                images_dir,
                product_info['id']
            )
            # ä¸ºæ¯å¼ å›¾ç‰‡å»ºç«‹å‘é‡ç´¢å¼•
            # æ³¨æ„ï¼šYOLOè£å‰ªå·²é›†æˆåœ¨DINOv2ç‰¹å¾æå–è¿‡ç¨‹ä¸­ï¼Œæ— éœ€é¢å¤–æ­¥éª¤
            # ä½¿ç”¨é¢„åŠ è½½çš„å…¨å±€ç‰¹å¾æå–å™¨
            global feature_extractor
            if feature_extractor is None:
                logger.error("AIæ¨¡å‹æœªé¢„åŠ è½½ï¼Œä½¿ç”¨å•ä¾‹æ¨¡å¼")
                from feature_extractor import get_feature_extractor
                extractor = get_feature_extractor()
            else:
                logger.info("ä½¿ç”¨é¢„åŠ è½½çš„AIæ¨¡å‹")
                extractor = feature_extractor

            # ä¸²è¡Œå»ºç«‹å‘é‡ç´¢å¼• (SQLiteä¸æ”¯æŒå¤šçº¿ç¨‹å†™å…¥)
            # ä½†å…ˆä½¿ç”¨å¤šçº¿ç¨‹è¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åä¸²è¡Œæ’å…¥æ•°æ®åº“
            import concurrent.futures
            from vector_engine import get_vector_engine
            engine = get_vector_engine()

            def extract_features_only(img_path):
                """åªæå–ç‰¹å¾ï¼Œä¸æ’å…¥æ•°æ®åº“"""
                try:
                    features = extractor.extract_feature(img_path)
                    return features
                except Exception as e:
                    logger.error(f"ç‰¹å¾æå–å¤±è´¥ {img_path}: {e}")
                    return None

            # ç¬¬ä¸€æ­¥ï¼šå¤šçº¿ç¨‹ç‰¹å¾æå–
            logger.info("å¼€å§‹å¤šçº¿ç¨‹ç‰¹å¾æå–...")
            features_list = []
            max_workers = min(config.FEATURE_EXTRACT_THREADS, len(saved_image_paths))

            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ç‰¹å¾æå–ä»»åŠ¡
                future_to_image = {
                    executor.submit(extract_features_only, img_path): (i, img_path)
                    for i, img_path in enumerate(saved_image_paths)
                }

                # æ”¶é›†ç‰¹å¾æå–ç»“æœ
                for future in concurrent.futures.as_completed(future_to_image):
                    i, img_path = future_to_image[future]
                    try:
                        features = future.result()
                        features_list.append((i, img_path, features))
                    except Exception as e:
                        logger.error(f"ç‰¹å¾æå–å¼‚å¸¸ {img_path}: {e}")
                        features_list.append((i, img_path, None))

            # æŒ‰ç´¢å¼•æ’åºç»“æœ
            features_list.sort(key=lambda x: x[0])

            # ç¬¬äºŒæ­¥ï¼šä¸²è¡Œæ’å…¥æ•°æ®åº“å’ŒFAISSç´¢å¼•
            logger.info("å¼€å§‹ä¸²è¡Œæ•°æ®åº“æ’å…¥å’Œç´¢å¼•å»ºç«‹...")
            indexed_images = []

            for i, img_path, features in features_list:
                try:
                    if features is None:
                        logger.error(f"è·³è¿‡å›¾ç‰‡ {i}: ç‰¹å¾æå–å¤±è´¥")
                        continue

                    # æ’å…¥æ•°æ®åº“è®°å½•
                    image_db_id = db.insert_image_record(product_id, img_path, i)
                    if not image_db_id:
                        logger.error(f"å›¾ç‰‡ {i} å…ƒæ•°æ®æ’å…¥å¤±è´¥")
                        continue

                    # æ’å…¥FAISSå‘é‡ç´¢å¼•
                    success = engine.add_vector(image_db_id, features)
                    if success:
                        indexed_images.append(f"{i}.jpg")
                        logger.info(f"å›¾ç‰‡ {i} ç´¢å¼•å»ºç«‹æˆåŠŸ")
                    else:
                        logger.error(f"å›¾ç‰‡ {i} ç´¢å¼•å»ºç«‹å¤±è´¥")

                except Exception as e:
                    logger.error(f"å¤„ç†å›¾ç‰‡ {i} æ—¶å‡ºé”™: {e}")
                    continue

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡å¤„ç†å¤±è´¥
            if len(indexed_images) != len(saved_image_paths):
                failed_count = len(saved_image_paths) - len(indexed_images)
                logger.warning(f"æœ‰ {failed_count} å¼ å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")

            # å¦‚æœä¸€å¼ å›¾ç‰‡éƒ½æ²¡æˆåŠŸï¼Œè®¤ä¸ºæ˜¯é”™è¯¯
            if not indexed_images:
                logger.error("æ‰€æœ‰å›¾ç‰‡å¤„ç†éƒ½å¤±è´¥äº†")
                try:
                    db.delete_product_images(product_id)
                except Exception as del_e:
                    logger.error(f"å›æ»šåˆ é™¤å¤±è´¥: {del_e}")
                return jsonify({'error': 'All image processing failed'}), 500

            # å®æ—¶ä¿å­˜FAISSç´¢å¼•
            engine.save()

            logger.info(f"å…±å»ºç«‹ {len(indexed_images)} å¼ å›¾ç‰‡çš„ç´¢å¼•")
        else:
            logger.warning("æœªæ‰¾åˆ°å•†å“å›¾ç‰‡")

        # è¿”å›å®Œæ•´çš„å•†å“ä¿¡æ¯
        result = {
            'id': product_id,
            'weidianId': product_info['id'],  # æ·»åŠ å¾®åº—å•†å“ID
            'product_url': product_info['weidian_url'],
            'title': product_info['title'],
            'englishTitle': product_info['english_title'],
            'weidianUrl': product_info['weidian_url'],
            'cnfansUrl': product_info['cnfans_url'],
            'description': product_info['description'],
            'ruleEnabled': True,  # é»˜è®¤å¯ç”¨è§„åˆ™
            'createdAt': datetime.now().isoformat(),
            'images': product_info['images']  # è¿”å›å›¾ç‰‡URLåˆ—è¡¨
        }

        logger.info(f"å•†å“æŠ“å–å®Œæˆ: {product_info['title']}")
        return jsonify(result)

    except Exception as e:
        logger.error(f"æŠ“å–å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# Discord è´¦å·ç®¡ç† API
@app.route('/api/accounts', methods=['GET'])
def get_accounts():
    """è·å–æ‰€æœ‰ Discord è´¦å·"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, username, token, status, last_active, created_at, updated_at
                FROM discord_accounts
                ORDER BY created_at DESC
            """)
            accounts = []
            for row in cursor.fetchall():
                accounts.append({
                    'id': row[0],
                    'username': row[1],
                    'token': row[2],
                    'status': row[3],
                    'lastActive': row[4],
                    'createdAt': row[5]
                })
        return jsonify({'accounts': accounts})
    except Exception as e:
        logger.error(f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/products', methods=['GET'])
def list_products():
    """åˆ—å‡ºæ‰€æœ‰å·²ä¿å­˜çš„å•†å“åŠå…¶å›¾ç‰‡"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM products ORDER BY created_at DESC")
            rows = cursor.fetchall()
            products = []
            for row in rows:
                prod = dict(row)
                # è·å–å›¾ç‰‡è·¯å¾„
                cursor.execute("SELECT image_path FROM product_images WHERE product_id = ? ORDER BY image_index", (prod['id'],))
                rows_imgs = cursor.fetchall()
                images = []
                for idx, r in enumerate(rows_imgs):
                    local_path = r[0]
                    # æ„å»ºå¯è®¿é—®çš„å›¾ç‰‡URLï¼š/api/image/<product_id>/<index>
                    try:
                        host = request.host_url.rstrip('/')
                        images.append(f"{host}/api/image/{prod['id']}/{idx}")
                    except Exception:
                        images.append('')
                prod['images'] = images
                prod['weidianUrl'] = prod.get('product_url')
                # æå–å¾®åº—ID (itemID)
                try:
                    import re
                    m = re.search(r'itemID=(\d+)', prod.get('product_url') or '')
                    prod['weidianId'] = m.group(1) if m else ''
                except Exception:
                    prod['weidianId'] = ''
                # ä¿ç•™ camelCase å­—æ®µä»¥å…¼å®¹å‰ç«¯
                prod['englishTitle'] = prod.get('english_title') or prod.get('englishTitle') or ''
                prod['cnfansUrl'] = prod.get('cnfans_url') or prod.get('cnfansUrl') or ''
                prod['acbuyUrl'] = prod.get('acbuy_url') or prod.get('acbuyUrl') or ''
                prod['createdAt'] = prod.get('created_at') or prod.get('createdAt')
                # ç§»é™¤å•†å“çº§åˆ«å»¶è¿Ÿï¼Œä½¿ç”¨å…¨å±€å»¶è¿Ÿ
                prod.pop('min_delay', None)
                prod.pop('max_delay', None)
                # æ˜ å°„ruleEnabledåˆ°autoReplyEnabledä»¥å…¼å®¹å‰ç«¯
                prod['autoReplyEnabled'] = prod.get('ruleEnabled', True)
                products.append(prod)
        return jsonify(products)
    except Exception as e:
        logger.error(f"åˆ—å‡ºå•†å“å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/backfill_products', methods=['POST'])
def backfill_products():
    """ä¸ºå·²å­˜åœ¨ä½†ç¼ºå°‘è‹±åæˆ– cnfans é“¾æ¥çš„å•†å“å›å¡«æ•°æ®"""
    try:
        from weidian_scraper import get_weidian_scraper
        scraper = get_weidian_scraper()

        updated = []
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT id, product_url, english_title, cnfans_url FROM products")
            rows = cursor.fetchall()

            for row in rows:
                pid = row['id']
                url = row['product_url']
                need_english = not row['english_title']
                need_cnfans = not row['cnfans_url']
                if not (need_english or need_cnfans):
                    continue

                product_info = scraper.scrape_product_info(url)
                if not product_info:
                    logger.warning(f"å›å¡«å¤±è´¥ï¼Œæ— æ³•æŠ“å–: {url}")
                    continue

                english = product_info.get('english_title') or ''
                cnfans = product_info.get('cnfans_url') or ''

                cursor.execute("""
                    UPDATE products
                    SET english_title = ?, cnfans_url = ?
                    WHERE id = ?
                """, (english, cnfans, pid))
                conn.commit()
                updated.append(pid)

        return jsonify({'updated': updated, 'count': len(updated)})
    except Exception as e:
        logger.error(f"å›å¡«å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/rebuild_index', methods=['POST'])
def rebuild_index():
    """é‡å»ºFAISSç´¢å¼•ï¼Œæ¸…ç†è¢«åˆ é™¤çš„å‘é‡"""
    try:
        from vector_engine import get_vector_engine
        from feature_extractor import get_feature_extractor

        logger.info("å¼€å§‹é‡å»ºFAISSç´¢å¼•...")

        # è·å–æ‰€æœ‰æœ‰æ•ˆçš„å›¾ç‰‡è®°å½•ï¼ˆç¡®ä¿å›¾ç‰‡æ–‡ä»¶å­˜åœ¨ï¼‰
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pi.id, pi.product_id, pi.image_path, pi.image_index
                FROM product_images pi
                JOIN products p ON pi.product_id = p.id
                ORDER BY pi.id
            """)
            all_records = cursor.fetchall()

        # è¿‡æ»¤å‡ºæ–‡ä»¶å­˜åœ¨çš„è®°å½•
        image_records = []
        for record in all_records:
            if os.path.exists(record['image_path']):
                image_records.append(record)
            else:
                logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {record['image_path']}")

        if not image_records:
            return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡è®°å½•'}), 400

        logger.info(f"æ‰¾åˆ° {len(image_records)} å¼ å›¾ç‰‡è®°å½•")

        # é‡æ–°æå–ç‰¹å¾å¹¶é‡å»ºç´¢å¼•
        extractor = get_feature_extractor()
        engine = get_vector_engine()

        # åˆ›å»ºæ–°ç´¢å¼•
        vectors_data = []
        for record in image_records:
            try:
                image_path = record['image_path']
                if not os.path.exists(image_path):
                    logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue

                # æå–ç‰¹å¾
                features = extractor.extract_feature(image_path)
                if features is not None:
                    vectors_data.append((record['id'], features))
                    logger.info(f"é‡æ–°æå–ç‰¹å¾: {record['id']}")
                else:
                    logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {image_path}")

            except Exception as e:
                logger.error(f"å¤„ç†å›¾ç‰‡ {record['id']} å¤±è´¥: {e}")
                continue

        # é‡å»ºç´¢å¼•
        success = engine.rebuild_index(vectors_data)
        if success:
            logger.info(f"ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {len(vectors_data)} ä¸ªå‘é‡")
            return jsonify({
                'success': True,
                'message': f'ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {len(vectors_data)} ä¸ªæœ‰æ•ˆå‘é‡',
                'total_vectors': len(vectors_data)
            })
        else:
            return jsonify({'error': 'ç´¢å¼•é‡å»ºå¤±è´¥'}), 500

    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/rebuild_vectors', methods=['POST'])
def rebuild_vectors():
    """ä¸ºå·²æœ‰å•†å“ï¼ˆæˆ–ç¼ºå¤±å‘é‡çš„å›¾ç‰‡ï¼‰é‡å»ºç‰¹å¾å¹¶æ’å…¥ FAISS"""
    try:
        extractor = get_feature_extractor()
        rebuilt = []
        failed = []

        with db.get_connection() as conn:
            cursor = conn.cursor()
            # æŸ¥æ‰¾æ‰€æœ‰ product_images ä¸­ milvus_id ä¸ºç©ºæˆ– NULL çš„è®°å½•
            cursor.execute("SELECT id, product_id, image_path, image_index FROM product_images WHERE milvus_id IS NULL OR milvus_id = ''")
            rows = cursor.fetchall()

        for row in rows:
            pid = row['product_id']
            img_path = row['image_path']
            idx = row['image_index']
            try:
                features = extractor.extract_feature(img_path)
                if features is None:
                    logger.error(f"é‡å»ºç‰¹å¾å¤±è´¥: {img_path}")
                    failed.append({'product_id': pid, 'image_index': idx})
                    continue

                success = db.insert_image_vector(product_id=pid, image_path=img_path, image_index=idx, vector=features)
                if success:
                    rebuilt.append({'product_id': pid, 'image_index': idx})
                else:
                    failed.append({'product_id': pid, 'image_index': idx})
            except Exception as e:
                logger.error(f"é‡å»ºå‘é‡å‡ºé”™: {e}")
                failed.append({'product_id': pid, 'image_index': idx})

        return jsonify({'rebuilt': rebuilt, 'failed': failed, 'count': len(rebuilt)})
    except Exception as e:
        logger.error(f"é‡å»ºå‘é‡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500



@app.route('/api/image/<int:product_id>/<int:image_index>', methods=['GET'])
def serve_product_image(product_id: int, image_index: int):
    """è¿”å›æŒ‡å®šå•†å“æŒ‡å®šåºå·çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆç”¨äºå‰ç«¯ç¼©ç•¥å›¾/æŸ¥çœ‹ï¼‰"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT image_path FROM product_images WHERE product_id = ? AND image_index = ?", (product_id, image_index))
            row = cursor.fetchone()
            if not row:
                return jsonify({'error': 'Image not found'}), 404
            image_path = row[0]

        # å®‰å…¨æ£€æŸ¥å¹¶è¿”å›æ–‡ä»¶
        from flask import send_file
        if not os.path.exists(image_path):
            return jsonify({'error': 'Image file missing'}), 404
        return send_file(image_path, mimetype='image/jpeg')
    except Exception as e:
        logger.error(f"serve_product_image å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

def verify_discord_token(token):
    """éªŒè¯Discord tokenå¹¶è·å–ç”¨æˆ·ä¿¡æ¯"""
    try:
        headers = {
            'Authorization': f'Bot {token}' if token.startswith('Bot ') else token,
            'User-Agent': 'DiscordBot/1.0'
        }

        # é¦–å…ˆå°è¯•ä½œä¸ºBot tokenéªŒè¯
        response = requests.get('https://discord.com/api/v10/users/@me', headers=headers, timeout=10)

        if response.status_code == 401:
            # å¦‚æœBot tokenå¤±è´¥ï¼Œå°è¯•ä½œä¸ºUser token
            if not token.startswith('Bot '):
                headers['Authorization'] = f'Bot {token}'
                response = requests.get('https://discord.com/api/v10/users/@me', headers=headers, timeout=10)

        if response.status_code == 200:
            user_data = response.json()
            return {
                'valid': True,
                'username': f"{user_data.get('username', 'Unknown')}#{user_data.get('discriminator', '0000')}",
                'user_id': user_data.get('id'),
                'avatar': user_data.get('avatar'),
                'bot': user_data.get('bot', False)
            }
        else:
            return {
                'valid': False,
                'error': f'HTTP {response.status_code}: {response.text}'
            }
    except requests.exceptions.RequestException as e:
        return {
            'valid': False,
            'error': f'ç½‘ç»œé”™è¯¯: {str(e)}'
        }
    except Exception as e:
        return {
            'valid': False,
            'error': f'éªŒè¯å¤±è´¥: {str(e)}'
        }

@app.route('/api/accounts', methods=['POST'])
def add_account():
    """æ·»åŠ æ–°çš„ Discord è´¦å·"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        token = data.get('token')
        username = data.get('username', '')

        if not token:
            return jsonify({'error': 'Token is required'}), 400

        # éªŒè¯tokenå¹¶è·å–çœŸå®ç”¨æˆ·å
        logger.info("æ­£åœ¨éªŒè¯Discord token...")
        token_info = verify_discord_token(token)

        if not token_info['valid']:
            return jsonify({'error': f'TokenéªŒè¯å¤±è´¥: {token_info["error"]} è¯·æ£€æŸ¥tokenæ˜¯å¦æ­£ç¡®'}), 400

        # å¦‚æœæ²¡æœ‰æä¾›ç”¨æˆ·åï¼Œä½¿ç”¨ä»tokenè·å–çš„ç”¨æˆ·å
        if not username:
            username = token_info['username']
            logger.info(f"è‡ªåŠ¨è·å–ç”¨æˆ·å: {username}")

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO discord_accounts (username, token, status)
                VALUES (?, ?, 'offline')
            """, (username, token))
            account_id = cursor.lastrowid

            cursor.execute("SELECT id, username, token, status, last_active FROM discord_accounts WHERE id = ?", (account_id,))
            account = cursor.fetchone()
            conn.commit()

        logger.info(f"è´¦å·æ·»åŠ æˆåŠŸ: {username}")
        return jsonify({
            'id': account[0],
            'username': account[1],
            'token': account[2],
            'status': account[3],
            'lastActive': account[4],
            'verified': True
        })
    except Exception as e:
        logger.error(f"æ·»åŠ è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<int:account_id>', methods=['DELETE'])
def delete_account(account_id):
    """åˆ é™¤ Discord è´¦å·"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("DELETE FROM discord_accounts WHERE id = ?", (account_id,))
            conn.commit()

        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"åˆ é™¤è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<int:account_id>/status', methods=['PUT'])
def update_account_status(account_id):
    """æ›´æ–°è´¦å·çŠ¶æ€"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        status = data.get('status')

        if status not in ['online', 'offline']:
            return jsonify({'error': 'Invalid status'}), 400

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE discord_accounts
                SET status = ?, updated_at = datetime('now')
                WHERE id = ?
            """, (status, account_id))
            conn.commit()

        return jsonify({'success': True, 'status': status})
    except Exception as e:
        logger.error(f"æ›´æ–°è´¦å·çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/current', methods=['GET'])
def get_current_account():
    """è·å–å½“å‰å¯ç”¨çš„ Discord è´¦å· (çŠ¶æ€ä¸ºonlineçš„ç¬¬ä¸€ä¸ª)"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, username, token, status, last_active
                FROM discord_accounts
                WHERE status = 'online'
                ORDER BY last_active DESC NULLS LAST, created_at ASC
                LIMIT 1
            """)
            account = cursor.fetchone()

            if account:
                return jsonify({
                    'id': account[0],
                    'username': account[1],
                    'token': account[2],
                    'status': account[3],
                    'lastActive': account[4]
                })
            else:
                return jsonify({'error': 'No active account found'}), 404
    except Exception as e:
        logger.error(f"è·å–å½“å‰è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/verify-all', methods=['POST'])
def verify_all_accounts():
    """é‡æ–°éªŒè¯æ‰€æœ‰è´¦å·"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            # è·å–æ‰€æœ‰è´¦å·
            cursor.execute("SELECT id, username, token FROM discord_accounts")
            accounts = cursor.fetchall()

            verified_count = 0
            invalid_count = 0
            results = []

            for account in accounts:
                account_id, username, token = account
                logger.info(f"æ­£åœ¨éªŒè¯è´¦å·: {username}")

                token_info = verify_discord_token(token)

                if token_info['valid']:
                    # æ›´æ–°ç”¨æˆ·åï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
                    new_username = token_info['username']
                    if new_username != username:
                        cursor.execute("""
                            UPDATE discord_accounts
                            SET username = ?
                            WHERE id = ?
                        """, (new_username, account_id))
                        logger.info(f"ç”¨æˆ·åå·²æ›´æ–°: {username} -> {new_username}")

                    verified_count += 1
                    results.append({
                        'id': account_id,
                        'username': new_username,
                        'valid': True
                    })
                else:
                    invalid_count += 1
                    results.append({
                        'id': account_id,
                        'username': username,
                        'valid': False,
                        'error': token_info['error']
                    })

            conn.commit()

        return jsonify({
            'success': True,
            'total': len(accounts),
            'verified': verified_count,
            'invalid': invalid_count,
            'results': results
        })
    except Exception as e:
        logger.error(f"æ‰¹é‡éªŒè¯è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/bulk-status', methods=['POST'])
def bulk_update_status():
    """æ‰¹é‡å¼€å¯æˆ–åœæ­¢æ‰€æœ‰è´¦å·"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        new_status = data.get('status')
        if new_status not in ['online', 'offline']:
            return jsonify({'error': 'Invalid status. Must be "online" or "offline"'}), 400

        with db.get_connection() as conn:
            cursor = conn.cursor()

            if new_status == 'online':
                cursor.execute("""
                    UPDATE discord_accounts
                    SET status = 'online', last_active = ?
                """, (datetime.now(),))
            else:
                cursor.execute("""
                    UPDATE discord_accounts
                    SET status = 'offline'
                """)

            updated_count = cursor.rowcount
            conn.commit()

        logger.info(f"æ‰¹é‡æ›´æ–°è´¦å·çŠ¶æ€: {updated_count} ä¸ªè´¦å·è®¾ç½®ä¸º {new_status}")

        return jsonify({
            'success': True,
            'updated_count': updated_count,
            'new_status': new_status
        })
    except Exception as e:
        logger.error(f"æ‰¹é‡æ›´æ–°è´¦å·çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/rotation', methods=['GET'])
def get_rotation_config():
    """è·å–è´¦å·è½®æ¢é…ç½®"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT enabled, rotation_interval, current_account_id
                FROM account_rotation_config
                LIMIT 1
            """)
            row = cursor.fetchone()

        if row:
            return jsonify({
                'enabled': row[0],
                'rotationInterval': row[1],
                'currentAccountId': row[2]
            })
        return jsonify({'enabled': False, 'rotationInterval': 10})
    except Exception as e:
        logger.error(f"è·å–è½®æ¢é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/rotation', methods=['POST'])
def update_rotation_config():
    """æ›´æ–°è´¦å·è½®æ¢é…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        enabled = data.get('enabled', False)
        rotation_interval = data.get('rotationInterval', 10)

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE account_rotation_config
                SET enabled = ?, rotation_interval = ?, updated_at = datetime('now')
                WHERE id = 1
            """, (enabled, rotation_interval))
            conn.commit()

        return jsonify({'success': True, 'enabled': enabled, 'rotationInterval': rotation_interval})
    except Exception as e:
        logger.error(f"æ›´æ–°è½®æ¢é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/get_indexed_ids', methods=['GET'])
def get_indexed_ids():
    """è·å–å·²å»ºç«‹ç´¢å¼•çš„å•†å“URLåˆ—è¡¨"""
    try:
        indexed_urls = db.get_indexed_product_urls()
        return jsonify({'indexedIds': indexed_urls})
    except Exception as e:
        logger.error(f"è·å–å·²ç´¢å¼•IDå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/products/<int:product_id>', methods=['DELETE'])
def delete_product(product_id):
    """åˆ é™¤å•†å“åŠå…¶æ‰€æœ‰ç›¸å…³æ•°æ®"""
    try:
        # åˆ é™¤å•†å“åŠå…¶å‘é‡æ•°æ®
        if db.delete_product_images(product_id):
            return jsonify({'success': True, 'message': f'å•†å“ {product_id} å·²åˆ é™¤'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤å•†å“å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/products/<int:product_id>/images/<int:image_index>', methods=['DELETE'])
def delete_product_image(product_id, image_index):
    """åˆ é™¤å•†å“çš„å•ä¸ªå›¾ç‰‡"""
    try:
        # è·å–å•†å“ä¿¡æ¯
        product = db.get_product_by_id(product_id)
        if not product:
            return jsonify({'error': 'å•†å“ä¸å­˜åœ¨'}), 404

        images = product.get('images', [])
        if image_index < 0 or image_index >= len(images):
            return jsonify({'error': 'å›¾ç‰‡ç´¢å¼•æ— æ•ˆ'}), 400

        # åˆ é™¤æŒ‡å®šçš„å›¾ç‰‡
        removed_image = images.pop(image_index)

        # æ›´æ–°æ•°æ®åº“
        db.update_product_images(product_id, images)

        # å¦‚æœå¯ç”¨äº†è§„åˆ™ï¼Œé‡æ–°å»ºç«‹å‘é‡ç´¢å¼•
        if product.get('rule_enabled', False):
            try:
                from weidian_scraper import get_weidian_scraper
                scraper = get_weidian_scraper()
                # é‡æ–°å¤„ç†å•†å“ä»¥æ›´æ–°å‘é‡ç´¢å¼•
                updated_product = scraper.scrape_product_info(product['weidian_url'])
                if updated_product and updated_product.get('images'):
                    db.update_product_images(product_id, updated_product['images'])
            except Exception as e:
                logger.warning(f"é‡æ–°å»ºç«‹å‘é‡ç´¢å¼•å¤±è´¥: {e}")

        return jsonify({'success': True, 'message': f'å›¾ç‰‡å·²åˆ é™¤', 'removed_image': removed_image})
    except Exception as e:
        logger.error(f"åˆ é™¤å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-threshold', methods=['GET'])
def get_discord_threshold():
    """è·å–Discordç›¸ä¼¼åº¦é˜ˆå€¼"""
    try:
        sys_config = db.get_system_config()
        threshold = sys_config['discord_similarity_threshold']
        return jsonify({
            'threshold': threshold,
            'threshold_percentage': threshold * 100
        })
    except Exception as e:
        logger.error(f"è·å–Discordé˜ˆå€¼å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-threshold', methods=['POST'])
def update_discord_threshold():
    """æ›´æ–°Discordç›¸ä¼¼åº¦é˜ˆå€¼"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        threshold = float(data.get('threshold', 0.4))

        # éªŒè¯èŒƒå›´
        if not (0.0 <= threshold <= 1.0):
            return jsonify({'error': 'é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_system_config(discord_similarity_threshold=threshold):
            # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
            config.DISCORD_SIMILARITY_THRESHOLD = threshold
            logger.info(f"Discordç›¸ä¼¼åº¦é˜ˆå€¼è®¾ç½®ä¸º: {threshold} ({threshold*100:.0f}%)")

            return jsonify({
            'success': True,
            'threshold': threshold,
            'threshold_percentage': threshold * 100,
            'message': 'Discordé˜ˆå€¼è®¾ç½®å·²æ›´æ–°ï¼Œè¯·é‡å¯Discordæœºå™¨äººæœåŠ¡ä»¥ç”Ÿæ•ˆ'
        })

    except Exception as e:
        logger.error(f"æ›´æ–°Discordé˜ˆå€¼å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/global-reply-delay', methods=['GET'])
def get_global_reply_delay():
    """è·å–å…¨å±€å›å¤å»¶è¿Ÿé…ç½®"""
    try:
        delay_config = db.get_global_reply_config()
        return jsonify({
            'min_delay': delay_config['min_delay'],
            'max_delay': delay_config['max_delay'],
            'description': f'{delay_config["min_delay"]}-{delay_config["max_delay"]}ç§’éšæœºå»¶è¿Ÿ'
        })
    except Exception as e:
        logger.error(f"è·å–å…¨å±€å›å¤å»¶è¿Ÿå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/debug/faiss_status', methods=['GET'])
def get_faiss_status():
    """è·å–FAISSå‘é‡æ•°æ®åº“çŠ¶æ€"""
    try:
        from vector_engine import get_vector_engine
        engine = get_vector_engine()
        stats = engine.get_stats()

        # å°è¯•æœç´¢ä¸€ä¸ªæµ‹è¯•å‘é‡
        test_vector = np.zeros(config.VECTOR_DIMENSION, dtype='float32')
        test_results = engine.search(test_vector, top_k=1)

        return jsonify({
            'index_exists': True,
            'entity_count': stats['total_vectors'],
            'test_search_works': len(test_results) > 0,
            'vector_dimension': config.VECTOR_DIMENSION,
            'index_type': stats['index_type'],
            'metric_type': stats['metric_type'],
            'memory_usage_mb': stats['memory_usage_mb'],
            'ef_construction': stats['ef_construction'],
            'ef_search': stats['ef_search']
        })
    except Exception as e:
        logger.error(f"è·å–FAISSçŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'index_exists': False,
            'entity_count': 0
        }), 500

@app.route('/api/config/threads', methods=['GET'])
def get_thread_config():
    """è·å–çº¿ç¨‹é…ç½®"""
    try:
        sys_config = db.get_system_config()
        return jsonify({
            'download_threads': sys_config['download_threads'],
            'feature_extract_threads': sys_config['feature_extract_threads']
        })
    except Exception as e:
        logger.error(f"è·å–çº¿ç¨‹é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/threads', methods=['POST'])
def update_thread_config():
    """æ›´æ–°çº¿ç¨‹é…ç½®"""
    try:
        data = request.get_json()
        download_threads = data.get('download_threads')
        feature_extract_threads = data.get('feature_extract_threads')

        # éªŒè¯å‚æ•°
        if download_threads is not None and not (1 <= download_threads <= 8):
            return jsonify({'error': 'ä¸‹è½½çº¿ç¨‹æ•°å¿…é¡»åœ¨1-8ä¹‹é—´'}), 400
        if feature_extract_threads is not None and not (1 <= feature_extract_threads <= 8):
            return jsonify({'error': 'ç‰¹å¾æå–çº¿ç¨‹æ•°å¿…é¡»åœ¨1-8ä¹‹é—´'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_system_config(download_threads=download_threads, feature_extract_threads=feature_extract_threads):
            # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
            sys_config = db.get_system_config()
            config.DOWNLOAD_THREADS = sys_config['download_threads']
            config.FEATURE_EXTRACT_THREADS = sys_config['feature_extract_threads']

            return jsonify({
                'success': True,
                'download_threads': config.DOWNLOAD_THREADS,
                'feature_extract_threads': config.FEATURE_EXTRACT_THREADS
            })
        else:
            return jsonify({'error': 'ä¿å­˜å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°çº¿ç¨‹é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/config/global-reply-delay', methods=['POST'])
def update_global_reply_delay():
    """æ›´æ–°å…¨å±€å›å¤å»¶è¿Ÿé…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        min_delay = float(data.get('min_delay', 3))
        max_delay = float(data.get('max_delay', 8))

        # éªŒè¯èŒƒå›´
        if min_delay < 0 or max_delay < 0:
            return jsonify({'error': 'å»¶è¿Ÿæ—¶é—´ä¸èƒ½ä¸ºè´Ÿæ•°'}), 400
        if min_delay > max_delay:
            return jsonify({'error': 'æœ€å°å»¶è¿Ÿä¸èƒ½å¤§äºæœ€å¤§å»¶è¿Ÿ'}), 400
        if max_delay > 300:
            return jsonify({'error': 'æœ€å¤§å»¶è¿Ÿä¸èƒ½è¶…è¿‡300ç§’'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_global_reply_config(min_delay, max_delay):
            # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
            config.GLOBAL_REPLY_MIN_DELAY = min_delay
            config.GLOBAL_REPLY_MAX_DELAY = max_delay

            logger.info(f"å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®ä¸º: {min_delay}-{max_delay}ç§’")

            return jsonify({
                'success': True,
                'min_delay': min_delay,
                'max_delay': max_delay,
                'description': f'{min_delay}-{max_delay}ç§’éšæœºå»¶è¿Ÿ',
                'message': 'å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®å·²æ›´æ–°ï¼Œæ‰€æœ‰è‡ªåŠ¨å›å¤å°†ä½¿ç”¨æ­¤è®¾ç½®'
            })
        else:
            return jsonify({'error': 'ä¿å­˜å¤±è´¥'}), 500

    except Exception as e:
        logger.error(f"æ›´æ–°å…¨å±€å›å¤å»¶è¿Ÿå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-channel', methods=['GET'])
def get_discord_channel():
    """è·å–Discordé¢‘é“é…ç½®"""
    try:
        sys_config = db.get_system_config()
        return jsonify({
            'channel_id': sys_config['discord_channel_id'],
            'cnfans_channel_id': sys_config['cnfans_channel_id'],
            'acbuy_channel_id': sys_config['acbuy_channel_id']
        })
    except Exception as e:
        logger.error(f"è·å–Discordé¢‘é“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-channel', methods=['POST'])
def update_discord_channel():
    """æ›´æ–°Discordé¢‘é“é…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        channel_id = data.get('channel_id', '').strip()
        cnfans_channel_id = data.get('cnfans_channel_id', '').strip()
        acbuy_channel_id = data.get('acbuy_channel_id', '').strip()

        # éªŒè¯é¢‘é“IDæ ¼å¼ï¼ˆåº”è¯¥æ˜¯æ•°å­—ï¼‰
        for cid_name, cid_value in [('channel_id', channel_id), ('cnfans_channel_id', cnfans_channel_id), ('acbuy_channel_id', acbuy_channel_id)]:
            if cid_value and not cid_value.isdigit():
                return jsonify({'error': f'{cid_name} å¿…é¡»æ˜¯æ•°å­—'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_system_config(
            discord_channel_id=channel_id,
            cnfans_channel_id=cnfans_channel_id,
            acbuy_channel_id=acbuy_channel_id
        ):
            # åŒæ—¶æ›´æ–°ç¯å¢ƒå˜é‡å’Œbot_config
            if channel_id:
                os.environ['DISCORD_CHANNEL_ID'] = channel_id
                import bot_config
                bot_config.config.DISCORD_CHANNEL_ID = int(channel_id)
                logger.info(f"Discordé¢‘é“IDè®¾ç½®ä¸º: {channel_id}")
            else:
                os.environ.pop('DISCORD_CHANNEL_ID', None)
                import bot_config
                bot_config.config.DISCORD_CHANNEL_ID = 0
                logger.info("Discordé¢‘é“IDå·²æ¸…é™¤")

            return jsonify({
                'success': True,
                'channel_id': channel_id,
                'message': f'Discordé¢‘é“IDå·²è®¾ç½®ä¸º: {channel_id or "æ— (ç›‘å¬æ‰€æœ‰é¢‘é“)"}'
            })
        else:
            return jsonify({'error': 'ä¿å­˜å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°Discordé¢‘é“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history', methods=['GET'])
def get_search_history():
    """è·å–æœç´¢å†å²è®°å½•ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    try:
        limit = min(int(request.args.get('limit', 20)), 100)  # æœ€å¤š100æ¡
        offset = max(int(request.args.get('offset', 0)), 0)
        page = max(int(request.args.get('page', 1)), 1)

        # å¦‚æœæä¾›äº†pageå‚æ•°ï¼Œè®¡ç®—offset
        if 'page' in request.args and 'offset' not in request.args:
            offset = (page - 1) * limit

        result = db.get_search_history(limit, offset)
        return jsonify(result)
    except Exception as e:
        logger.error(f"è·å–æœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_similar_text', methods=['POST'])
def search_similar_text():
    """æ ¹æ®æ–‡å­—å…³é”®è¯æœç´¢ç›¸ä¼¼å•†å“"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Invalid request body'}), 400

        query = data.get('query', '').strip()
        limit = min(int(data.get('limit', 5)), 20)  # æœ€å¤š20ä¸ªç»“æœ

        if not query:
            return jsonify({'error': 'Query is required'}), 400

        logger.info(f'æ–‡å­—æœç´¢è¯·æ±‚: "{query}", é™åˆ¶: {limit}')

        # åœ¨æ•°æ®åº“ä¸­æœç´¢åŒ…å«å…³é”®è¯çš„å•†å“
        with db.get_connection() as conn:
            cursor = conn.cursor()

            # ä½¿ç”¨LIKEæŸ¥è¯¢åœ¨æ ‡é¢˜å’Œè‹±æ–‡æ ‡é¢˜ä¸­æœç´¢
            cursor.execute("""
                SELECT id, product_url, title, english_title, description,
                       ruleEnabled, min_delay, max_delay, created_at,
                       cnfans_url
                FROM products
                WHERE (title LIKE ? OR english_title LIKE ? OR description LIKE ?)
                  AND ruleEnabled = 1
                ORDER BY created_at DESC
                LIMIT ?
            """, (f'%{query}%', f'%{query}%', f'%{query}%', limit))

            rows = cursor.fetchall()

            products = []
            for row in rows:
                prod = dict(row)
                # è·å–å›¾ç‰‡
                cursor.execute("SELECT image_path FROM product_images WHERE product_id = ? ORDER BY image_index LIMIT 1", (prod['id'],))
                img_row = cursor.fetchone()
                if img_row:
                    prod['image'] = f"/api/image/{prod['id']}/0"
                else:
                    prod['image'] = None

                # æ ¼å¼åŒ–å­—æ®µ
                prod['weidianUrl'] = prod.get('product_url')
                prod['englishTitle'] = prod.get('english_title') or ''
                prod['cnfansUrl'] = prod.get('cnfans_url') or ''
                prod['autoReplyEnabled'] = prod.get('ruleEnabled', True)
                # ä»URLä¸­æå–weidian ID
                try:
                    import re
                    m = re.search(r'itemID=(\d+)', prod.get('product_url') or '')
                    prod['weidianId'] = m.group(1) if m else ''
                except:
                    prod['weidianId'] = ''

                products.append(prod)

        logger.info(f'æ–‡å­—æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(products)} ä¸ªå•†å“')

        return jsonify({
            'success': True,
            'query': query,
            'products': products,
            'total': len(products)
        })

    except Exception as e:
        logger.error(f"æ–‡å­—æœç´¢å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history/<int:history_id>', methods=['DELETE'])
def delete_search_history(history_id):
    """åˆ é™¤æœç´¢å†å²è®°å½•"""
    try:
        if db.delete_search_history(history_id):
            return jsonify({'success': True})
        else:
            return jsonify({'error': 'è®°å½•ä¸å­˜åœ¨'}), 404
    except Exception as e:
        logger.error(f"åˆ é™¤æœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history', methods=['DELETE'])
def clear_search_history():
    """æ¸…ç©ºæ‰€æœ‰æœç´¢å†å²"""
    try:
        if db.clear_search_history():
            return jsonify({'success': True})
        else:
            return jsonify({'error': 'æ¸…ç©ºå¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ¸…ç©ºæœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/logs/stream')
def log_stream():
    """Server-Sent Events æ—¥å¿—æµ"""
    import json

    def generate():
        # ä¸ºè¿™ä¸ªå®¢æˆ·ç«¯åˆ›å»ºé˜Ÿåˆ—
        client_queue = queue.Queue(maxsize=100)  # é™åˆ¶é˜Ÿåˆ—å¤§å°
        log_clients.append(client_queue)

        try:
            # å‘é€æœ€è¿‘çš„æ—¥å¿—å†å²
            for log_entry in all_logs[-20:]:  # å‘é€æœ€è¿‘20æ¡å†å²æ—¥å¿—
                yield f"data: {json.dumps(log_entry)}\n\n"

            # æŒç»­ç›‘å¬æ–°æ—¥å¿—
            while True:
                try:
                    # ç­‰å¾…æ–°æ—¥å¿—ï¼Œè¶…æ—¶æ—¶é—´è®¾ä¸º30ç§’
                    log_entry = client_queue.get(timeout=30)
                    yield f"data: {json.dumps(log_entry)}\n\n"
                except queue.Empty:
                    # å‘é€å¿ƒè·³åŒ…ä¿æŒè¿æ¥
                    yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': datetime.now().isoformat()})}\n\n"

        except GeneratorExit:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            pass
        finally:
            # æ¸…ç†å®¢æˆ·ç«¯é˜Ÿåˆ—
            if client_queue in log_clients:
                log_clients.remove(client_queue)

    return Response(generate(), mimetype='text/event-stream',
                   headers={'Cache-Control': 'no-cache',
                           'Access-Control-Allow-Origin': '*',
                           'Access-Control-Allow-Headers': 'Cache-Control'})

@app.route('/api/logs/recent')
def get_recent_logs():
    """è·å–æœ€è¿‘çš„æ—¥å¿—è®°å½•"""
    try:
        # ä»æ—¥å¿—åˆ—è¡¨ä¸­è¿”å›æœ€è¿‘50æ¡æ—¥å¿—
        return jsonify({
            'logs': all_logs[-50:],
            'total': len(all_logs)
        })
    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘æ—¥å¿—å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/logs/add', methods=['POST'])
def add_external_log():
    """æ¥æ”¶å¤–éƒ¨è¿›ç¨‹å‘é€çš„æ—¥å¿—"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Invalid log data'}), 400

        # åˆ›å»ºæ—¥å¿—æ¡ç›®
        log_entry = {
            'timestamp': data.get('timestamp', datetime.now().isoformat()),
            'level': data.get('level', 'INFO'),
            'message': data.get('message', ''),
            'module': data.get('module', 'external'),
            'func': data.get('func', '')
        }

        # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨
        all_logs.append(log_entry)
        if len(all_logs) > 200:
            all_logs.pop(0)

        # æ·»åŠ åˆ°é˜Ÿåˆ—
        log_queue.put(log_entry)

        return jsonify({'success': True})
    except Exception as e:
        print(f"æ·»åŠ å¤–éƒ¨æ—¥å¿—å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

def start_discord_bot():
    """å¯åŠ¨Discordæœºå™¨äºº - æ”¯æŒå¤šè´¦å·"""
    global bot_clients, bot_tasks

    try:
        import asyncio
        from bot import DiscordBotClient, get_all_accounts_from_backend

        logger.info("æ­£åœ¨å¯åŠ¨Discordæœºå™¨äºº...")

        # è·å–æ‰€æœ‰è´¦å·
        accounts = asyncio.run(get_all_accounts_from_backend())
        if not accounts:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Discordè´¦å·")
            return

        logger.info(f"æ‰¾åˆ° {len(accounts)} ä¸ªDiscordè´¦å·ï¼Œå¼€å§‹å¯åŠ¨æœºå™¨äºº...")

        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œæœºå™¨äºº
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # ä¸ºæ¯ä¸ªè´¦å·åˆ›å»ºæœºå™¨äººå®ä¾‹
        for account in accounts:
            account_id = account['id']
            token = account['token']
            username = account.get('username', f'account_{account_id}')

            logger.info(f"æ­£åœ¨å¯åŠ¨æœºå™¨äººè´¦å·: {username}")

            # åˆ›å»ºæœºå™¨äººå®ä¾‹
            client = DiscordBotClient(account_id=account_id)

            # å¯åŠ¨æœºå™¨äºº
            try:
                task = loop.create_task(client.start(token, reconnect=True))
                bot_clients.append(client)
                bot_tasks.append(task)
                logger.info(f"Discordæœºå™¨äººå¯åŠ¨æˆåŠŸ: {username}")
            except Exception as e:
                logger.error(f"å¯åŠ¨æœºå™¨äººå¤±è´¥ {username}: {e}")

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        import threading
        bot_thread = threading.Thread(target=loop.run_forever, daemon=True)
        bot_thread.start()

        logger.info(f"å…±å¯åŠ¨äº† {len(bot_clients)} ä¸ªDiscordæœºå™¨äºº")

    except ImportError as e:
        logger.warning(f"Discordæœºå™¨äººæ¨¡å—ä¸å¯ç”¨: {e}")
        logger.info("Flaskåº”ç”¨å°†ç»§ç»­è¿è¡Œï¼Œä½†æœºå™¨äººåŠŸèƒ½ä¸å¯ç”¨")
    except Exception as e:
        logger.error(f"Discordæœºå™¨äººå¯åŠ¨å¤±è´¥: {e}")
        logger.info("Flaskåº”ç”¨å°†ç»§ç»­è¿è¡Œï¼Œä½†æœºå™¨äººåŠŸèƒ½ä¸å¯ç”¨")

def stop_discord_bot():
    """åœæ­¢Discordæœºå™¨äºº"""
    global bot_clients, bot_tasks

    if bot_clients:
        logger.info(f"æ­£åœ¨åœæ­¢ {len(bot_clients)} ä¸ªDiscordæœºå™¨äºº...")
        try:
            import asyncio
            # åˆ›å»ºä»»åŠ¡æ¥åœæ­¢æ‰€æœ‰æœºå™¨äºº
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            for i, client in enumerate(bot_clients):
                try:
                    if client and not client.is_closed():
                        loop.run_until_complete(client.close())
                        logger.info(f"Discordæœºå™¨äºº {i+1} å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"åœæ­¢æœºå™¨äºº {i+1} æ—¶å‡ºé”™: {e}")

            logger.info("æ‰€æœ‰Discordæœºå™¨äººå·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢æœºå™¨äººæ—¶å‡ºé”™: {e}")

    # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
    for task in bot_tasks:
        if task and not task.done():
            task.cancel()

@app.route('/api/shop-info', methods=['GET'])
def get_shop_info():
    """è·å–åº—é“ºä¿¡æ¯"""
    try:
        shop_id = request.args.get('shopId')
        if not shop_id:
            return jsonify({'error': 'ç¼ºå°‘shopIdå‚æ•°'}), 400

        shop_id = shop_id.strip()
        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        logger.info(f'è·å–åº—é“ºä¿¡æ¯: {shop_id}')

        # è°ƒç”¨å¾®åº—APIè·å–åº—é“ºä¿¡æ¯
        try:
            param = json.dumps({"shop_id": shop_id, "page_id": 0})
            encoded_param = quote(param)

            api_url = f"https://thor.weidian.com/decorate/customSharePage.getPageInfo/1.0?param={encoded_param}&wdtoken=8ea9315c&_={int(time.time() * 1000)}"

            response = requests.get(api_url, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
                'Origin': 'https://weidian.com',
                'Referer': 'https://weidian.com/',
                'Sec-Ch-Ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"macOS"',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-site',
            }, cookies={
                'wdtoken': '8ea9315c',
                '__spider__visitorid': '0dcf6a5b878847ec',
                'visitor_id': '4d36e980-4128-451c-8178-a976b6303114',
                'v-components/cpn-coupon-dialog@nologinshop': '10',
                '__spider__sessionid': 'e55c6458ac1fdba4'
            }, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if data.get('status', {}).get('code') == 0:
                    shop_name = data.get('result', {}).get('shareTitle', f'åº—é“º {shop_id}')
                    return jsonify({'shopName': shop_name})
                else:
                    logger.warning(f'APIè¿”å›é”™è¯¯çŠ¶æ€: {data}')
            else:
                logger.warning(f'APIè¯·æ±‚å¤±è´¥: {response.status_code}')

        except Exception as e:
            logger.error(f'è·å–åº—é“ºä¿¡æ¯å¤±è´¥: {e}')

        # å¦‚æœAPIå¤±è´¥ï¼Œè¿”å›é»˜è®¤åç§°
        return jsonify({'shopName': f'åº—é“º {shop_id}'})

    except Exception as e:
        logger.error(f'è·å–åº—é“ºä¿¡æ¯å‡ºé”™: {e}')
        return jsonify({'error': 'è·å–åº—é“ºä¿¡æ¯å¤±è´¥'}), 500

# ===== åº—é“ºç®¡ç†API =====

@app.route('/api/shops', methods=['GET'])
def get_shops():
    """è·å–æ‰€æœ‰åº—é“ºåˆ—è¡¨"""
    try:
        shops = db.get_all_shops()
        return jsonify({'shops': shops})
    except Exception as e:
        logger.error(f'è·å–åº—é“ºåˆ—è¡¨å¤±è´¥: {e}')
        return jsonify({'error': 'è·å–åº—é“ºåˆ—è¡¨å¤±è´¥'}), 500

@app.route('/api/shops', methods=['POST'])
def add_shop():
    """æ·»åŠ æ–°åº—é“º"""
    try:
        data = request.get_json()
        if not data or not data.get('shopId') or not data.get('name'):
            return jsonify({'error': 'ç¼ºå°‘shopIdæˆ–nameå‚æ•°'}), 400

        shop_id = data['shopId'].strip()
        name = data['name'].strip()

        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        # è·å–çœŸå®çš„åº—é“ºåç§°
        shop_info = get_shop_info_from_api(shop_id)
        if shop_info and shop_info.get('shopName'):
            name = shop_info['shopName']

        if db.add_shop(shop_id, name):
            return jsonify({'success': True, 'message': 'åº—é“ºæ·»åŠ æˆåŠŸ'})
        else:
            return jsonify({'error': 'åº—é“ºå·²å­˜åœ¨æˆ–æ·»åŠ å¤±è´¥'}), 400
    except Exception as e:
        logger.error(f'æ·»åŠ åº—é“ºå¤±è´¥: {e}')
        return jsonify({'error': 'æ·»åŠ åº—é“ºå¤±è´¥'}), 500

@app.route('/api/shops/<shop_id>', methods=['DELETE'])
def delete_shop(shop_id):
    """åˆ é™¤åº—é“º"""
    try:
        if db.delete_shop(shop_id):
            return jsonify({'success': True, 'message': 'åº—é“ºåˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'åº—é“ºä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥'}), 404
    except Exception as e:
        logger.error(f'åˆ é™¤åº—é“ºå¤±è´¥: {e}')
        return jsonify({'error': 'åˆ é™¤åº—é“ºå¤±è´¥'}), 500

def get_shop_info_from_api(shop_id):
    """ä»APIè·å–åº—é“ºä¿¡æ¯"""
    try:
        import json
        from urllib.parse import quote
        import time

        param = json.dumps({"shop_id": shop_id, "page_id": 0})
        encoded_param = quote(param)

        api_url = f"https://thor.weidian.com/decorate/customSharePage.getPageInfo/1.0?param={encoded_param}&wdtoken=8ea9315c&_={int(time.time() * 1000)}"

        response = requests.get(api_url, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
            'Origin': 'https://weidian.com',
            'Referer': 'https://weidian.com/',
            'Sec-Ch-Ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
        }, cookies={
            'wdtoken': '8ea9315c',
            '__spider__visitorid': '0dcf6a5b878847ec',
            'visitor_id': '4d36e980-4128-451c-8178-a976b6303114',
            'v-components/cpn-coupon-dialog@nologinshop': '2',
            '__spider__sessionid': 'c7da7d6e06b1f1ac'
        }, timeout=10, proxies={'http': None, 'https': None})

        if response.status_code == 200:
            data = response.json()
            if data.get('status', {}).get('code') == 0:
                result = data.get('result', {})
                shop_name = result.get('shareTitle', '')
                if shop_name:
                    return {'shopName': shop_name}

    except Exception as e:
        logger.warning(f'è·å–åº—é“ºä¿¡æ¯å¤±è´¥: {e}')

    return None

@app.route('/api/scrape/shop', methods=['POST'])
def scrape_shop():
    """æŠ“å–æ•´ä¸ªåº—é“ºçš„æ‰€æœ‰å•†å“"""
    try:
        data = request.get_json()
        if not data or not data.get('shopId'):
            return jsonify({'error': 'ç¼ºå°‘shopIdå‚æ•°'}), 400

        shop_id = data['shopId'].strip()
        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        logger.info(f'å¼€å§‹æŠ“å–åº—é“º: {shop_id}')

        # è¿™é‡Œå®ç°åº—é“ºæŠ“å–é€»è¾‘
        # ä½¿ç”¨å¾®åº—APIè·å–åº—é“ºæ‰€æœ‰å•†å“
        result = scrape_shop_products(shop_id)

        logger.info(f'åº—é“º {shop_id} æŠ“å–å®Œæˆï¼Œå…±è·å– {result["total_products"]} ä¸ªå•†å“')

        return jsonify({
            'success': True,
            'totalProducts': result["total_products"],
            'pagesProcessed': result["pages_processed"],
            'message': f'æˆåŠŸæŠ“å– {result["total_products"]} ä¸ªå•†å“ï¼Œå…±å¤„ç† {result["pages_processed"]} é¡µ'
        })

    except Exception as e:
        logger.error(f'åº—é“ºæŠ“å–å¤±è´¥: {e}')
        return jsonify({'error': str(e)}), 500

def scrape_shop_products(shop_id):
    """æŠ“å–åº—é“ºæ‰€æœ‰å•†å“çš„å®ç°"""
    import requests
    import time

    total_products = 0
    offset = 0
    limit = 20
    page_count = 0

    # è·å–åº—é“ºåç§°
    shop_info = get_shop_info_from_api(shop_id)
    shop_name = shop_info.get('shopName', f'åº—é“º {shop_id}') if shop_info else f'åº—é“º {shop_id}'
    logger.info(f'å¼€å§‹æŠ“å–åº—é“º: {shop_name} (ID: {shop_id})')

    while True:
        try:
            # æ„å»ºAPI URL
            url = f"https://thor.weidian.com/decorate/shopDetail.tab.getItemList/1.0"
            params = {
                "param": f'{{"shopId":"{shop_id}","tabId":0,"sortOrder":"desc","offset":{offset},"limit":{limit},"from":"h5","showItemTag":true}}'
            }

            # å‘é€è¯·æ±‚
            headers = {
                'accept': 'application/json, text/plain, */*',
                'accept-language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
                'origin': 'https://weidian.com',
                'priority': 'u=1, i',
                'referer': 'https://weidian.com/',
                'sec-ch-ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
                'sec-ch-ua-mobile': '?0',
                'sec-ch-ua-platform': '"macOS"',
                'sec-fetch-dest': 'empty',
                'sec-fetch-mode': 'cors',
                'sec-fetch-site': 'same-site',
                'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36'
            }

            cookies = {
                'wdtoken': '8ea9315c',
                '__spider__visitorid': '0dcf6a5b878847ec',
                'visitor_id': '4d36e980-4128-451c-8178-a976b6303114',
                'v-components/cpn-coupon-dialog@nologinshop': '10',
                '__spider__sessionid': 'e55c6458ac1fdba4'
            }

            response = requests.get(url, params=params, headers=headers, cookies=cookies, timeout=10, proxies={'http': None, 'https': None})

            if response.status_code != 200:
                logger.warning(f'APIè¯·æ±‚å¤±è´¥: {response.status_code}')
                break

            data = response.json()

            if data.get('status', {}).get('code') != 0:
                logger.warning('APIå“åº”çŠ¶æ€ç ä¸ä¸º0')
                break

            result = data.get('result', {})
            if not result.get('hasData', False):
                logger.info('æ²¡æœ‰æ›´å¤šæ•°æ®ï¼ŒæŠ“å–å®Œæˆ')
                break

            items = result.get('itemList', [])
            if not items:
                logger.info('å•†å“åˆ—è¡¨ä¸ºç©ºï¼ŒæŠ“å–å®Œæˆ')
                break

            # æ‰¹é‡å¤„ç†å•†å“è¯¦æƒ…ï¼ˆå¤šçº¿ç¨‹ï¼‰
            products_to_process = []
            for item in items:
                item_id = item.get('itemId', '')
                if item_id:
                    products_to_process.append({
                        'item_id': item_id,
                        'item_url': item.get('itemUrl', ''),
                        'shop_name': shop_name
                    })

            if products_to_process:
                # å¤šçº¿ç¨‹è·å–å•†å“è¯¦æƒ…
                processed_products = process_products_multithreaded(products_to_process)

                for product_data in processed_products:
                    try:
                        if product_data:
                            # æ£€æŸ¥å•†å“æ˜¯å¦å·²å­˜åœ¨
                            existing = db.get_product_by_url(product_data['product_url'])
                            if existing:
                                logger.debug(f'å•†å“å·²å­˜åœ¨ï¼Œè·³è¿‡: {product_data["title"]}')
                                continue

                            # æ’å…¥å•†å“
                            product_id = db.insert_product(product_data)

                            # ä¸‹è½½å›¾ç‰‡
                            if product_data.get('images'):
                                save_product_images(product_id, product_data['images'])

                            total_products += 1
                            logger.debug(f'æˆåŠŸæ·»åŠ å•†å“: {product_data["title"]}')

                    except Exception as e:
                        logger.error(f'ä¿å­˜å•†å“å¤±è´¥: {e}')
                        continue

            # å¢åŠ offsetç»§ç»­æŠ“å–
            offset += limit

            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(0.5)

        except Exception as e:
            logger.error(f'æŠ“å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}')
            break

    return {
        "total_products": total_products,
        "pages_processed": page_count
    }

def scrape_product_info(product_url):
    """æ ¹æ®å•†å“URLè·å–å•†å“è¯¦ç»†ä¿¡æ¯"""
    try:
        from weidian_scraper import get_weidian_scraper

        scraper = get_weidian_scraper()
        product_info = scraper.scrape_product_info(product_url)

        if product_info:
            # é‡æ–°æ ¼å¼åŒ–è¿”å›æ•°æ®
            return {
                'title': product_info.get('title', ''),
                'description': product_info.get('description', ''),
                'images': product_info.get('images', [])[:5],  # æœ€å¤š5å¼ å›¾ç‰‡
                'shop_name': product_info.get('shop_name', '')
            }

        return None

    except Exception as e:
        logger.error(f'è·å–å•†å“è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}')
        return None

def generate_acbuy_url(weidian_url):
    """ç”ŸæˆAcBuyé“¾æ¥"""
    if not weidian_url:
        return ''

    try:
        import re
        item_id_match = re.search(r'itemID=(\d+)', weidian_url)
        if item_id_match:
            item_id = item_id_match.group(1)
            # æ„å»ºacbuyé“¾æ¥
            encoded_url = weidian_url.replace(':', '%3A').replace('/', '%2F').replace('?', '%3F').replace('=', '%3D').replace('&', '%26')
            return f'https://www.acbuy.com/product?url={encoded_url}&id={item_id}&source=WD'
    except Exception as e:
        logger.error(f'ç”ŸæˆAcBuyé“¾æ¥å¤±è´¥: {e}')

    return ''

def generate_cnfans_url(item_id):
    """ç”ŸæˆCNFansé“¾æ¥"""
    if not item_id:
        return ''
    return f"https://cnfans.com/product?id={item_id}&platform=WEIDIAN"

def generate_english_title(chinese_title):
    """å°†ä¸­æ–‡æ ‡é¢˜ç¿»è¯‘ä¸ºè‹±æ–‡æ ‡é¢˜"""
    if not chinese_title:
        return ''

    try:
        import re
        import requests

        # é¦–å…ˆå°è¯•æå–å·²æœ‰çš„è‹±æ–‡éƒ¨åˆ†
        english_parts = re.findall(r'[a-zA-Z\s]+', chinese_title)
        if english_parts and len(' '.join(english_parts).strip()) > 5:
            # å¦‚æœè‹±æ–‡éƒ¨åˆ†è¶³å¤Ÿé•¿ï¼Œç›´æ¥è¿”å›
            return ' '.join(english_parts).strip()

        # å“ç‰Œåç§°æ˜ å°„ï¼ˆæ‰©å±•ç‰ˆï¼‰
        brand_mappings = {
            'Nike': 'Nike', 'é˜¿è¿ª': 'Adidas', 'Adidas': 'Adidas', 'æå®': 'LiNing',
            'å®‰è¸': 'Anta', 'åŒ¹å…‹': 'Peak', 'ä¹”ä¸¹': 'Jordan', 'New Balance': 'New Balance',
            'Converse': 'Converse', 'Vans': 'Vans', 'Supreme': 'Supreme', 'BAPE': 'BAPE',
            'Palace': 'Palace', 'Stone Island': 'Stone Island', 'Off-White': 'Off-White',
            'Balenciaga': 'Balenciaga', 'Gucci': 'Gucci', 'Louis Vuitton': 'Louis Vuitton',
            'Chanel': 'Chanel', 'Dior': 'Dior', 'Yeezy': 'Yeezy', 'Puma': 'Puma',
            'Reebok': 'Reebok', 'Under Armour': 'Under Armour', 'Fila': 'Fila',
            'The North Face': 'The North Face', 'Columbia': 'Columbia', 'Patagonia': 'Patagonia',
            'Arc\'teryx': 'Arc\'teryx', 'Canada Goose': 'Canada Goose', 'Moncler': 'Moncler',
            'Burberry': 'Burberry', 'Prada': 'Prada', 'Versace': 'Versace', 'Fendi': 'Fendi',
            'Hermes': 'Hermes', 'Rolex': 'Rolex', 'Cartier': 'Cartier', 'Omega': 'Omega',
            'IWC': 'IWC', 'Jaeger-LeCoultre': 'Jaeger-LeCoultre', 'Patek Philippe': 'Patek Philippe'
        }

        # åº”ç”¨å“ç‰Œæ˜ å°„
        title = chinese_title
        for zh, en in brand_mappings.items():
            title = title.replace(zh, en)

        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸­æ–‡å­—ç¬¦
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in title)

        if has_chinese:
            # ä½¿ç”¨ç™¾åº¦ç¿»è¯‘APIæˆ–å…¶ä»–å…è´¹ç¿»è¯‘æœåŠ¡
            try:
                # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„ç¿»è¯‘APIç¤ºä¾‹
                # å®é™…éƒ¨ç½²æ—¶éœ€è¦æ›¿æ¢ä¸ºç¨³å®šçš„ç¿»è¯‘æœåŠ¡
                api_url = "https://api.mymemory.translated.net/get"
                params = {
                    'q': chinese_title,
                    'langpair': 'zh-CN|en-US',
                    'de': 'your-email@example.com'  # MyMemoryè¦æ±‚æä¾›é‚®ç®±
                }

                response = requests.get(api_url, params=params, timeout=5, proxies={'http': None, 'https': None})
                if response.status_code == 200:
                    data = response.json()
                    translated = data.get('responseData', {}).get('translatedText', '')
                    if translated and translated != chinese_title:
                        # æ¸…ç†ç¿»è¯‘ç»“æœ
                        translated = re.sub(r'[^\w\s\-]', '', translated)
                        return translated.strip()

            except Exception as e:
                logger.warning(f'åœ¨çº¿ç¿»è¯‘å¤±è´¥: {e}')

            # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œè¿”å›æå–çš„è‹±æ–‡éƒ¨åˆ†æˆ–åŸæ ‡é¢˜
            english_parts = re.findall(r'[a-zA-Z\s\-]+', title)
            if english_parts:
                result = ' '.join(english_parts).strip()
                if len(result) > 3:
                    return result

        # å¦‚æœæ²¡æœ‰ä¸­æ–‡æˆ–ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›å¤„ç†åçš„æ ‡é¢˜
        return re.sub(r'[^\w\s\-]', '', title).strip()

    except Exception as e:
        logger.error(f'ç”Ÿæˆè‹±æ–‡æ ‡é¢˜å¤±è´¥: {e}')
        return chinese_title

def process_single_product(product_info):
    """å¤„ç†å•ä¸ªå•†å“çš„è¯¦æƒ…æŠ“å–"""
    try:
        item_id = product_info['item_id']
        item_url = product_info['item_url']
        shop_name = product_info['shop_name']

        # è·å–å•†å“è¯¦ç»†ä¿¡æ¯
        product_details = scrape_product_info(item_url)

        if product_details:
            # ç”Ÿæˆè‹±æ–‡æ ‡é¢˜
            english_title = generate_english_title(product_details.get('title', ''))

            return {
                'product_url': item_url,
                'title': product_details.get('title', ''),
                'description': product_details.get('description', ''),
                'english_title': english_title,
                'cnfans_url': generate_cnfans_url(item_id),
                'acbuy_url': generate_acbuy_url(item_url),
                'shop_name': shop_name,
                'images': product_details.get('images', []),
                'ruleEnabled': True
            }
        return None

    except Exception as e:
        logger.error(f'å¤„ç†å•†å“å¤±è´¥: {e}')
        return None

def process_products_multithreaded(products_list):
    """å¤šçº¿ç¨‹å¤„ç†å•†å“è¯¦æƒ…æŠ“å–"""
    import concurrent.futures

    processed_products = []

    # è·å–é…ç½®çš„çº¿ç¨‹æ•°
    max_workers = config.DOWNLOAD_THREADS if hasattr(config, 'DOWNLOAD_THREADS') else 4

    logger.info(f'å¼€å§‹å¤šçº¿ç¨‹å¤„ç† {len(products_list)} ä¸ªå•†å“ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹')

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_product = {
            executor.submit(process_single_product, product): product
            for product in products_list
        }

        # æ”¶é›†ç»“æœ
        for future in concurrent.futures.as_completed(future_to_product):
            try:
                result = future.result()
                if result:
                    processed_products.append(result)
            except Exception as e:
                logger.error(f'å•†å“å¤„ç†ä»»åŠ¡å¤±è´¥: {e}')

    logger.info(f'å¤šçº¿ç¨‹å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(processed_products)} ä¸ªå•†å“')
    return processed_products

def save_product_images(product_id, image_urls):
    """ä¿å­˜å•†å“å›¾ç‰‡"""
    try:
        for index, image_url in enumerate(image_urls[:5]):  # æœ€å¤šä¿å­˜5å¼ å›¾ç‰‡
            if image_url:
                # ä¸‹è½½å›¾ç‰‡
                response = requests.get(image_url, timeout=10, proxies={'http': None, 'https': None})
                if response.status_code == 200:
                    # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
                    image_filename = f"{product_id}_{index}.jpg"
                    image_path = os.path.join('data', 'images', image_filename)

                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(image_path), exist_ok=True)

                    with open(image_path, 'wb') as f:
                        f.write(response.content)

                    # æ’å…¥å›¾ç‰‡è®°å½•åˆ°æ•°æ®åº“
                    db.insert_image_record(product_id, image_path, index)

                    logger.debug(f'ä¿å­˜å›¾ç‰‡: {image_filename}')

    except Exception as e:
        logger.error(f'ä¿å­˜å•†å“å›¾ç‰‡å¤±è´¥: {e}')

if __name__ == '__main__':
    import atexit
    import threading
    import time

    # æ³¨å†Œé€€å‡ºæ—¶åœæ­¢æœºå™¨äººçš„å‡½æ•°
    atexit.register(stop_discord_bot)

    # æœ¬åœ°å¼€å‘æ¨¡å¼ - æ€»æ˜¯å¯ç”¨çƒ­é‡è½½
    print("ğŸš€ Starting Flask API in development mode...")
    print("ğŸ¤– Discord bot will start after Flask is ready...")
    print("ğŸ”„ Hot reload enabled - modify files and refresh browser")

    # åœ¨åå°å¯åŠ¨æœºå™¨äººï¼ˆå»¶è¿Ÿå¯åŠ¨ï¼‰
    def delayed_bot_start():
        # ç­‰å¾…Flaskåº”ç”¨å®Œå…¨å¯åŠ¨
        time.sleep(3)
        start_discord_bot()

    bot_startup_thread = threading.Thread(target=delayed_bot_start, daemon=True)
    bot_startup_thread.start()

    try:
        app.run(host='127.0.0.1', port=5001, debug=config.DEBUG, use_reloader=False)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Received interrupt signal, shutting down...")
    finally:
        stop_discord_bot()
