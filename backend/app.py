from flask import Flask, request, jsonify, Response, session
import numpy as np
import os
import logging
import sys
from datetime import datetime
from threading import Lock

# è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    # ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½.envæ–‡ä»¶
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    env_path = os.path.join(project_root, '.env')
    if os.path.exists(env_path):
        load_dotenv(env_path)
        print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
    else:
        print("â„¹ï¸  æœªæ‰¾åˆ°.envæ–‡ä»¶ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")
except ImportError:
    print("â„¹ï¸  python-dotenvæœªå®‰è£…ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")

try:
    from feature_extractor import get_feature_extractor, DINOv2FeatureExtractor
except ImportError:
    from .feature_extractor import get_feature_extractor, DINOv2FeatureExtractor
try:
    from database import db
    from config import config
except ImportError:
    from .database import db
    from .config import config
import requests
import json
from flask_cors import CORS
import queue
import threading
import time
from urllib.parse import quote
import hashlib

# åœ¨åº”ç”¨å¯åŠ¨æ—¶ä»æ•°æ®åº“åŠ è½½ç³»ç»Ÿé…ç½®
def load_system_config():
    """ä»æ•°æ®åº“åŠ è½½ç³»ç»Ÿé…ç½®åˆ°å†…å­˜"""
    # åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰loggerï¼Œå› ä¸ºæ­¤æ—¶å…¨å±€loggerå¯èƒ½è¿˜æ²¡æœ‰åˆå§‹åŒ–
    import logging
    func_logger = logging.getLogger(__name__)

    try:
        sys_config = db.get_system_config()
        config.DISCORD_SIMILARITY_THRESHOLD = sys_config['discord_similarity_threshold']
        config.DISCORD_CHANNEL_ID = sys_config['discord_channel_id']
        config.CNFANS_CHANNEL_ID = sys_config['cnfans_channel_id']
        config.ACBUY_CHANNEL_ID = sys_config['acbuy_channel_id']

        # åŠ è½½å…¨å±€å›å¤å»¶è¿Ÿé…ç½®
        reply_config = db.get_global_reply_config()
        config.GLOBAL_REPLY_MIN_DELAY = reply_config['min_delay']
        config.GLOBAL_REPLY_MAX_DELAY = reply_config['max_delay']

        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¾›æœºå™¨äººä½¿ç”¨ï¼‰
        discord_channel_id = sys_config['discord_channel_id']
        if discord_channel_id:
            os.environ['DISCORD_CHANNEL_ID'] = discord_channel_id

        func_logger.info("ç³»ç»Ÿé…ç½®å·²ä»æ•°æ®åº“åŠ è½½")
        func_logger.info(f"ä¸‹è½½çº¿ç¨‹: {config.DOWNLOAD_THREADS}")
        func_logger.info(f"ç‰¹å¾æå–çº¿ç¨‹: {config.FEATURE_EXTRACT_THREADS}")
        func_logger.info(f"Discordç›¸ä¼¼åº¦é˜ˆå€¼: {config.DISCORD_SIMILARITY_THRESHOLD} ({config.DISCORD_SIMILARITY_THRESHOLD*100:.0f}%)")
        func_logger.info(f"å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®ä¸º: {config.GLOBAL_REPLY_MIN_DELAY}-{config.GLOBAL_REPLY_MAX_DELAY}ç§’")
        func_logger.info(f"Discordé¢‘é“ID: {discord_channel_id or 'æœªè®¾ç½®(ç›‘å¬æ‰€æœ‰é¢‘é“)'}")
    except Exception as e:
        func_logger.warning(f"åŠ è½½ç³»ç»Ÿé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")

def check_duplicate_image(new_features, existing_features_list, threshold=0.99):
    """
    æ£€æŸ¥æ–°å›¾ç‰‡çš„ç‰¹å¾å‘é‡æ˜¯å¦ä¸ç°æœ‰åˆ—è¡¨ä¸­çš„å›¾ç‰‡é‡å¤

    :param new_features: æ–°å›¾ç‰‡çš„ç‰¹å¾å‘é‡ (numpy array)
    :param existing_features_list: ç°æœ‰å›¾ç‰‡çš„ç‰¹å¾å‘é‡åˆ—è¡¨ (å¯ä»¥æ˜¯jsonå­—ç¬¦ä¸²åˆ—è¡¨æˆ–numpyåˆ—è¡¨)
    :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤99%
    :return: (is_duplicate, similarity_score)
    """
    if not existing_features_list:
        return False, 0.0

    try:
        # é¢„è®¡ç®—æ–°å‘é‡çš„èŒƒæ•°
        norm_new = np.linalg.norm(new_features)
        if norm_new == 0:
            return False, 0.0

        for feat_item in existing_features_list:
            try:
                # å¤„ç†è¾“å…¥å¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ–å·²ç»æ˜¯ numpy æ•°ç»„çš„æƒ…å†µ
                if isinstance(feat_item, str):
                    feat_vec = np.array(json.loads(feat_item), dtype='float32')
                else:
                    feat_vec = np.array(feat_item, dtype='float32')

                norm_existing = np.linalg.norm(feat_vec)
                if norm_existing == 0:
                    continue

                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                dot_product = np.dot(new_features, feat_vec)
                similarity = dot_product / (norm_new * norm_existing)

                if similarity > threshold:
                    return True, similarity

            except Exception:
                continue

    except Exception as e:
        logger.error(f"å‘é‡æ¯”å¯¹å‡ºé”™: {e}")

    return False, 0.0

def process_and_save_image_core(product_id, image_url_or_file, index, existing_features=None, save_faiss_immediately=True):
    """
    æ ¸å¿ƒå›¾ç‰‡å¤„ç†å•å…ƒï¼šä¿å­˜ -> ç‰¹å¾æå– -> æŸ¥é‡ -> æ•°æ®åº“ -> FAISS

    :param product_id: å•†å“ID
    :param image_url_or_file: æˆ–è€…æ˜¯ URL å­—ç¬¦ä¸²ï¼Œæˆ–è€…æ˜¯ Flask çš„ FileStorage å¯¹è±¡
    :param index: å›¾ç‰‡ç´¢å¼•
    :param existing_features: ç°æœ‰ç‰¹å¾å‘é‡åˆ—è¡¨ï¼Œç”¨äºæŸ¥é‡
    :param save_faiss_immediately: æ˜¯å¦ç«‹å³ä¿å­˜FAISSç´¢å¼•ï¼ˆå•å¼ ä¸Šä¼ æ—¶ä¸ºTrueï¼Œæ‰¹é‡å¤„ç†æ—¶ä¸ºFalseï¼‰
    :return: å¤„ç†ç»“æœå­—å…¸
    """
    import os
    import time

    # 1. ç¡®å®šä¿å­˜è·¯å¾„ï¼ˆä½¿ç”¨é…ç½®çš„ç›®å½•ï¼‰
    timestamp = int(time.time() * 1000000)
    filename = f"{product_id}_{index}_{timestamp}.jpg"
    save_path = os.path.join(config.IMAGE_SAVE_DIR, str(product_id), filename)
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    img_db_id = None  # åˆå§‹åŒ–æ•°æ®åº“ ID

    try:
        # 2. ä¿å­˜æ–‡ä»¶
        if hasattr(image_url_or_file, 'save'):
            # æ˜¯ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ (FileStorage)
            image_url_or_file.save(save_path)
        else:
            # æ˜¯ URL å­—ç¬¦ä¸²
            import requests
            resp = requests.get(image_url_or_file, timeout=config.REQUEST_TIMEOUT, proxies={'http': None, 'https': None})
            if resp.status_code != 200:
                return {'success': False, 'error': f'Download failed: {resp.status_code}'}
            with open(save_path, 'wb') as f:
                f.write(resp.content)

        # éªŒè¯æ–‡ä»¶å¤§å°
        if os.path.getsize(save_path) == 0:
            os.remove(save_path)
            return {'success': False, 'error': 'Empty file'}

        # 3. ç‰¹å¾æå– (DINOv2 + YOLO)
        extractor = get_global_feature_extractor()
        if extractor is None:
            os.remove(save_path)
            return {'success': False, 'error': 'Feature extractor not initialized'}

        features = extractor.extract_feature(save_path)
        if features is None:
            os.remove(save_path)
            return {'success': False, 'error': 'Feature extraction failed'}

        # 4. æŸ¥é‡é€»è¾‘ (99.5%ç›¸ä¼¼åº¦)
        if existing_features:
            is_dup, score = check_duplicate_image(features, existing_features, threshold=0.995)
            if is_dup:
                os.remove(save_path)
                logger.info(f"ğŸš« å›¾ç‰‡é«˜åº¦ç›¸ä¼¼ (ç›¸ä¼¼åº¦: {score:.4f})ï¼Œå·²è·³è¿‡: {filename}")
                return {'success': True, 'skipped': True}  # æ ‡è®°ä¸ºæˆåŠŸä½†è·³è¿‡ï¼Œä»¥å…æŠ¥é”™

        # 5. å…¥åº“ (SQLite)
        img_db_id = db.insert_image_record(product_id, save_path, index, features)

        # 6. å…¥åº“ (FAISS)
        try:
            from vector_engine import get_vector_engine
            engine = get_vector_engine()

            # === FAISS çº¿ç¨‹å®‰å…¨é” ===
            with faiss_lock:  # åŠ é”ï¼Œç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªçº¿ç¨‹å†™å…¥ FAISS
                engine.add_vector(img_db_id, features)
                # æ€§èƒ½ä¼˜åŒ–ï¼šå•å¼ ä¸Šä¼ æ—¶ç«‹å³ä¿å­˜ï¼Œæ‰¹é‡å¤„ç†æ—¶å»¶è¿Ÿä¿å­˜
                if save_faiss_immediately:
                    engine.save()
        except Exception as faiss_err:
            logger.error(f"FAISS å…¥åº“å¤±è´¥: {faiss_err}")
            # FAISSå¤±è´¥æ—¶åˆ é™¤æ•°æ®åº“è®°å½•å’Œæ–‡ä»¶ï¼Œå›æ»šæ“ä½œ
            try:
                db.delete_image_record(img_db_id)
            except:
                pass
            if os.path.exists(save_path):
                os.remove(save_path)
            return {'success': False, 'error': f'FAISS error: {faiss_err}'}

        # 7. æ›´æ–°å¯¹æ¯”åˆ—è¡¨ï¼Œç¡®ä¿ä¸‹ä¸€å¼ å›¾èƒ½è·Ÿè¿™å¼ æ¯”
        if existing_features is not None:
            existing_features.append(features)  # å…³é”®ï¼šå®æ—¶åŠ å…¥åˆ—è¡¨

        # 8. å®Œæˆ
        return {
            'success': True,
            'image_path': save_path,
            'features': features,
            'index': index,
            'filename': filename,
            'db_id': img_db_id
        }

    except Exception as e:
        logger.error(f'å›¾ç‰‡å¤„ç†æ€»å‡ºé”™ï¼Œå°è¯•æ¸…ç†: {e}')
        if os.path.exists(save_path):
            os.remove(save_path)
        # å¦‚æœå·²ç»æ’å…¥æ•°æ®åº“ä½†åç»­å¤±è´¥ï¼Œéœ€è¦å›æ»š
        if img_db_id:
            try:
                db.delete_image_record(img_db_id)
            except:
                pass
        return {'success': False, 'error': str(e)}

# çº¿ç¨‹é…ç½®ç°åœ¨ç»Ÿä¸€åœ¨ config.py ä¸­ç®¡ç†

# åŠ è½½ç³»ç»Ÿé…ç½®
load_system_config()

# === é‡æ„ï¼šåº—é“ºæŠ“å–çŠ¶æ€æ§åˆ¶ ===
# ç§»é™¤å…¨å±€çŠ¶æ€å˜é‡ï¼Œæ”¹ä¸ºæ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨
# scrape_statusç°åœ¨é€šè¿‡db.get_scrape_status()å’Œdb.update_scrape_status()ç®¡ç†

# çº¿ç¨‹ç®¡ç†ï¼šè·Ÿè¸ªå½“å‰è¿è¡Œçš„æŠ“å–çº¿ç¨‹
current_scrape_thread = None
scrape_thread_lock = threading.Lock()
scrape_stop_event = threading.Event()  # æŠ“å–åœæ­¢äº‹ä»¶ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡

# FAISS çº¿ç¨‹å®‰å…¨é”ï¼šé˜²æ­¢å¤šçº¿ç¨‹åŒæ—¶å†™å…¥å‘é‡ç´¢å¼•å¯¼è‡´å´©æºƒ
faiss_lock = Lock()

# å…¨å±€å…³é—­äº‹ä»¶ï¼Œç”¨äºä¼˜é›…å…³é—­
shutdown_event = None

# é…ç½®æ—¥å¿—
# 1. è·å–æ ¹æ—¥å¿—è®°å½•å™¨
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)

# 2. æ¸…é™¤ç°æœ‰çš„æ‰€æœ‰å¤„ç†å™¨ï¼ˆé˜²æ­¢ Flask æˆ– basicConfig è‡ªåŠ¨æ·»åŠ çš„å¯¼è‡´é‡å¤ï¼‰
if root_logger.handlers:
    root_logger.handlers = []

# 3. åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)
root_logger.addHandler(console_handler)

# 4. åˆ›å»ºé˜Ÿåˆ—æ—¥å¿—å¤„ç†å™¨ (ç”¨äºå‰ç«¯ SSE)
log_queue = queue.Queue()
log_clients = []
all_logs = []

class QueueHandler(logging.Handler):
    """è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œå°†æ—¥å¿—å‘é€åˆ°é˜Ÿåˆ—"""
    def emit(self, record):
        try:
            # è¿‡æ»¤æ‰HTTPè¯·æ±‚æ—¥å¿—å’Œä¸é‡è¦çš„ç³»ç»Ÿæ—¥å¿—
            if self._should_filter_log(record):
                return

            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'level': record.levelname,
                'message': self.format(record),
                'module': record.module,
                'func': record.funcName
            }

            # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨ï¼ˆé™åˆ¶å¤§å°ï¼‰
            all_logs.append(log_entry)
            if len(all_logs) > 200:  # æœ€å¤šä¿å­˜200æ¡æ—¥å¿—
                all_logs.pop(0)

            log_queue.put(log_entry)

            # é€šçŸ¥æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
            for client_queue in log_clients[:]:  # å¤åˆ¶åˆ—è¡¨ä»¥é¿å…ä¿®æ”¹æ—¶çš„é—®é¢˜
                try:
                    client_queue.put(log_entry)
                except:
                    # å¦‚æœå®¢æˆ·ç«¯é˜Ÿåˆ—å·²æ»¡æˆ–æ–­å¼€ï¼Œç§»é™¤å®ƒ
                    if client_queue in log_clients:
                        log_clients.remove(client_queue)
        except Exception as e:
            print(f"æ—¥å¿—é˜Ÿåˆ—é”™è¯¯: {e}")

    def _should_filter_log(self, record):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰è¿™æ¡æ—¥å¿—"""
        # è¿‡æ»¤Werkzeugçš„HTTPè¯·æ±‚æ—¥å¿—
        if record.module == '_internal':
            return True

        # è¿‡æ»¤åŒ…å«HTTPè¯·æ±‚æ¨¡å¼çš„æ—¥å¿—
        message = self.format(record)
        if any(pattern in message for pattern in [
            '"GET ', '"POST ', '"PUT ', '"DELETE ',
            'HTTP/1.1"', 'HTTP/1.0"',
            'werkzeug',
            '127.0.0.1 - -',  # è¿‡æ»¤è®¿é—®æ—¥å¿—
        ]):
            return True

        # è¿‡æ»¤ä¸€äº›ä¸é‡è¦çš„ç³»ç»Ÿæ—¥å¿—
        if record.module in ['urllib3', 'requests', 'aiohttp']:
            return True

        # 2. å…³é”®ä¿®å¤ï¼šå…è®¸ weidian_scraper å’Œ app çš„ INFO æ—¥å¿—é€šè¿‡
        # åªè¦æ˜¯è¿™äº›æ¨¡å—ï¼Œå³ä½¿æ˜¯ INFO çº§åˆ«ä¹Ÿå…è®¸é€šè¿‡
        whitelist_modules = [
            '__main__', 'app', 'database', 'bot',
            'weidian_scraper', 'feature_extractor',
            'vector_engine', 'migrate_data'
        ]

        if record.module in whitelist_modules:
            return False

        # å¯¹äºå…¶ä»–æœªçŸ¥æ¨¡å—ï¼Œåªæ˜¾ç¤ºWARNINGçº§åˆ«ä»¥ä¸Š
        if record.levelno < logging.WARNING:
            return True

        return False

# 5. æ·»åŠ é˜Ÿåˆ—å¤„ç†å™¨
queue_handler = QueueHandler()
queue_handler.setLevel(logging.INFO)
root_logger.addHandler(queue_handler)

# æ§åˆ¶å°å¤„ç†å™¨å·²åœ¨ä¸Šé¢é…ç½®å®Œæˆ

# 1. è®¾ç½® werkzeug æ—¥å¿—çº§åˆ«ä¸º WARNINGï¼Œå±è”½ HTTP è¯·æ±‚åˆ·å±
logging.getLogger('werkzeug').setLevel(logging.WARNING)
# 2. è®¾ç½®å…¶ä»–åº“çš„æ—¥å¿—çº§åˆ«
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('requests').setLevel(logging.WARNING)
logging.getLogger('aiohttp').setLevel(logging.WARNING)
logging.getLogger('ultralytics').setLevel(logging.WARNING)  # å±è”½ YOLO æ—¥å¿—

logger = logging.getLogger(__name__)

# æœºå™¨äººç›¸å…³å˜é‡
bot_clients = []
bot_tasks = []
bot_running = False  # æ ‡è®°æœºå™¨äººæ˜¯å¦æ­£åœ¨è¿è¡Œ

# å…¨å±€ç‰¹å¾æå–å™¨å®ä¾‹ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºï¼‰
feature_extractor_instance = None

def initialize_feature_extractor():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–ç‰¹å¾æå–å™¨ï¼Œç¡®ä¿å•ä¾‹æ¨¡å¼"""
    global feature_extractor_instance
    if feature_extractor_instance is None:
        print("ğŸš€ åˆå§‹åŒ–å…¨å±€ç‰¹å¾æå–å™¨å®ä¾‹...")
        try:
            from feature_extractor import DINOv2FeatureExtractor
            feature_extractor_instance = DINOv2FeatureExtractor()
            print("âœ… å…¨å±€ç‰¹å¾æå–å™¨å®ä¾‹åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            feature_extractor_instance = None
    return feature_extractor_instance

def get_global_feature_extractor():
    """è·å–å…¨å±€ç‰¹å¾æå–å™¨å®ä¾‹"""
    global feature_extractor_instance
    if feature_extractor_instance is None:
        return initialize_feature_extractor()
    return feature_extractor_instance

# åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–
initialize_feature_extractor()

# Flaské…ç½®åˆå§‹åŒ–ï¼ˆç®€åŒ–ç‰ˆ - è§£å†³HTTP IPè®¿é—®é—®é¢˜ï¼‰
app = Flask(__name__)
app.secret_key = config.SECRET_KEY

# CORS é…ç½®ï¼ˆå…è®¸æ‰€æœ‰æ¥æºï¼‰
CORS(app, origins=config.CORS_ORIGINS, supports_credentials=True)

# å¼ºåˆ¶æ›´æ–°é…ç½®ï¼Œè¦†ç›–é»˜è®¤çš„å®‰å…¨è®¾ç½®
app.config.update(
    SECRET_KEY=config.SECRET_KEY,
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE=config.SESSION_COOKIE_SAMESITE,
    SESSION_COOKIE_SECURE=config.SESSION_COOKIE_SECURE,  # ç¡®ä¿æ˜¯False
    SESSION_COOKIE_DOMAIN=None,
    PERMANENT_SESSION_LIFETIME=config.SESSION_LIFETIME,  # 30å¤©ä¸è¿‡æœŸ
)

def extract_features(image_path):
    """ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æå–å›¾åƒç‰¹å¾"""
    try:
        extractor = get_global_feature_extractor()
        if extractor is None:
            logger.error("ç‰¹å¾æå–å™¨æœªåˆå§‹åŒ–")
            return None
        features = extractor.extract_feature(image_path)
        # å¦‚æœç‰¹å¾æå–å¤±è´¥ï¼Œè¿”å› Noneï¼ˆä¸Šå±‚å°†å¤„ç†å¹¶è¿”å›é”™è¯¯ï¼‰
        if features is None:
            logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {image_path}")
            return None

        return features

    except Exception as e:
        logger.error(f"ç‰¹å¾æå–å¼‚å¸¸: {e}")
        return None

@app.route('/search_similar', methods=['POST'])
def search_similar():
    """æœç´¢ç›¸ä¼¼å›¾åƒ - ä½¿ç”¨ FAISS HNSW"""
    try:
        image_url = request.form.get('image_url')
        threshold = float(request.form.get('threshold', 0.6))  # DINOv2éœ€è¦æ›´é«˜çš„é˜ˆå€¼
        limit = int(request.form.get('limit', 5))  # è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª

        # è·å–ç”¨æˆ·åº—é“ºæƒé™è¿‡æ»¤ï¼ˆç”¨äºDiscordæœºå™¨äººï¼‰
        user_shops = None
        user_shops_json = request.form.get('user_shops')
        if user_shops_json:
            try:
                user_shops = json.loads(user_shops_json)
            except:
                user_shops = None

        # è°ƒè¯•ä¿¡æ¯
        print(f"DEBUG: Received threshold: {threshold}")
        print(f"DEBUG: User shops filter: {user_shops}")
        print(f"DEBUG: Form data: {list(request.form.keys())}")
        print(f"DEBUG: Files: {list(request.files.keys()) if request.files else 'No files'}")
        print(f"DEBUG: Content-Type: {request.content_type}")
        print(f"DEBUG: Method: {request.method}")
        print(f"DEBUG: image_url parameter: '{image_url}'")

        # å¤„ç†å›¾ç‰‡æ¥æº
        import uuid
        import os
        if image_url:
            print(f"DEBUG: Processing image URL: {image_url}")
            # éªŒè¯URLæ ¼å¼
            if not image_url.startswith(('http://', 'https://')):
                return jsonify({'error': 'Invalid URL format, must start with http:// or https://'}), 400

            # ä»URLä¸‹è½½å›¾ç‰‡
            import requests
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                response = requests.get(image_url, timeout=15, headers=headers, stream=True)
                print(f"DEBUG: URL response status: {response.status_code}")
                print(f"DEBUG: Content-Type: {response.headers.get('content-type', 'unknown')}")

                if response.status_code != 200:
                    return jsonify({'error': f'Failed to download image from URL, status: {response.status_code}'}), 400

                # æ£€æŸ¥å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '').lower()
                if not any(img_type in content_type for img_type in ['image/', 'application/octet-stream']):
                    print(f"DEBUG: Warning - Content-Type '{content_type}' may not be an image")

                temp_filename = f"{uuid.uuid4()}.jpg"
                image_path = f"/tmp/{temp_filename}"

                with open(image_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)

                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(image_path)
                print(f"DEBUG: Image downloaded to: {image_path}, size: {file_size} bytes")

                if file_size == 0:
                    os.remove(image_path)
                    return jsonify({'error': 'Downloaded file is empty'}), 400

                if file_size > 10 * 1024 * 1024:  # 10MB limit
                    os.remove(image_path)
                    return jsonify({'error': 'Image file too large (max 10MB)'}), 400

            except requests.exceptions.RequestException as e:
                print(f"DEBUG: Network error downloading image: {str(e)}")
                return jsonify({'error': f'Network error downloading image: {str(e)}'}), 400
            except Exception as e:
                print(f"DEBUG: Failed to download image: {str(e)}")
                return jsonify({'error': f'Failed to download image: {str(e)}'}), 400
        else:
            print("DEBUG: No image_url provided, checking for uploaded file")
            # ä»ä¸Šä¼ çš„æ–‡ä»¶è·å–å›¾ç‰‡
            if 'image' not in request.files:
                print("DEBUG: No 'image' file found in request.files")
                return jsonify({'error': 'No image provided'}), 400

            image_file = request.files['image']
            print(f"DEBUG: Found uploaded file: {image_file.filename if image_file else 'None'}")
        temp_filename = f"{uuid.uuid4()}.jpg"
        image_path = f"/tmp/{temp_filename}"
        image_file.save(image_path)

        try:
            # æå–ç‰¹å¾ (ä½¿ç”¨ DINOv2 + YOLOv8)
            query_features = extract_features(image_path)

            if query_features is None:
                return jsonify({'error': 'Feature extraction failed'}), 500

            # ä½¿ç”¨ FAISS HNSW å‘é‡æœç´¢
            print(f"DEBUG: Searching with threshold: {threshold}, vector length: {len(query_features)}")
            # ç”¨è¾ƒä½çš„é˜ˆå€¼æœç´¢æ‰¾åˆ°å€™é€‰ç»“æœï¼Œç„¶åä»ä¸­ç­›é€‰æ»¡è¶³ç”¨æˆ·é˜ˆå€¼çš„ç»“æœ
            low_threshold_results = db.search_similar_images(query_features, limit=10, threshold=0.1)
            print(f"DEBUG: Low threshold (0.1) search results: {len(low_threshold_results) if low_threshold_results else 0}")

            # ä»ä½é˜ˆå€¼ç»“æœä¸­ç­›é€‰å‡ºæ»¡è¶³ç”¨æˆ·é˜ˆå€¼çš„ç»“æœ
            results = []
            if low_threshold_results:
                for result in low_threshold_results:
                    similarity = result.get('similarity', 0)
                    # åº”ç”¨ç”¨æˆ·ç›¸ä¼¼åº¦é˜ˆå€¼å’Œåº—é“ºè¿‡æ»¤
                    if similarity >= threshold:
                        # æ£€æŸ¥åº—é“ºæƒé™
                        if user_shops and result.get('shop_name') not in user_shops:
                            print(f"DEBUG: Skipping result from shop {result.get('shop_name')} - not in user shops {user_shops}")
                            continue
                        results.append(result)
                        if len(results) >= limit:
                            break

            print(f"DEBUG: Filtered results count (threshold {threshold}): {len(results)}")
            if results:
                print(f"DEBUG: Best match similarity: {results[0]['similarity']}")
            elif low_threshold_results:
                print(f"DEBUG: Best low-threshold match similarity: {low_threshold_results[0]['similarity']}")
            print(f"DEBUG: Total indexed images: {db.get_total_indexed_images()}")

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ»¡è¶³é˜ˆå€¼çš„ç»“æœï¼Œä½†æœ‰é«˜è´¨é‡çš„ä½é˜ˆå€¼åŒ¹é…ï¼ˆç›¸ä¼¼åº¦>0.8ï¼‰ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨
            if not results and low_threshold_results and len(low_threshold_results) > 0:
                best_low_match = low_threshold_results[0]
                if best_low_match.get('similarity', 0) > 0.8:  # é«˜è´¨é‡åŒ¹é…
                    print(f"DEBUG: Using high-quality low-threshold result (similarity: {best_low_match['similarity']:.4f})")
                    results = [best_low_match]

            response_data = {
                'success': True,
                'results': [],
                'totalResults': 0,
                'message': f'æœªæ‰¾åˆ°ç›¸ä¼¼åº¦è¶…è¿‡{threshold*100:.0f}%çš„å•†å“',
                'searchTime': datetime.now().isoformat(),
                'debugInfo': {
                    'totalIndexedImages': db.get_total_indexed_images(),
                    'threshold': threshold,
                    'searchedVectors': len(results) if results else 0
                }
            }

            if results:
                # å¤„ç†å¤šä¸ªæœç´¢ç»“æœ
                processed_results = []
                for i, result in enumerate(results):
                    # è·å–å®Œæ•´äº§å“ä¿¡æ¯
                    product_info = db._get_product_info_by_id(result['id'])

                    # è·å–å®é™…çš„å›¾ç‰‡URLåˆ—è¡¨
                    actual_images = []
                    if product_info:
                        with db.get_connection() as conn:
                            cursor = conn.cursor()
                            cursor.execute("SELECT image_index FROM product_images WHERE product_id = ? ORDER BY image_index", (result['id'],))
                            actual_images = [f"/api/image/{result['id']}/{row[0]}" for row in cursor.fetchall()]

                    # ç”Ÿæˆæ‰€æœ‰ç½‘ç«™çš„é“¾æ¥
                    weidian_id = None
                    if product_info and product_info.get('product_url'):
                        import re
                        match = re.search(r'itemID=(\d+)', product_info['product_url'])
                        if match:
                            weidian_id = match.group(1)

                    website_urls = []
                    if weidian_id:
                        website_urls = db.generate_website_urls(weidian_id)

                    result_data = {
                        'rank': i + 1,
                        'similarity': float(result['similarity']),
                        'imageIndex': result['image_index'],
                        'matchedImage': f"/api/image/{result['id']}/{result['image_index']}",
                        'product': {
                            'id': result['id'],
                            'title': product_info['title'] if product_info else result.get('title', ''),
                            'englishTitle': product_info.get('english_title', ''),
                            'weidianUrl': product_info['product_url'] if product_info else result.get('product_url', ''),
                            'cnfansUrl': product_info.get('cnfans_url', ''),
                            'acbuyUrl': product_info.get('acbuy_url', ''),
                            'ruleEnabled': product_info.get('ruleEnabled', True) if product_info else True,
                            'images': actual_images if actual_images else [f"/api/image/{result['id']}/{result['image_index']}"],  # ä½¿ç”¨å®é™…å›¾ç‰‡åˆ—è¡¨
                            'websiteUrls': website_urls  # æ·»åŠ æ‰€æœ‰ç½‘ç«™çš„é“¾æ¥
                        }
                    }
                    processed_results.append(result_data)

                # ä¿å­˜æœ€ä½³åŒ¹é…çš„æœç´¢å†å²
                if processed_results:
                    best_match = processed_results[0]
                    db.add_search_history(
                        query_image_path=image_path,
                        matched_product_id=best_match['product']['id'],
                        matched_image_index=best_match['imageIndex'],
                        similarity=best_match['similarity'],
                        threshold=threshold
                    )

                response_data = {
                    'success': True,
                    'results': processed_results,
                    'totalResults': len(processed_results),
                    'searchTime': datetime.now().isoformat(),
                    'debugInfo': {
                        'totalIndexedImages': db.get_total_indexed_images(),
                        'threshold': threshold,
                        'limit': limit,
                        'searchedVectors': len(results) if results else 0
                    }
                }

            return jsonify(response_data)

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(image_path):
                os.unlink(image_path)

    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/scrape', methods=['POST'])
def scrape_product():
    """æŠ“å–å•†å“å¹¶å»ºç«‹ç´¢å¼•"""
    try:
        logger.info("æ”¶åˆ°å•†å“æŠ“å–è¯·æ±‚")
        data = request.get_json()
        if data is None:
            logger.error("è¯·æ±‚ä½“ä¸ºç©º")
            return jsonify({'error': 'Invalid request body'}), 400

        logger.info(f"è¯·æ±‚æ•°æ®: {data}")

        # æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼ï¼šå®Œæ•´URLæˆ–å•†å“ID
        url = data.get('url')
        weidian_id = data.get('weidianId')

        if not url and not weidian_id:
            logger.error("ç¼ºå°‘URLæˆ–weidianId")
            return jsonify({'error': 'URL or weidianId is required'}), 400

        # å¦‚æœæä¾›äº†weidianIdï¼Œæ„é€ URL
        if weidian_id and not url:
            url = f"https://weidian.com/item.html?itemID={weidian_id}"
            logger.info(f"æ„é€ URL: {url}")

        # éªŒè¯URLæ ¼å¼
        if 'weidian.com' not in url:
            logger.error(f"ä¸æ”¯æŒçš„URLæ ¼å¼: {url}")
            return jsonify({'error': 'åªæ”¯æŒå¾®åº—å•†å“é“¾æ¥'}), 400

        logger.info(f"å¼€å§‹æŠ“å–å•†å“: {url}")

        # æ£€æŸ¥å•†å“æ˜¯å¦å·²å­˜åœ¨
        existing = db.get_product_by_url(url)
        if existing:
            return jsonify({'error': 'å•†å“å·²å­˜åœ¨', 'existing': True}), 409

        # ä½¿ç”¨çœŸæ­£çš„çˆ¬è™«
        from weidian_scraper import get_weidian_scraper
        scraper = get_weidian_scraper()

        # æŠ“å–å•†å“ä¿¡æ¯
        product_info = scraper.scrape_product_info(url)

        if not product_info:
            return jsonify({'error': 'å•†å“ä¿¡æ¯æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®'}), 500

        # ç”Ÿæˆacbuyé“¾æ¥
        acbuy_url = ''
        if product_info['weidian_url']:
            # ä»weidian_urlä¸­æå–itemID
            import re
            item_id_match = re.search(r'itemID=(\d+)', product_info['weidian_url'])
            if item_id_match:
                item_id = item_id_match.group(1)
                # æ„å»ºacbuyé“¾æ¥
                encoded_url = product_info['weidian_url'].replace(':', '%3A').replace('/', '%2F').replace('?', '%3F').replace('=', '%3D').replace('&', '%26')
                acbuy_url = f'https://www.acbuy.com/product?url={encoded_url}&id={item_id}&source=WD'

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨å…¨å±€å»¶è¿Ÿé…ç½®ï¼‰
        product_id = db.insert_product({
            'product_url': product_info['weidian_url'],
            'title': product_info['title'],
            'description': product_info['description'],
            'english_title': product_info.get('english_title') or '',
            'cnfans_url': product_info.get('cnfans_url') or '',
            'acbuy_url': acbuy_url,
            'shop_name': product_info.get('shop_name', ''),  # ä»product_infoè·å–åº—é“ºåç§°
            'ruleEnabled': True  # é»˜è®¤å¯ç”¨è‡ªåŠ¨å›å¤è§„åˆ™
        })

        # ä¸‹è½½å›¾ç‰‡å¹¶å»ºç«‹å‘é‡ç´¢å¼•
        if product_info['images']:
            logger.info(f"ä¸‹è½½ {len(product_info['images'])} å¼ å›¾ç‰‡å¹¶å»ºç«‹ç´¢å¼•")

            # åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•
            import os
            images_dir = os.path.join(os.path.dirname(__file__), 'data', 'scraped_images', product_info['id'])
            os.makedirs(images_dir, exist_ok=True)

            # ä¸‹è½½å›¾ç‰‡
            saved_image_paths = scraper.download_images(
                product_info['images'],
                images_dir,
                product_info['id']
            )
            # ä¸ºæ¯å¼ å›¾ç‰‡å»ºç«‹å‘é‡ç´¢å¼•
            # æ³¨æ„ï¼šYOLOè£å‰ªå·²é›†æˆåœ¨DINOv2ç‰¹å¾æå–è¿‡ç¨‹ä¸­ï¼Œæ— éœ€é¢å¤–æ­¥éª¤
            # ä½¿ç”¨å…¨å±€ç‰¹å¾æå–å™¨
            extractor = get_global_feature_extractor()
            if extractor is None:
                logger.error("ç‰¹å¾æå–å™¨æœªåˆå§‹åŒ–")
                return

            # ä¸²è¡Œå»ºç«‹å‘é‡ç´¢å¼• (SQLiteä¸æ”¯æŒå¤šçº¿ç¨‹å†™å…¥)
            # ä½†å…ˆä½¿ç”¨å¤šçº¿ç¨‹è¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åä¸²è¡Œæ’å…¥æ•°æ®åº“
            import concurrent.futures
            try:
                from vector_engine import get_vector_engine
            except ImportError:
                from .vector_engine import get_vector_engine
            engine = get_vector_engine()

            def extract_features_only(img_path):
                """åªæå–ç‰¹å¾ï¼Œä¸æ’å…¥æ•°æ®åº“"""
                try:
                    features = extractor.extract_feature(img_path)
                    return features
                except Exception as e:
                    logger.error(f"ç‰¹å¾æå–å¤±è´¥ {img_path}: {e}")
                    return None

            # ç¬¬ä¸€æ­¥ï¼šå¤šçº¿ç¨‹ç‰¹å¾æå–
            logger.info("å¼€å§‹å¤šçº¿ç¨‹ç‰¹å¾æå–...")
            features_list = []
            max_workers = min(config.FEATURE_EXTRACT_THREADS, len(saved_image_paths))

            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ç‰¹å¾æå–ä»»åŠ¡
                future_to_image = {
                    executor.submit(extract_features_only, img_path): (i, img_path)
                    for i, img_path in enumerate(saved_image_paths)
                }

                # æ”¶é›†ç‰¹å¾æå–ç»“æœ
                for future in concurrent.futures.as_completed(future_to_image):
                    i, img_path = future_to_image[future]
                    try:
                        features = future.result()
                        features_list.append((i, img_path, features))
                    except Exception as e:
                        logger.error(f"ç‰¹å¾æå–å¼‚å¸¸ {img_path}: {e}")
                        features_list.append((i, img_path, None))

            # æŒ‰ç´¢å¼•æ’åºç»“æœ
            features_list.sort(key=lambda x: x[0])

            # ç¬¬äºŒæ­¥ï¼šä¸²è¡Œæ’å…¥æ•°æ®åº“å’ŒFAISSç´¢å¼•
            logger.info("å¼€å§‹ä¸²è¡Œæ•°æ®åº“æ’å…¥å’Œç´¢å¼•å»ºç«‹...")
            indexed_images = []

            for i, img_path, features in features_list:
                try:
                    if features is None:
                        logger.error(f"è·³è¿‡å›¾ç‰‡ {i}: ç‰¹å¾æå–å¤±è´¥")
                        continue

                    # æ’å…¥æ•°æ®åº“è®°å½•
                    image_db_id = db.insert_image_record(product_id, img_path, i)
                    if not image_db_id:
                        logger.error(f"å›¾ç‰‡ {i} å…ƒæ•°æ®æ’å…¥å¤±è´¥")
                        continue

                    # æ’å…¥FAISSå‘é‡ç´¢å¼•
                    with faiss_lock:  # FAISS çº¿ç¨‹å®‰å…¨é”
                        success = engine.add_vector(image_db_id, features)
                    if success:
                        indexed_images.append(f"{i}.jpg")
                        logger.info(f"å›¾ç‰‡ {i} ç´¢å¼•å»ºç«‹æˆåŠŸ")
                    else:
                        logger.error(f"å›¾ç‰‡ {i} ç´¢å¼•å»ºç«‹å¤±è´¥")

                except Exception as e:
                    logger.error(f"å¤„ç†å›¾ç‰‡ {i} æ—¶å‡ºé”™: {e}")
                    continue

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡å¤„ç†å¤±è´¥
            if len(indexed_images) != len(saved_image_paths):
                failed_count = len(saved_image_paths) - len(indexed_images)
                logger.warning(f"æœ‰ {failed_count} å¼ å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")

            # å¦‚æœä¸€å¼ å›¾ç‰‡éƒ½æ²¡æˆåŠŸï¼Œè®¤ä¸ºæ˜¯é”™è¯¯
            if not indexed_images:
                logger.error("æ‰€æœ‰å›¾ç‰‡å¤„ç†éƒ½å¤±è´¥äº†")
                try:
                    db.delete_product_images(product_id)
                except Exception as del_e:
                    logger.error(f"å›æ»šåˆ é™¤å¤±è´¥: {del_e}")
                return jsonify({'error': 'All image processing failed'}), 500

            # å®æ—¶ä¿å­˜FAISSç´¢å¼•
            engine.save()

            logger.info(f"å…±å»ºç«‹ {len(indexed_images)} å¼ å›¾ç‰‡çš„ç´¢å¼•")
        else:
            logger.warning("æœªæ‰¾åˆ°å•†å“å›¾ç‰‡")

        # è¿”å›å®Œæ•´çš„å•†å“ä¿¡æ¯
        result = {
            'id': product_id,
            'weidianId': product_info['id'],  # æ·»åŠ å¾®åº—å•†å“ID
            'product_url': product_info['weidian_url'],
            'title': product_info['title'],
            'englishTitle': product_info['english_title'],
            'weidianUrl': product_info['weidian_url'],
            'cnfansUrl': product_info['cnfans_url'],
            'description': product_info['description'],
            'ruleEnabled': True,  # é»˜è®¤å¯ç”¨è§„åˆ™
            'createdAt': datetime.now().isoformat(),
            'images': product_info['images']  # è¿”å›å›¾ç‰‡URLåˆ—è¡¨
        }

        logger.info(f"å•†å“æŠ“å–å®Œæˆ: {product_info['title']}")
        return jsonify(result)

    except Exception as e:
        logger.error(f"æŠ“å–å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# Discord è´¦å·ç®¡ç† API
# ===== ç”¨æˆ·è®¤è¯å’Œæƒé™ç®¡ç†API =====

def get_current_user():
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·"""
    user_id = session.get('user_id')
    if user_id:
        return db.get_user_by_id(user_id)
    return None

def require_admin():
    """æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜"""
    user = get_current_user()
    return user and user.get('role') == 'admin'

def can_manage_shops():
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰ç®¡ç†åº—é“ºçš„æƒé™ï¼ˆç®¡ç†å‘˜æˆ–æœ‰åˆ†é…çš„åº—é“ºï¼‰"""
    user = get_current_user()
    if not user:
        return False
    # ç®¡ç†å‘˜å¯ä»¥ç®¡ç†æ‰€æœ‰åº—é“º
    if user.get('role') == 'admin':
        return True
    # æ™®é€šç”¨æˆ·å¦‚æœæœ‰åˆ†é…çš„åº—é“ºï¼Œä¹Ÿå¯ä»¥ç®¡ç†
    user_shops = user.get('shops', [])
    return len(user_shops) > 0

def require_login():
    """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
    # å¼€å‘æ¨¡å¼ä¸‹è·³è¿‡è®¤è¯
    if config.DEBUG:
        # å¼€å‘æ¨¡å¼ä¸‹è‡ªåŠ¨è®¾ç½®ä¸ºadminç”¨æˆ·
        if 'user_id' not in session:
            session['user_id'] = 1  # é»˜è®¤adminç”¨æˆ·ID
        return True
    return get_current_user() is not None

@app.route('/api/auth/login', methods=['POST'])
def login():
    """ç”¨æˆ·ç™»å½•"""
    try:
        data = request.get_json()
        if not data or not data.get('username') or not data.get('password'):
            return jsonify({'error': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'}), 400

        username = data['username']
        password = data['password']

        user = db.authenticate_user(username, password)
        if user:
            session['user_id'] = user['id']
            # ä¸è¿”å›å¯†ç å“ˆå¸Œ
            user_info = {k: v for k, v in user.items() if k != 'password_hash'}
            return jsonify({'user': user_info, 'message': 'ç™»å½•æˆåŠŸ'})
        else:
            return jsonify({'error': 'ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯'}), 401
    except Exception as e:
        logger.error(f"ç™»å½•å¤±è´¥: {e}")
        return jsonify({'error': 'ç™»å½•å¤±è´¥'}), 500

@app.route('/api/auth/logout', methods=['POST'])
def logout():
    """ç”¨æˆ·ç™»å‡º"""
    session.pop('user_id', None)
    return jsonify({'message': 'å·²ç™»å‡º'})

@app.route('/api/auth/me', methods=['GET'])
def get_current_user_info():
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    user = get_current_user()
    if user:
        # ä¸è¿”å›å¯†ç å“ˆå¸Œ
        user_info = {k: v for k, v in user.items() if k != 'password_hash'}
        return jsonify({'user': user_info})
    return jsonify({'error': 'æœªç™»å½•'}), 401

@app.route('/api/users', methods=['GET'])
def get_users():
    """è·å–æ‰€æœ‰ç”¨æˆ·ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        users = db.get_all_users()
        # ä¸è¿”å›å¯†ç å“ˆå¸Œ
        for user in users:
            user.pop('password_hash', None)
        return jsonify({'users': users})
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/users', methods=['POST'])
def create_user():
    """åˆ›å»ºæ–°ç”¨æˆ·ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        if not data or not data.get('username') or not data.get('password'):
            return jsonify({'error': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'}), 400

        username = data['username']
        password = data['password']
        role = data.get('role', 'user')
        shop_ids = data.get('shops', [])

        # åˆ›å»ºç”¨æˆ·
        password_hash = f"hashed_{password}"
        if db.create_user(username, password_hash, role):
            # è·å–æ–°åˆ›å»ºçš„ç”¨æˆ·ID
            user = db.authenticate_user(username, password_hash)
            if user:
                # è®¾ç½®åº—é“ºæƒé™
                if shop_ids:
                    db.update_user_shops(user['id'], shop_ids)

                user_info = {k: v for k, v in user.items() if k != 'password_hash'}
                return jsonify({'user': user_info, 'message': 'ç”¨æˆ·åˆ›å»ºæˆåŠŸ'})
            else:
                return jsonify({'error': 'ç”¨æˆ·åˆ›å»ºå¤±è´¥'}), 500
        else:
            return jsonify({'error': 'ç”¨æˆ·åå·²å­˜åœ¨æˆ–åˆ›å»ºå¤±è´¥'}), 400
    except Exception as e:
        logger.error(f"åˆ›å»ºç”¨æˆ·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/users/<int:user_id>', methods=['DELETE'])
def delete_user(user_id):
    """åˆ é™¤ç”¨æˆ·ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        current_user = get_current_user()
        if current_user['id'] == user_id:
            return jsonify({'error': 'ä¸èƒ½åˆ é™¤è‡ªå·±çš„è´¦å·'}), 400

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
        user = db.get_user_by_id(user_id)
        if not user:
            return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        # åˆ é™¤ç”¨æˆ·
        if db.delete_user(user_id):
            logger.info(f"ç®¡ç†å‘˜ {current_user['username']} åˆ é™¤äº†ç”¨æˆ· {user['username']}")
            return jsonify({'message': 'ç”¨æˆ·åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'ç”¨æˆ·åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šç®¡ç†å‘˜ä¿®æ”¹ç”¨æˆ·å¯†ç  ===
@app.route('/api/users/<int:user_id>/password', methods=['PUT'])
def reset_user_password(user_id):
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        new_password = data.get('password')
        if not new_password:
            return jsonify({'error': 'å¯†ç ä¸èƒ½ä¸ºç©º'}), 400

        # ç®€å•å“ˆå¸Œ (ç”Ÿäº§ç¯å¢ƒè¯·ç”¨ bcrypt)
        password_hash = f"hashed_{new_password}"

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("UPDATE users SET password_hash = ? WHERE id = ?", (password_hash, user_id))
            conn.commit()

        return jsonify({'success': True, 'message': 'å¯†ç å·²é‡ç½®'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šç½‘ç«™é…ç½®ç®¡ç†API ===
@app.route('/api/websites', methods=['GET'])
def get_website_configs():
    """è·å–æ‰€æœ‰ç½‘ç«™é…ç½®åŠå…¶é¢‘é“ç»‘å®šå’Œè´¦å·ç»‘å®š"""
    try:
        configs = db.get_website_configs()

        # ä¸ºæ¯ä¸ªé…ç½®æ·»åŠ è´¦å·ç»‘å®šä¿¡æ¯
        for config in configs:
            config_id = config['id']
            config['accounts'] = db.get_website_account_bindings(config_id)

        return jsonify({'websites': configs})
    except Exception as e:
        logger.error(f"è·å–ç½‘ç«™é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites', methods=['POST'])
def add_website_config():
    """æ·»åŠ ç½‘ç«™é…ç½®"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        name = data.get('name')
        display_name = data.get('display_name')
        url_template = data.get('url_template')
        id_pattern = data.get('id_pattern')
        badge_color = data.get('badge_color', 'blue')

        if not all([name, display_name, url_template, id_pattern]):
            return jsonify({'error': 'æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.add_website_config(name, display_name, url_template, id_pattern, badge_color):
            return jsonify({'success': True, 'message': 'ç½‘ç«™é…ç½®å·²æ·»åŠ '})
        else:
            return jsonify({'error': 'æ·»åŠ å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ·»åŠ ç½‘ç«™é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>', methods=['PUT'])
def update_website_config(config_id):
    """æ›´æ–°ç½‘ç«™é…ç½®"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        name = data.get('name')
        display_name = data.get('display_name')
        url_template = data.get('url_template')
        id_pattern = data.get('id_pattern')
        badge_color = data.get('badge_color', 'blue')

        if not all([name, display_name, url_template, id_pattern]):
            return jsonify({'error': 'æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.update_website_config(config_id, name, display_name, url_template, id_pattern, badge_color):
            return jsonify({'success': True, 'message': 'ç½‘ç«™é…ç½®å·²æ›´æ–°'})
        else:
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°ç½‘ç«™é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>', methods=['DELETE'])
def delete_website_config(config_id):
    """åˆ é™¤ç½‘ç«™é…ç½®"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        if db.delete_website_config(config_id):
            return jsonify({'success': True, 'message': 'ç½‘ç«™é…ç½®å·²åˆ é™¤'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤ç½‘ç«™é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/channels', methods=['GET'])
def get_website_channels(config_id):
    """è·å–ç½‘ç«™ç»‘å®šçš„é¢‘é“"""
    try:
        channels = db.get_website_channel_bindings(config_id)
        return jsonify({'channels': channels})
    except Exception as e:
        logger.error(f"è·å–ç½‘ç«™é¢‘é“å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/channels', methods=['POST'])
def add_website_channel(config_id):
    """æ·»åŠ ç½‘ç«™é¢‘é“ç»‘å®š"""
    try:
        data = request.get_json()
        channel_id = data.get('channel_id')

        if not channel_id:
            return jsonify({'error': 'é¢‘é“IDä¸èƒ½ä¸ºç©º'}), 400

        if db.add_website_channel_binding(config_id, channel_id):
            return jsonify({'success': True, 'message': 'é¢‘é“ç»‘å®šå·²æ·»åŠ '})
        else:
            return jsonify({'error': 'æ·»åŠ å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ·»åŠ ç½‘ç«™é¢‘é“ç»‘å®šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/channels/<channel_id>', methods=['DELETE'])
def remove_website_channel(config_id, channel_id):
    """ç§»é™¤ç½‘ç«™é¢‘é“ç»‘å®š"""
    try:
        if db.remove_website_channel_binding(config_id, channel_id):
            return jsonify({'success': True, 'message': 'é¢‘é“ç»‘å®šå·²ç§»é™¤'})
        else:
            return jsonify({'error': 'ç§»é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"ç§»é™¤ç½‘ç«™é¢‘é“ç»‘å®šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# ===== ç½‘ç«™è´¦å·ç»‘å®šAPI =====

@app.route('/api/websites/<int:config_id>/accounts', methods=['GET'])
def get_website_accounts(config_id):
    """è·å–ç½‘ç«™ç»‘å®šçš„è´¦å·"""
    try:
        accounts = db.get_website_account_bindings(config_id)
        return jsonify({'accounts': accounts})
    except Exception as e:
        logger.error(f"è·å–ç½‘ç«™è´¦å·ç»‘å®šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/accounts', methods=['POST'])
def add_website_account(config_id):
    """ä¸ºç½‘ç«™ç»‘å®šè´¦å·"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        account_id = data.get('account_id')
        role = data.get('role', 'both')  # 'listener', 'sender', 'both'

        if not account_id or role not in ['listener', 'sender', 'both']:
            return jsonify({'error': 'æ— æ•ˆçš„è´¦å·IDæˆ–è§’è‰²'}), 400

        if db.add_website_account_binding(config_id, account_id, role):
            return jsonify({'success': True, 'message': f'è´¦å·ç»‘å®šæˆåŠŸï¼Œè§’è‰²: {role}'})
        else:
            return jsonify({'error': 'ç»‘å®šå¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ·»åŠ ç½‘ç«™è´¦å·ç»‘å®šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/accounts/<int:account_id>', methods=['DELETE'])
def remove_website_account(config_id, account_id):
    """ç§»é™¤ç½‘ç«™è´¦å·ç»‘å®š"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        if db.remove_website_account_binding(config_id, account_id):
            return jsonify({'success': True, 'message': 'è´¦å·ç»‘å®šå·²ç§»é™¤'})
        else:
            return jsonify({'error': 'ç§»é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"ç§»é™¤ç½‘ç«™è´¦å·ç»‘å®šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/rotation', methods=['PUT'])
def update_website_rotation(config_id):
    """æ›´æ–°ç½‘ç«™è½®æ¢é…ç½®ï¼ˆé—´éš”å’Œå¯ç”¨çŠ¶æ€ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        updates = []
        messages = []

        # æ›´æ–°è½®æ¢é—´éš”
        if 'rotation_interval' in data:
            rotation_interval = data['rotation_interval']
        if rotation_interval <= 0:
            return jsonify({'error': 'è½®æ¢é—´éš”å¿…é¡»å¤§äº0ç§’'}), 400

            if db.update_website_config_rotation(config_id, rotation_interval):
                updates.append(True)
                messages.append(f'è½®æ¢é—´éš”å·²è®¾ç½®ä¸º {rotation_interval} ç§’')
            else:
                updates.append(False)

        # æ›´æ–°è½®æ¢å¯ç”¨çŠ¶æ€
        if 'rotation_enabled' in data:
            rotation_enabled = data['rotation_enabled']
            if rotation_enabled not in [0, 1]:
                return jsonify({'error': 'è½®æ¢å¯ç”¨çŠ¶æ€å¿…é¡»æ˜¯0æˆ–1'}), 400

            if db.update_website_config_rotation_enabled(config_id, rotation_enabled):
                updates.append(True)
                status_text = 'å¯ç”¨' if rotation_enabled else 'ç¦ç”¨'
                messages.append(f'è½®æ¢åŠŸèƒ½å·²{status_text}')
            else:
                updates.append(False)

        if all(updates):
            return jsonify({'success': True, 'message': '; '.join(messages)})
        else:
            return jsonify({'error': 'éƒ¨åˆ†æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°ç½‘ç«™è½®æ¢é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/filters', methods=['GET'])
def get_website_filters(config_id):
    """è·å–ç½‘ç«™çš„æ¶ˆæ¯è¿‡æ»¤æ¡ä»¶"""
    try:
        configs = db.get_website_configs()
        config = next((c for c in configs if c['id'] == config_id), None)
        if not config:
            return jsonify({'error': 'ç½‘ç«™é…ç½®ä¸å­˜åœ¨'}), 404

        import json
        filters = json.loads(config.get('message_filters', '[]'))
        return jsonify({'filters': filters})
    except Exception as e:
        logger.error(f"è·å–ç½‘ç«™è¿‡æ»¤æ¡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/websites/<int:config_id>/filters', methods=['PUT'])
def update_website_filters(config_id):
    """æ›´æ–°ç½‘ç«™çš„æ¶ˆæ¯è¿‡æ»¤æ¡ä»¶"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        filters = data.get('filters', [])

        # éªŒè¯è¿‡æ»¤æ¡ä»¶æ ¼å¼
        for filter_item in filters:
            if not isinstance(filter_item, dict) or 'filter_type' not in filter_item or 'filter_value' not in filter_item:
                return jsonify({'error': 'è¿‡æ»¤æ¡ä»¶æ ¼å¼æ— æ•ˆ'}), 400

        import json
        filters_json = json.dumps(filters)

        if db.update_website_message_filters(config_id, filters_json):
            return jsonify({'success': True, 'message': f'å·²æ›´æ–° {len(filters)} ä¸ªè¿‡æ»¤æ¡ä»¶'})
        else:
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°ç½‘ç«™è¿‡æ»¤æ¡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/products/<int:product_id>/urls', methods=['GET'])
def get_product_urls(product_id):
    """è·å–å•†å“çš„æ‰€æœ‰ç½‘ç«™URL"""
    try:
        # è·å–å•†å“ä¿¡æ¯
        product = db._get_product_info_by_id(product_id)
        if not product:
            return jsonify({'error': 'å•†å“ä¸å­˜åœ¨'}), 404

        # ä»å•†å“URLä¸­æå–å¾®åº—ID
        weidian_url = product.get('product_url', '')
        weidian_id = None

        if 'itemID=' in weidian_url:
            # æå–itemIDå‚æ•°
            import re
            match = re.search(r'itemID=([^&]+)', weidian_url)
            if match:
                weidian_id = match.group(1)

        if not weidian_id:
            return jsonify({'urls': []})

        # ç”Ÿæˆæ‰€æœ‰ç½‘ç«™çš„URL
        urls = db.generate_website_urls(weidian_id)
        return jsonify({'urls': urls})
    except Exception as e:
        logger.error(f"è·å–å•†å“URLå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯API ===
@app.route('/api/system/stats', methods=['GET'])
def get_system_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = db.get_system_stats()
        return jsonify(stats)
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šå…¬å‘Šç®¡ç†API ===
@app.route('/api/announcements', methods=['GET'])
def get_announcements():
    """è·å–æ‰€æœ‰å…¬å‘Š"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        announcements = db.get_active_announcements()
        return jsonify({'announcements': announcements})
    except Exception as e:
        logger.error(f"è·å–å…¬å‘Šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/announcements', methods=['POST'])
def create_announcement():
    """åˆ›å»ºå…¬å‘Š"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        title = data.get('title')
        content = data.get('content')

        if not title or not content:
            return jsonify({'error': 'æ ‡é¢˜å’Œå†…å®¹éƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.create_announcement(title, content):
            return jsonify({'success': True, 'message': 'å…¬å‘Šåˆ›å»ºæˆåŠŸ'})
        else:
            return jsonify({'error': 'åˆ›å»ºå¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ›å»ºå…¬å‘Šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/announcements/<int:announcement_id>', methods=['PUT'])
def update_announcement(announcement_id):
    """æ›´æ–°å…¬å‘Š"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        title = data.get('title')
        content = data.get('content')
        is_active = data.get('is_active', True)

        if not title or not content:
            return jsonify({'error': 'æ ‡é¢˜å’Œå†…å®¹éƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.update_announcement(announcement_id, title, content, is_active):
            return jsonify({'success': True, 'message': 'å…¬å‘Šæ›´æ–°æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°å…¬å‘Šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/announcements/<int:announcement_id>', methods=['DELETE'])
def delete_announcement(announcement_id):
    """åˆ é™¤å…¬å‘Š"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        if db.delete_announcement(announcement_id):
            return jsonify({'success': True, 'message': 'å…¬å‘Šåˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤å…¬å‘Šå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šæ¶ˆæ¯è¿‡æ»¤è§„åˆ™API ===
@app.route('/api/message-filters', methods=['GET'])
def get_message_filters():
    """è·å–æ¶ˆæ¯è¿‡æ»¤è§„åˆ™"""
    try:
        filters = db.get_message_filters()
        return jsonify({'filters': filters})
    except Exception as e:
        logger.error(f"è·å–æ¶ˆæ¯è¿‡æ»¤è§„åˆ™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/message-filters', methods=['POST'])
def add_message_filter():
    """æ·»åŠ æ¶ˆæ¯è¿‡æ»¤è§„åˆ™"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        filter_type = data.get('filter_type')
        filter_value = data.get('filter_value')

        if not filter_type or not filter_value:
            return jsonify({'error': 'è¿‡æ»¤ç±»å‹å’Œå€¼éƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.add_message_filter(filter_type, filter_value):
            return jsonify({'success': True, 'message': 'è¿‡æ»¤è§„åˆ™æ·»åŠ æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ·»åŠ å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ·»åŠ æ¶ˆæ¯è¿‡æ»¤è§„åˆ™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/message-filters/<int:filter_id>', methods=['PUT'])
def update_message_filter(filter_id):
    """æ›´æ–°æ¶ˆæ¯è¿‡æ»¤è§„åˆ™"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        filter_type = data.get('filter_type')
        filter_value = data.get('filter_value')
        is_active = data.get('is_active', True)

        if not filter_type or not filter_value:
            return jsonify({'error': 'è¿‡æ»¤ç±»å‹å’Œå€¼éƒ½æ˜¯å¿…å¡«çš„'}), 400

        if db.update_message_filter(filter_id, filter_type, filter_value, is_active):
            return jsonify({'success': True, 'message': 'è¿‡æ»¤è§„åˆ™æ›´æ–°æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°æ¶ˆæ¯è¿‡æ»¤è§„åˆ™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/message-filters/<int:filter_id>', methods=['DELETE'])
def delete_message_filter(filter_id):
    """åˆ é™¤æ¶ˆæ¯è¿‡æ»¤è§„åˆ™"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        if db.delete_message_filter(filter_id):
            return jsonify({'success': True, 'message': 'è¿‡æ»¤è§„åˆ™åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤æ¶ˆæ¯è¿‡æ»¤è§„åˆ™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === æ–°å¢ï¼šè‡ªå®šä¹‰å›å¤å†…å®¹API ===
@app.route('/api/custom-replies', methods=['GET'])
def get_custom_replies():
    """è·å–è‡ªå®šä¹‰å›å¤å†…å®¹"""
    try:
        replies = db.get_custom_replies()
        return jsonify({'replies': replies})
    except Exception as e:
        logger.error(f"è·å–è‡ªå®šä¹‰å›å¤å†…å®¹å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/custom-replies', methods=['POST'])
def add_custom_reply():
    """æ·»åŠ è‡ªå®šä¹‰å›å¤å†…å®¹"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        reply_type = data.get('reply_type')
        content = data.get('content')
        image_url = data.get('image_url')
        priority = data.get('priority', 0)

        if not reply_type:
            return jsonify({'error': 'å›å¤ç±»å‹æ˜¯å¿…å¡«çš„'}), 400

        if db.add_custom_reply(reply_type, content, image_url, priority):
            return jsonify({'success': True, 'message': 'è‡ªå®šä¹‰å›å¤æ·»åŠ æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ·»åŠ å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ·»åŠ è‡ªå®šä¹‰å›å¤å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/custom-replies/<int:reply_id>', methods=['PUT'])
def update_custom_reply(reply_id):
    """æ›´æ–°è‡ªå®šä¹‰å›å¤å†…å®¹"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        reply_type = data.get('reply_type')
        content = data.get('content')
        image_url = data.get('image_url')
        priority = data.get('priority', 0)
        is_active = data.get('is_active', True)

        if not reply_type:
            return jsonify({'error': 'å›å¤ç±»å‹æ˜¯å¿…å¡«çš„'}), 400

        if db.update_custom_reply(reply_id, reply_type, content, image_url, priority, is_active):
            return jsonify({'success': True, 'message': 'è‡ªå®šä¹‰å›å¤æ›´æ–°æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°è‡ªå®šä¹‰å›å¤å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/custom-replies/<int:reply_id>', methods=['DELETE'])
def delete_custom_reply(reply_id):
    """åˆ é™¤è‡ªå®šä¹‰å›å¤å†…å®¹"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        if db.delete_custom_reply(reply_id):
            return jsonify({'success': True, 'message': 'è‡ªå®šä¹‰å›å¤åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤è‡ªå®šä¹‰å›å¤å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/users/<int:user_id>/shops', methods=['PUT'])
def update_user_shops(user_id):
    """æ›´æ–°ç”¨æˆ·åº—é“ºæƒé™ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        shop_ids = data.get('shops', [])

        if db.update_user_shops(user_id, shop_ids):
            return jsonify({'message': 'æƒé™æ›´æ–°æˆåŠŸ'})
        else:
            return jsonify({'error': 'æƒé™æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°ç”¨æˆ·æƒé™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts', methods=['GET'])
def get_accounts():
    """è·å–æ‰€æœ‰ Discord è´¦å·"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    current_user = get_current_user()
    try:
        # æ ¹æ®ç”¨æˆ·æƒé™è¿‡æ»¤è´¦å·
        if current_user['role'] == 'admin':
            # ç®¡ç†å‘˜å¯ä»¥çœ‹åˆ°æ‰€æœ‰è´¦å·
            accounts = db.get_discord_accounts_by_user(None)
        else:
            # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±å…³è”çš„è´¦å·
            accounts = db.get_discord_accounts_by_user(current_user['id'])

        return jsonify({'accounts': accounts})
    except Exception as e:
        logger.error(f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/products', methods=['GET'])
def list_products():
    """åˆ—å‡ºç”¨æˆ·æœ‰æƒé™çš„å•†å“åŠå…¶å›¾ç‰‡"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    current_user = get_current_user()
    try:
        # è·å–åˆ†é¡µå‚æ•°
        page = int(request.args.get('page', 1))
        limit = int(request.args.get('limit', 50))  # é»˜è®¤æ¯é¡µ50æ¡
        offset = (page - 1) * limit

        # æ ¹æ®ç”¨æˆ·æƒé™è·å–å•†å“ï¼ˆæ”¯æŒåˆ†é¡µï¼‰
        if current_user['role'] == 'admin':
            # ç®¡ç†å‘˜å¯ä»¥çœ‹åˆ°æ‰€æœ‰å•†å“
            logger.info(f"ç®¡ç†å‘˜ç”¨æˆ· {current_user['username']} è·å–å•†å“åˆ—è¡¨ (é¡µ{page}, æ¯é¡µ{limit}æ¡)")
            result = db.get_products_by_user_shops(None, limit=limit, offset=offset)
        else:
            # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±ç®¡ç†çš„åº—é“ºçš„å•†å“
            user_shops = current_user.get('shops', [])
            logger.info(f"æ™®é€šç”¨æˆ· {current_user['username']} è·å–åº—é“ºå•†å“ (é¡µ{page}, æ¯é¡µ{limit}æ¡)ï¼Œåˆ†é…çš„åº—é“º: {user_shops}")
            result = db.get_products_by_user_shops(user_shops, limit=limit, offset=offset)

            # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­çš„å•†å“å’Œåº—é“ºåŒ¹é…æƒ…å†µ
            if user_shops:
                with db.get_connection() as conn:
                    cursor = conn.cursor()
                    placeholders = ','.join('?' * len(user_shops))
                    cursor.execute(f"SELECT COUNT(*) FROM products WHERE shop_name IN ({placeholders})", user_shops)
                    matching_products = cursor.fetchone()[0]
                    logger.info(f"æ•°æ®åº“ä¸­åŒ¹é…çš„å•†å“æ•°é‡: {matching_products}")

                    # åˆ—å‡ºæ‰€æœ‰åº—é“ºåç§°
                    cursor.execute("SELECT DISTINCT shop_name FROM products")
                    all_shop_names = [row[0] for row in cursor.fetchall()]
                    logger.info(f"æ•°æ®åº“ä¸­çš„æ‰€æœ‰åº—é“ºåç§°: {all_shop_names}")

        logger.info(f"è¿”å›å•†å“æ•°é‡: {len(result['products'])}")

        # æ·»åŠ è°ƒè¯•ä¿¡æ¯åˆ°å“åº”ä¸­
        response_data = {
            'products': result['products'],
            'total': result['total'],
            'debug': {
                'user_role': current_user['role'],
                'user_shops': current_user.get('shops', []),
                'is_admin': current_user['role'] == 'admin'
            }
        }

        # æ·»åŠ ç¼“å­˜å¤´ä»¥ä¼˜åŒ–æ€§èƒ½ï¼ˆ5åˆ†é’Ÿç¼“å­˜ï¼‰
        response = jsonify(response_data)
        response.headers['Cache-Control'] = 'private, max-age=300'
        return response
    except Exception as e:
        logger.error(f"åˆ—å‡ºå•†å“å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/products', methods=['PUT'])
def update_product():
    """æ›´æ–°å•†å“ä¿¡æ¯"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    current_user = get_current_user()

    # æ£€æŸ¥æ˜¯å¦æ˜¯multipart/form-dataï¼ˆåŒ…å«æ–‡ä»¶ä¸Šä¼ ï¼‰
    if request.content_type and 'multipart/form-data' in request.content_type:
        # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
        product_id = request.form.get('id')
        if not product_id:
            return jsonify({'error': 'å•†å“IDä¸èƒ½ä¸ºç©º'}), 400

        try:
            # æ£€æŸ¥æƒé™
            if current_user['role'] == 'admin':
                pass
            else:
                user_shops = current_user.get('shops', [])
                product = db.get_product_by_id(int(product_id))
                if not product or product.get('shop_name') not in user_shops:
                    return jsonify({'error': 'æ— æƒé™æ›´æ–°æ­¤å•†å“'}), 403

            # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
            uploaded_files = []
            if 'uploadedImages' in request.files:
                files = request.files.getlist('uploadedImages')
                for file in files:
                    if file and file.filename:
                        # ä¿å­˜æ–‡ä»¶åˆ°å•†å“å›¾ç‰‡ç›®å½•
                        import uuid
                        import os
                        filename = f"{uuid.uuid4()}_{file.filename}"
                        image_path = os.path.join('data', 'images', str(product_id), filename)

                        # ç¡®ä¿ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(image_path), exist_ok=True)

                        # ä¿å­˜æ–‡ä»¶
                        file.save(image_path)

                        # æ·»åŠ åˆ°æ•°æ®åº“
                        db.add_product_image(int(product_id), filename)
                        uploaded_files.append(filename)

            # æ„å»ºæ›´æ–°æ•°æ®
            updates = {}
            for key in ['title', 'englishTitle', 'ruleEnabled', 'customReplyText', 'imageSource']:
                value = request.form.get(key)
                if value is not None:
                    if key == 'englishTitle':
                        updates['english_title'] = value
                    elif key == 'ruleEnabled':
                        updates['ruleEnabled'] = value.lower() == 'true'
                    elif key == 'customReplyText':
                        updates['custom_reply_text'] = value
                    elif key == 'imageSource':
                        updates['image_source'] = value
                    else:
                        updates[key] = value

            # å¤„ç†æ•°ç»„æ•°æ®
            if 'selectedImageIndexes' in request.form:
                import json
                try:
                    updates['custom_reply_images'] = json.loads(request.form.get('selectedImageIndexes'))
                except:
                    pass

            if 'customImageUrls' in request.form:
                try:
                    updates['custom_image_urls'] = json.loads(request.form.get('customImageUrls'))
                except:
                    pass

            # æ‰§è¡Œæ›´æ–°
            if updates:
                success = db.update_product(int(product_id), updates)
                if success:
                    updated_product = db.get_product_by_id(int(product_id))
                    return jsonify({'message': 'å•†å“æ›´æ–°æˆåŠŸ', 'product': updated_product})
                else:
                    return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
            else:
                return jsonify({'error': 'æ²¡æœ‰è¦æ›´æ–°çš„å­—æ®µ'}), 400

        except Exception as e:
            logger.error(f"æ›´æ–°å•†å“å¤±è´¥: {e}")
            return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
    else:
        # å¤„ç†JSONæ•°æ®ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        data = request.get_json()

    if not data or not data.get('id'):
        return jsonify({'error': 'å•†å“IDä¸èƒ½ä¸ºç©º'}), 400

    product_id = data['id']

    try:
            # æ£€æŸ¥æƒé™
        if current_user['role'] == 'admin':
            pass
        else:
            user_shops = current_user.get('shops', [])
            product = db.get_product_by_id(product_id)
            if not product or product.get('shop_name') not in user_shops:
                return jsonify({'error': 'æ— æƒé™æ›´æ–°æ­¤å•†å“'}), 403

            # æ„å»ºæ›´æ–°æ•°æ®
            updates = {}
            if 'title' in data:
                updates['title'] = data['title']
            if 'englishTitle' in data:
                updates['english_title'] = data['englishTitle']
            if 'ruleEnabled' in data:
                updates['ruleEnabled'] = data['ruleEnabled']
            if 'customReplyText' in data:
                updates['custom_reply_text'] = data['customReplyText']
            if 'selectedImageIndexes' in data:
                updates['custom_reply_images'] = data['selectedImageIndexes']
            if 'customImageUrls' in data:
                updates['custom_image_urls'] = data['customImageUrls']
            if 'imageSource' in data:
                updates['image_source'] = data['imageSource']

            # æ‰§è¡Œæ›´æ–°
            if updates:
                success = db.update_product(product_id, updates)
                if success:
                    updated_product = db.get_product_by_id(product_id)
                    return jsonify({'message': 'å•†å“æ›´æ–°æˆåŠŸ', 'product': updated_product})
                else:
                    return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500
            else:
                return jsonify({'error': 'æ²¡æœ‰è¦æ›´æ–°çš„å­—æ®µ'}), 400

    except Exception as e:
        logger.error(f"æ›´æ–°å•†å“å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°å¤±è´¥'}), 500


@app.route('/api/backfill_products', methods=['POST'])
def backfill_products():
    """ä¸ºå·²å­˜åœ¨ä½†ç¼ºå°‘è‹±åæˆ– cnfans é“¾æ¥çš„å•†å“å›å¡«æ•°æ®"""
    try:
        from weidian_scraper import get_weidian_scraper
        scraper = get_weidian_scraper()

        updated = []
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT id, product_url, english_title, cnfans_url FROM products")
            rows = cursor.fetchall()

            for row in rows:
                pid = row['id']
                url = row['product_url']
                need_english = not row['english_title']
                need_cnfans = not row['cnfans_url']
                if not (need_english or need_cnfans):
                    continue

                product_info = scraper.scrape_product_info(url)
                if not product_info:
                    logger.warning(f"å›å¡«å¤±è´¥ï¼Œæ— æ³•æŠ“å–: {url}")
                    continue

                english = product_info.get('english_title') or ''
                cnfans = product_info.get('cnfans_url') or ''

                cursor.execute("""
                    UPDATE products
                    SET english_title = ?, cnfans_url = ?
                    WHERE id = ?
                """, (english, cnfans, pid))
                conn.commit()
                updated.append(pid)

        return jsonify({'updated': updated, 'count': len(updated)})
    except Exception as e:
        logger.error(f"å›å¡«å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/rebuild_index', methods=['POST'])
def rebuild_index():
    """é‡å»ºFAISSç´¢å¼•ï¼Œæ¸…ç†è¢«åˆ é™¤çš„å‘é‡"""
    try:
        try:
            from vector_engine import get_vector_engine
        except ImportError:
            from .vector_engine import get_vector_engine
        from feature_extractor import get_feature_extractor

        logger.info("å¼€å§‹é‡å»ºFAISSç´¢å¼•...")

        # è·å–æ‰€æœ‰æœ‰æ•ˆçš„å›¾ç‰‡è®°å½•ï¼ˆç¡®ä¿å›¾ç‰‡æ–‡ä»¶å­˜åœ¨ï¼‰
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pi.id, pi.product_id, pi.image_path, pi.image_index
                FROM product_images pi
                JOIN products p ON pi.product_id = p.id
                ORDER BY pi.id
            """)
            all_records = cursor.fetchall()

        # è¿‡æ»¤å‡ºæ–‡ä»¶å­˜åœ¨çš„è®°å½•
        image_records = []
        for record in all_records:
            if os.path.exists(record['image_path']):
                image_records.append(record)
            else:
                logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {record['image_path']}")

        if not image_records:
            return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡è®°å½•'}), 400

        logger.info(f"æ‰¾åˆ° {len(image_records)} å¼ å›¾ç‰‡è®°å½•")

        # é‡æ–°æå–ç‰¹å¾å¹¶é‡å»ºç´¢å¼•
        extractor = get_feature_extractor()
        engine = get_vector_engine()

        # åˆ›å»ºæ–°ç´¢å¼•
        vectors_data = []
        for record in image_records:
            try:
                image_path = record['image_path']
                if not os.path.exists(image_path):
                    logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue

                # æå–ç‰¹å¾
                features = extractor.extract_feature(image_path)
                if features is not None:
                    vectors_data.append((record['id'], features))
                    logger.info(f"é‡æ–°æå–ç‰¹å¾: {record['id']}")
                else:
                    logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {image_path}")

            except Exception as e:
                logger.error(f"å¤„ç†å›¾ç‰‡ {record['id']} å¤±è´¥: {e}")
                continue

        # é‡å»ºç´¢å¼•
        success = engine.rebuild_index(vectors_data)
        if success:
            logger.info(f"ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {len(vectors_data)} ä¸ªå‘é‡")
            return jsonify({
                'success': True,
                'message': f'ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {len(vectors_data)} ä¸ªæœ‰æ•ˆå‘é‡',
                'total_vectors': len(vectors_data)
            })
        else:
            return jsonify({'error': 'ç´¢å¼•é‡å»ºå¤±è´¥'}), 500

    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/rebuild_vectors', methods=['POST'])
def rebuild_vectors():
    """ä¸ºå·²æœ‰å•†å“ï¼ˆæˆ–ç¼ºå¤±å‘é‡çš„å›¾ç‰‡ï¼‰é‡å»ºç‰¹å¾å¹¶æ’å…¥ FAISS"""
    try:
        extractor = get_feature_extractor()
        rebuilt = []
        failed = []

        with db.get_connection() as conn:
            cursor = conn.cursor()
            # æŸ¥æ‰¾æ‰€æœ‰ product_images ä¸­ milvus_id ä¸ºç©ºæˆ– NULL çš„è®°å½•
            cursor.execute("SELECT id, product_id, image_path, image_index FROM product_images WHERE milvus_id IS NULL OR milvus_id = ''")
            rows = cursor.fetchall()

        for row in rows:
            pid = row['product_id']
            img_path = row['image_path']
            idx = row['image_index']
            try:
                features = extractor.extract_feature(img_path)
                if features is None:
                    logger.error(f"é‡å»ºç‰¹å¾å¤±è´¥: {img_path}")
                    failed.append({'product_id': pid, 'image_index': idx})
                    continue

                success = db.insert_image_vector(product_id=pid, image_path=img_path, image_index=idx, vector=features)
                if success:
                    rebuilt.append({'product_id': pid, 'image_index': idx})
                else:
                    failed.append({'product_id': pid, 'image_index': idx})
            except Exception as e:
                logger.error(f"é‡å»ºå‘é‡å‡ºé”™: {e}")
                failed.append({'product_id': pid, 'image_index': idx})

        return jsonify({'rebuilt': rebuilt, 'failed': failed, 'count': len(rebuilt)})
    except Exception as e:
        logger.error(f"é‡å»ºå‘é‡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500



@app.route('/api/image/<int:product_id>/<int:image_index>', methods=['GET'])
def serve_product_image(product_id: int, image_index: int):
    """è¿”å›æŒ‡å®šå•†å“æŒ‡å®šåºå·çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆç”¨äºå‰ç«¯ç¼©ç•¥å›¾/æŸ¥çœ‹ï¼‰"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT image_path FROM product_images WHERE product_id = ? AND image_index = ?", (product_id, image_index))
            row = cursor.fetchone()
            if not row:
                return jsonify({'error': 'Image not found'}), 404
            image_path = row[0]

        # å®‰å…¨æ£€æŸ¥å¹¶è¿”å›æ–‡ä»¶
        from flask import send_file
        if not os.path.exists(image_path):
            return jsonify({'error': 'Image file missing'}), 404
        return send_file(image_path, mimetype='image/jpeg')
    except Exception as e:
        logger.error(f"serve_product_image å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

def verify_discord_token(token):
    """éªŒè¯Discord tokenå¹¶è·å–ç”¨æˆ·ä¿¡æ¯"""
    try:
        headers = {
            'Authorization': f'Bot {token}' if token.startswith('Bot ') else token,
            'User-Agent': 'DiscordBot/1.0'
        }

        # é¦–å…ˆå°è¯•ä½œä¸ºBot tokenéªŒè¯
        response = requests.get('https://discord.com/api/v10/users/@me', headers=headers, timeout=10)

        if response.status_code == 401:
            # å¦‚æœBot tokenå¤±è´¥ï¼Œå°è¯•ä½œä¸ºUser token
            if not token.startswith('Bot '):
                headers['Authorization'] = f'Bot {token}'
                response = requests.get('https://discord.com/api/v10/users/@me', headers=headers, timeout=10)

        if response.status_code == 200:
            user_data = response.json()
            return {
                'valid': True,
                'username': f"{user_data.get('username', 'Unknown')}#{user_data.get('discriminator', '0000')}",
                'user_id': user_data.get('id'),
                'avatar': user_data.get('avatar'),
                'bot': user_data.get('bot', False)
            }
        else:
            return {
                'valid': False,
                'error': f'HTTP {response.status_code}: {response.text}'
            }
    except requests.exceptions.RequestException as e:
        return {
            'valid': False,
            'error': f'ç½‘ç»œé”™è¯¯: {str(e)}'
        }
    except Exception as e:
        return {
            'valid': False,
            'error': f'éªŒè¯å¤±è´¥: {str(e)}'
        }

@app.route('/api/accounts', methods=['POST'])
def add_account():
    """æ·»åŠ æ–°çš„ Discord è´¦å·"""
    try:
        # è·å–å½“å‰ç™»å½•ç”¨æˆ·
        current_user = get_current_user()
        if not current_user:
            return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        token = data.get('token')
        username = data.get('username', '')

        if not token:
            return jsonify({'error': 'Token is required'}), 400

        # éªŒè¯tokenå¹¶è·å–çœŸå®ç”¨æˆ·å
        logger.info("æ­£åœ¨éªŒè¯Discord token...")
        token_info = verify_discord_token(token)

        if not token_info['valid']:
            return jsonify({'error': f'TokenéªŒè¯å¤±è´¥: {token_info["error"]} è¯·æ£€æŸ¥tokenæ˜¯å¦æ­£ç¡®'}), 400

        # å¦‚æœæ²¡æœ‰æä¾›ç”¨æˆ·åï¼Œä½¿ç”¨ä»tokenè·å–çš„ç”¨æˆ·å
        if not username:
            username = token_info['username']
            logger.info(f"è‡ªåŠ¨è·å–ç”¨æˆ·å: {username}")

        with db.get_connection() as conn:
            cursor = conn.cursor()

            # é¦–å…ˆæ£€æŸ¥tokenæ˜¯å¦å·²å­˜åœ¨
            cursor.execute("SELECT id, username, user_id FROM discord_accounts WHERE token = ?", (token,))
            existing_account = cursor.fetchone()

            if existing_account:
                # å¦‚æœtokenå·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å±äºå½“å‰ç”¨æˆ·
                if existing_account[2] == current_user['id']:
                    # å±äºå½“å‰ç”¨æˆ·ï¼Œæ›´æ–°ä¿¡æ¯
                    cursor.execute("""
                        UPDATE discord_accounts
                        SET username = ?, status = 'offline', updated_at = CURRENT_TIMESTAMP
                        WHERE token = ?
                    """, (username, token))
                    account_id = existing_account[0]
                    logger.info(f"æ›´æ–°ç°æœ‰è´¦å·: {username} (ç”¨æˆ·ID: {current_user['id']})")
                else:
                    # å±äºå…¶ä»–ç”¨æˆ·ï¼Œè¿”å›é”™è¯¯
                    return jsonify({'error': 'æ­¤Discord tokenå·²è¢«å…¶ä»–ç”¨æˆ·ä½¿ç”¨'}), 400
            else:
                # tokenä¸å­˜åœ¨ï¼Œæ’å…¥æ–°è®°å½•
                cursor.execute("""
                    INSERT INTO discord_accounts (username, token, status, user_id)
                    VALUES (?, ?, 'offline', ?)
                """, (username, token, current_user['id']))
                account_id = cursor.lastrowid
                logger.info(f"æ·»åŠ æ–°è´¦å·: {username} (ç”¨æˆ·ID: {current_user['id']})")

            # è·å–è´¦å·ä¿¡æ¯
            cursor.execute("SELECT id, username, token, status, last_active, user_id FROM discord_accounts WHERE id = ?", (account_id,))
            account = cursor.fetchone()
            conn.commit()

        logger.info(f"è´¦å·æ·»åŠ æˆåŠŸ: {username} (ç”¨æˆ·ID: {current_user['id']})")
        return jsonify({
            'id': account[0],
            'username': account[1],
            'token': account[2],
            'status': account[3],
            'lastActive': account[4],
            'user_id': account[5],
            'verified': True
        })
    except Exception as e:
        logger.error(f"æ·»åŠ è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<int:account_id>/user', methods=['PUT'])
def assign_account_to_user(account_id):
    """å°†Discordè´¦å·åˆ†é…ç»™ç”¨æˆ·ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        data = request.get_json()
        user_id = data.get('user_id')

        if db.update_discord_account_user(account_id, user_id):
            return jsonify({'message': 'è´¦å·åˆ†é…æˆåŠŸ'})
        else:
            return jsonify({'error': 'è´¦å·åˆ†é…å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ†é…è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<int:account_id>', methods=['DELETE'])
def delete_account(account_id):
    """åˆ é™¤ Discord è´¦å·"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("DELETE FROM discord_accounts WHERE id = ?", (account_id,))
            conn.commit()

        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"åˆ é™¤è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<int:account_id>/status', methods=['PUT'])
def update_account_status(account_id):
    """æ›´æ–°è´¦å·çŠ¶æ€"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        status = data.get('status')

        if status not in ['online', 'offline']:
            return jsonify({'error': 'Invalid status'}), 400

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE discord_accounts
                SET status = ?, updated_at = datetime('now')
                WHERE id = ?
            """, (status, account_id))
            conn.commit()

        return jsonify({'success': True, 'status': status})
    except Exception as e:
        logger.error(f"æ›´æ–°è´¦å·çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/current', methods=['GET'])
def get_current_account():
    """è·å–å½“å‰å¯ç”¨çš„ Discord è´¦å· (çŠ¶æ€ä¸ºonlineçš„ç¬¬ä¸€ä¸ª)"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, username, token, status, last_active
                FROM discord_accounts
                WHERE status = 'online'
                ORDER BY last_active DESC NULLS LAST, created_at ASC
                LIMIT 1
            """)
            account = cursor.fetchone()

            if account:
                return jsonify({
                    'id': account[0],
                    'username': account[1],
                    'token': account[2],
                    'status': account[3],
                    'lastActive': account[4]
                })
            else:
                return jsonify({'error': 'No active account found'}), 404
    except Exception as e:
        logger.error(f"è·å–å½“å‰è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/verify-all', methods=['POST'])
def verify_all_accounts():
    """é‡æ–°éªŒè¯æ‰€æœ‰è´¦å·"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            # è·å–æ‰€æœ‰è´¦å·
            cursor.execute("SELECT id, username, token FROM discord_accounts")
            accounts = cursor.fetchall()

            verified_count = 0
            invalid_count = 0
            results = []

            for account in accounts:
                account_id, username, token = account
                logger.info(f"æ­£åœ¨éªŒè¯è´¦å·: {username}")

                token_info = verify_discord_token(token)

                if token_info['valid']:
                    # æ›´æ–°ç”¨æˆ·åï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
                    new_username = token_info['username']
                    if new_username != username:
                        cursor.execute("""
                            UPDATE discord_accounts
                            SET username = ?
                            WHERE id = ?
                        """, (new_username, account_id))
                        logger.info(f"ç”¨æˆ·åå·²æ›´æ–°: {username} -> {new_username}")

                    verified_count += 1
                    results.append({
                        'id': account_id,
                        'username': new_username,
                        'valid': True
                    })
                else:
                    invalid_count += 1
                    results.append({
                        'id': account_id,
                        'username': username,
                        'valid': False,
                        'error': token_info['error']
                    })

            conn.commit()

        return jsonify({
            'success': True,
            'total': len(accounts),
            'verified': verified_count,
            'invalid': invalid_count,
            'results': results
        })
    except Exception as e:
        logger.error(f"æ‰¹é‡éªŒè¯è´¦å·å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/bulk-status', methods=['POST'])
def bulk_update_status():
    """æ‰¹é‡å¼€å¯æˆ–åœæ­¢æ‰€æœ‰è´¦å·"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        new_status = data.get('status')
        if new_status not in ['online', 'offline']:
            return jsonify({'error': 'Invalid status. Must be "online" or "offline"'}), 400

        with db.get_connection() as conn:
            cursor = conn.cursor()

            if new_status == 'online':
                cursor.execute("""
                    UPDATE discord_accounts
                    SET status = 'online', last_active = ?
                """, (datetime.now(),))
            else:
                cursor.execute("""
                    UPDATE discord_accounts
                    SET status = 'offline'
                """)

            updated_count = cursor.rowcount
            conn.commit()

        logger.info(f"æ‰¹é‡æ›´æ–°è´¦å·çŠ¶æ€: {updated_count} ä¸ªè´¦å·è®¾ç½®ä¸º {new_status}")

        return jsonify({
            'success': True,
            'updated_count': updated_count,
            'new_status': new_status
        })
    except Exception as e:
        logger.error(f"æ‰¹é‡æ›´æ–°è´¦å·çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/rotation', methods=['GET'])
def get_rotation_config():
    """è·å–è´¦å·è½®æ¢é…ç½®"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT enabled, rotation_interval, current_account_id
                FROM account_rotation_config
                LIMIT 1
            """)
            row = cursor.fetchone()

        if row:
            return jsonify({
                'enabled': row[0],
                'rotationInterval': row[1],
                'currentAccountId': row[2]
            })
        return jsonify({'enabled': False, 'rotationInterval': 10})
    except Exception as e:
        logger.error(f"è·å–è½®æ¢é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/user/settings', methods=['GET'])
def get_user_settings():
    """è·å–å½“å‰ç”¨æˆ·çš„ä¸ªæ€§åŒ–è®¾ç½®"""
    user = get_current_user()
    if not user:
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        settings = db.get_user_settings(user['id'])
        return jsonify(settings)
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·è®¾ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–è®¾ç½®å¤±è´¥'}), 500

@app.route('/api/user/settings', methods=['PUT'])
def update_user_settings():
    """æ›´æ–°å½“å‰ç”¨æˆ·çš„ä¸ªæ€§åŒ–è®¾ç½®"""
    user = get_current_user()
    if not user:
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Invalid request body'}), 400

        success = db.update_user_settings(
            user_id=user['id'],
            download_threads=data.get('download_threads'),
            feature_extract_threads=data.get('feature_extract_threads'),
            discord_similarity_threshold=data.get('discord_similarity_threshold'),
            global_reply_min_delay=data.get('global_reply_min_delay'),
            global_reply_max_delay=data.get('global_reply_max_delay'),
            user_blacklist=data.get('user_blacklist'),
            keyword_filters=data.get('keyword_filters')
        )

        if success:
            return jsonify({'message': 'è®¾ç½®æ›´æ–°æˆåŠŸ'})
        else:
            return jsonify({'error': 'è®¾ç½®æ›´æ–°å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°ç”¨æˆ·è®¾ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°è®¾ç½®å¤±è´¥'}), 500

@app.route('/api/accounts/rotation', methods=['POST'])
def update_rotation_config():
    """æ›´æ–°è´¦å·è½®æ¢é…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        enabled = data.get('enabled', False)
        rotation_interval = data.get('rotationInterval', 10)

        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE account_rotation_config
                SET enabled = ?, rotation_interval = ?, updated_at = datetime('now')
                WHERE id = 1
            """, (enabled, rotation_interval))
            conn.commit()

        return jsonify({'success': True, 'enabled': enabled, 'rotationInterval': rotation_interval})
    except Exception as e:
        logger.error(f"æ›´æ–°è½®æ¢é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/get_indexed_ids', methods=['GET'])
def get_indexed_ids():
    """è·å–å·²å»ºç«‹ç´¢å¼•çš„å•†å“URLåˆ—è¡¨"""
    try:
        indexed_urls = db.get_indexed_product_urls()
        return jsonify({'indexedIds': indexed_urls})
    except Exception as e:
        logger.error(f"è·å–å·²ç´¢å¼•IDå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === ä¿®å¤ï¼šæ‰¹é‡åˆ é™¤ API ===
@app.route('/api/products/batch', methods=['DELETE'])
def batch_delete_products():
    """æ‰¹é‡åˆ é™¤å•†å“ï¼ˆå¤šçº¿ç¨‹é«˜æ€§èƒ½ç‰ˆï¼‰"""
    try:
        data = request.get_json()
        ids = data.get('ids', [])
        if not ids:
            return jsonify({'error': 'No IDs provided'}), 400

        logger.info(f"å¼€å§‹æ‰¹é‡åˆ é™¤ {len(ids)} ä¸ªå•†å“")

        # ä½¿ç”¨å¤šçº¿ç¨‹åˆ é™¤
        import concurrent.futures
        max_threads = min(5, len(ids))  # åˆ é™¤ç”¨è¾ƒå°‘çš„çº¿ç¨‹ï¼Œé¿å…IOå†²çª

        deleted_count = 0
        failed_ids = []

        def delete_single_product(product_id):
            """åˆ é™¤å•ä¸ªå•†å“"""
            try:
                # åˆ›å»ºæ–°çš„æ•°æ®åº“å®ä¾‹é¿å…å¤šçº¿ç¨‹å†²çª
                from database import Database
                temp_db = Database()
                if temp_db.delete_product_images(product_id):
                    return {'success': True, 'id': product_id}
                else:
                    return {'success': False, 'id': product_id}
            except Exception as e:
                logger.error(f"åˆ é™¤å•†å“ {product_id} å¤±è´¥: {e}")
                return {'success': False, 'id': product_id}

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
            futures = [executor.submit(delete_single_product, pid) for pid in ids]

            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result['success']:
                    deleted_count += 1
                else:
                    failed_ids.append(result['id'])

        logger.info(f"æ‰¹é‡åˆ é™¤å®Œæˆ: {deleted_count}/{len(ids)} ä¸ªå•†å“æˆåŠŸåˆ é™¤")

        response = {'success': True, 'count': deleted_count, 'total': len(ids)}
        if failed_ids:
            response['failed_ids'] = failed_ids
            response['warning'] = f'{len(failed_ids)} ä¸ªå•†å“åˆ é™¤å¤±è´¥'

        return jsonify(response)
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/products/batch-delete-all', methods=['DELETE'])
def batch_delete_all_products():
    """åˆ é™¤æ‰€æœ‰å•†å“ï¼ˆå…¨é€‰åˆ é™¤ï¼‰"""
    try:
        # è·å–æ‰€æœ‰å•†å“ID
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT id FROM products")
            all_ids = [row['id'] for row in cursor.fetchall()]

        if not all_ids:
            return jsonify({'success': True, 'count': 0, 'message': 'æ²¡æœ‰å•†å“éœ€è¦åˆ é™¤'})

        logger.info(f"å¼€å§‹åˆ é™¤æ‰€æœ‰ {len(all_ids)} ä¸ªå•†å“")

        # ä½¿ç”¨å¤šçº¿ç¨‹åˆ é™¤æ‰€æœ‰å•†å“
        import concurrent.futures
        max_threads = min(5, len(all_ids))

        deleted_count = 0
        failed_ids = []

        def delete_single_product(product_id):
            try:
                # åˆ›å»ºæ–°çš„æ•°æ®åº“å®ä¾‹é¿å…å¤šçº¿ç¨‹å†²çª
                from database import Database
                temp_db = Database()
                if temp_db.delete_product_images(product_id):
                    return {'success': True, 'id': product_id}
                else:
                    return {'success': False, 'id': product_id}
            except Exception as e:
                logger.error(f"åˆ é™¤å•†å“ {product_id} å¤±è´¥: {e}")
                return {'success': False, 'id': product_id}

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
            futures = [executor.submit(delete_single_product, pid) for pid in all_ids]

            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result['success']:
                    deleted_count += 1
                else:
                    failed_ids.append(result['id'])

        logger.info(f"å…¨é€‰åˆ é™¤å®Œæˆ: {deleted_count}/{len(all_ids)} ä¸ªå•†å“æˆåŠŸåˆ é™¤")

        response = {
            'success': True,
            'count': deleted_count,
            'total': len(all_ids),
            'message': f'æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªå•†å“'
        }

        if failed_ids:
            response['failed_ids'] = failed_ids
            response['warning'] = f'{len(failed_ids)} ä¸ªå•†å“åˆ é™¤å¤±è´¥'

        return jsonify(response)
    except Exception as e:
        logger.error(f"å…¨é€‰åˆ é™¤å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/products/<int:product_id>', methods=['DELETE'])
def delete_product(product_id):
    """åˆ é™¤å•†å“åŠå…¶æ‰€æœ‰ç›¸å…³æ•°æ®"""
    try:
        # åˆ é™¤å•†å“åŠå…¶å‘é‡æ•°æ®
        if db.delete_product_images(product_id):
            return jsonify({'success': True, 'message': f'å•†å“ {product_id} å·²åˆ é™¤'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"åˆ é™¤å•†å“å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === ä¿®å¤ï¼šå•†å“å›¾ç‰‡ä¸Šä¼  API ===
@app.route('/api/products/<int:product_id>/images', methods=['POST'])
def upload_product_image(product_id):
    """ä¸Šä¼ æ–°å›¾ç‰‡åˆ°å•†å“ï¼ˆè°ƒç”¨å®Œæ•´çš„æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼‰"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    file = request.files.get('image')
    if not file:
        return jsonify({'error': 'æ— æ–‡ä»¶'}), 400

    try:
        # è·å–ç°æœ‰ç‰¹å¾ç”¨äºæŸ¥é‡
        existing_images = db.get_product_images(product_id)
        existing_feats = [img['features'] for img in existing_images if img['features']]

        # è·å–ä¸‹ä¸€ä¸ª index
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT MAX(image_index) FROM product_images WHERE product_id = ?", (product_id,))
            row = cursor.fetchone()
            next_index = (row[0] + 1) if row and row[0] is not None else 0

            # æ£€æŸ¥å›¾ç‰‡æ•°é‡é™åˆ¶ï¼ˆæ¯ä¸ªå•†å“æœ€å¤š20å¼ å›¾ç‰‡ï¼‰
            cursor.execute("SELECT COUNT(*) FROM product_images WHERE product_id = ?", (product_id,))
            count_row = cursor.fetchone()
            if count_row and count_row[0] >= 20:
                return jsonify({'error': 'æ¯ä¸ªå•†å“æœ€å¤šåªèƒ½ä¸Šä¼ 20å¼ å›¾ç‰‡'}), 400

        # è°ƒç”¨æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼ˆç°åœ¨åŒ…å«å®Œæ•´çš„æ•°æ®åº“å’ŒFAISSæ“ä½œï¼‰
        result = process_and_save_image_core(product_id, file, next_index, existing_feats)

        if not result['success']:
            return jsonify({'error': result['error']}), 400

        # è¿”å›æ›´æ–°åçš„å•†å“ä¿¡æ¯
        product = db._get_product_info_by_id(product_id)

        # è·å–æ‰€æœ‰å›¾ç‰‡
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT image_index FROM product_images WHERE product_id = ? ORDER BY image_index", (product_id,))
            images = [f"/api/image/{product_id}/{row[0]}" for row in cursor.fetchall()]

        product['images'] = images

        # æ ¼å¼åŒ–ä»¥åŒ¹é…å‰ç«¯
        product['weidianId'] = product.get('product_url', '').split('itemID=')[1] if 'itemID=' in product.get('product_url', '') else ''
        product['weidianUrl'] = product.get('product_url')
        product['englishTitle'] = product.get('english_title')
        product['cnfansUrl'] = product.get('cnfans_url')
        product['ruleEnabled'] = product.get('ruleEnabled')
        product['matchType'] = 'fuzzy'

        return jsonify({'success': True, 'product': product})

    except Exception as e:
        logger.error(f"ä¸Šä¼ å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# === ä¿®å¤ï¼šåˆ é™¤å›¾ç‰‡åè¿”å›æœ€æ–° Product å¯¹è±¡ ===
@app.route('/api/products/<int:product_id>/images/<int:image_index>', methods=['DELETE'])
def delete_product_image(product_id, image_index):
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        logger.info(f"å¼€å§‹åˆ é™¤å›¾ç‰‡: product_id={product_id}, image_index={image_index}")


        # éªŒè¯å‚æ•°
        try:
            product_id = int(product_id)
            image_index = int(image_index)
        except ValueError:
            return jsonify({'error': 'å‚æ•°æ ¼å¼é”™è¯¯'}), 400

        # è°ƒç”¨æ•°æ®åº“åˆ é™¤é€»è¾‘
        success = db.delete_image_vector(product_id, image_index)

        if not success:
            logger.warning(f"åˆ é™¤å›¾ç‰‡å¤±è´¥: product_id={product_id}, image_index={image_index}")
            return jsonify({'error': 'åˆ é™¤å¤±è´¥ï¼Œå›¾ç‰‡å¯èƒ½ä¸å­˜åœ¨'}), 404

        # è·å–æœ€æ–°å•†å“ä¿¡æ¯
        product = db._get_product_info_by_id(product_id)

        if not product:
            logger.error(f"åˆ é™¤åå•†å“ä¸å­˜åœ¨: product_id={product_id}")
            return jsonify({'error': 'å•†å“ä¸å­˜åœ¨'}), 404

        # è·å–å‰©ä½™æ‰€æœ‰å›¾ç‰‡
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT image_index FROM product_images WHERE product_id = ? ORDER BY image_index", (product_id,))
            image_indices = [row[0] for row in cursor.fetchall()]
            images = [f"/api/image/{product_id}/{idx}" for idx in image_indices]

        product['images'] = images

        # æ ¼å¼åŒ–å•†å“ä¿¡æ¯
        try:
            if 'itemID=' in product.get('product_url', ''):
                product['weidianId'] = product.get('product_url', '').split('itemID=')[1]
            else:
                product['weidianId'] = ''
        except:
            product['weidianId'] = ''

        product['weidianUrl'] = product.get('product_url')
        product['englishTitle'] = product.get('english_title')
        product['cnfansUrl'] = product.get('cnfans_url')
        product['acbuyUrl'] = product.get('acbuy_url')
        product['ruleEnabled'] = product.get('ruleEnabled')

        logger.info(f"åˆ é™¤å›¾ç‰‡æˆåŠŸ: product_id={product_id}, image_index={image_index}, å‰©ä½™å›¾ç‰‡æ•°é‡={len(images)}")

        return jsonify({'success': True, 'product': product})

    except Exception as e:
        logger.error(f"åˆ é™¤å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/cleanup/images', methods=['POST'])
def cleanup_images():
    """æ¸…ç†æœªä½¿ç”¨çš„å›¾ç‰‡æ–‡ä»¶"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        current_user = get_current_user()
        if current_user['role'] != 'admin':
            return jsonify({'error': 'åªæœ‰ç®¡ç†å‘˜å¯ä»¥æ‰§è¡Œæ¸…ç†æ“ä½œ'}), 403

        # è·å–æ¸…ç†å‚æ•°
        data = request.get_json() or {}
        days_old = data.get('days_old', 30)

        # æ‰§è¡Œæ¸…ç†
        deleted_count = db.cleanup_unused_images(days_old)

        return jsonify({
            'success': True,
            'message': f'æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæœªä½¿ç”¨çš„å›¾ç‰‡æ–‡ä»¶',
            'deleted_count': deleted_count
        })

    except Exception as e:
        logger.error(f"å›¾ç‰‡æ¸…ç†å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/system/ai-status', methods=['GET'])
def get_ai_status():
    """è·å–AIç³»ç»Ÿå®Œæ•´çŠ¶æ€å’Œè¯Šæ–­ä¿¡æ¯"""
    try:
        extractor = get_global_feature_extractor()
        if extractor is None:
            return {'error': 'ç‰¹å¾æå–å™¨æœªåˆå§‹åŒ–'}
        ai_status = extractor.get_status()

        # è·å–FAISSçŠ¶æ€
        try:
            from vector_engine import get_vector_engine
        except ImportError:
            from .vector_engine import get_vector_engine
        faiss_engine = get_vector_engine()
        faiss_status = faiss_engine.get_stats()

        # ç»¼åˆçŠ¶æ€
        overall_status = {
            'ai_model_status': ai_status,
            'vector_engine_status': faiss_status,
            'system_health': 'è‰¯å¥½' if ai_status['yolo_available'] and faiss_status['total_vectors'] >= 0 else 'éœ€è¦ä¼˜åŒ–',
            'recommendations': []
        }

        # ç”Ÿæˆå»ºè®®
        recommendations = []
        recommendations.extend(ai_status.get('performance_tips', []))
        recommendations.extend(faiss_status.get('performance_tips', []))

        # é¢å¤–çš„ç³»ç»Ÿçº§å»ºè®®
        if not ai_status['yolo_available']:
            recommendations.append("YOLOè£å‰ªåŠŸèƒ½å·²ç¦ç”¨ï¼Œå›¾åƒè¯†åˆ«å‡†ç¡®ç‡ä¼šé™ä½")
        if faiss_status['total_vectors'] == 0:
            recommendations.append("å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œå»ºè®®æ·»åŠ å•†å“æ•°æ®")
        if faiss_status['ef_construction'] == 'ä¸æ”¯æŒ' or faiss_status['ef_search'] == 'ä¸æ”¯æŒ':
            recommendations.append("FAISSç‰ˆæœ¬è¾ƒæ—§ï¼Œå»ºè®®å‡çº§ä»¥è·å¾—æœ€ä½³æœç´¢æ€§èƒ½")

        overall_status['recommendations'] = recommendations[:5]  # æœ€å¤šæ˜¾ç¤º5æ¡å»ºè®®

        return jsonify(overall_status)
    except Exception as e:
        logger.error(f"è·å–AIçŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/system/rebuild-index', methods=['POST'])
def rebuild_faiss_index():
    """é‡å»ºFAISSç´¢å¼•ï¼Œæ¸…ç†å·²åˆ é™¤çš„å‘é‡"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        current_user = get_current_user()
        if current_user['role'] != 'admin':
            return jsonify({'error': 'åªæœ‰ç®¡ç†å‘˜å¯ä»¥é‡å»ºç´¢å¼•'}), 403

        try:
            from vector_engine import get_vector_engine
        except ImportError:
            from .vector_engine import get_vector_engine
        engine = get_vector_engine()

        # è·å–æ‰€æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ•°æ®
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT id, image_path FROM product_images WHERE id IS NOT NULL")
            all_images = cursor.fetchall()

        # é‡æ–°æå–æ‰€æœ‰ç‰¹å¾
        valid_vectors = []
        for row in all_images:
            try:
                extractor = get_global_feature_extractor()
                if extractor is None:
                    logger.error("ç‰¹å¾æå–å™¨æœªåˆå§‹åŒ–")
                    continue
                features = extractor.extract_feature(row['image_path'])
                if features is not None:
                    valid_vectors.append((row['id'], features))
            except Exception as e:
                logger.warning(f"é‡æ–°æå–ç‰¹å¾å¤±è´¥ {row['image_path']}: {e}")

        # é‡å»ºç´¢å¼•
        engine.rebuild_index(valid_vectors)

        return jsonify({
            'success': True,
            'message': f'ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {len(valid_vectors)} ä¸ªå‘é‡',
            'total_vectors': len(valid_vectors)
        })

    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config', methods=['GET'])
def get_config():
    """è·å–ç³»ç»Ÿé…ç½®ä¿¡æ¯"""
    try:
        from config import config
        return jsonify({
            'version': '1.0.0',
            'features': {
                'multithread_scraping': True,
                'ai_image_processing': True,
                'discord_bot': True,
                'real_time_monitoring': True
            },
            'limits': {
                'max_scrape_threads': config.SCRAPE_THREADS,
                'max_download_threads': config.DOWNLOAD_THREADS,
                'max_feature_threads': config.FEATURE_EXTRACT_THREADS
            }
        })
    except Exception as e:
        logger.error(f"è·å–é…ç½®ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-threshold', methods=['GET'])
def get_discord_threshold():
    """è·å–Discordç›¸ä¼¼åº¦é˜ˆå€¼"""
    try:
        sys_config = db.get_system_config()
        threshold = sys_config['discord_similarity_threshold']
        return jsonify({
            'threshold': threshold,
            'threshold_percentage': threshold * 100
        })
    except Exception as e:
        logger.error(f"è·å–Discordé˜ˆå€¼å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-threshold', methods=['POST'])
def update_discord_threshold():
    """æ›´æ–°Discordç›¸ä¼¼åº¦é˜ˆå€¼"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        threshold = float(data.get('threshold', 0.4))

        # éªŒè¯èŒƒå›´
        if not (0.0 <= threshold <= 1.0):
            return jsonify({'error': 'é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_system_config(discord_similarity_threshold=threshold):
            # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é…ç½®

            return jsonify({
                'message': f'Discordç›¸ä¼¼åº¦é˜ˆå€¼å·²æ›´æ–°ä¸º {threshold}',
                'threshold': threshold
            })

        return jsonify({'error': 'æ›´æ–°é…ç½®å¤±è´¥'}), 500
    except ValueError as e:
        return jsonify({'error': 'é˜ˆå€¼å¿…é¡»æ˜¯æ•°å­—'}), 400
    except Exception as e:
        logger.error(f"æ›´æ–°Discordé˜ˆå€¼å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°é…ç½®å¤±è´¥'}), 500

@app.route('/api/config/scrape-threads', methods=['GET', 'POST'])
def config_scrape_threads():
    """é…ç½®æŠ“å–å¤šçº¿ç¨‹æ•°é‡"""
    if request.method == 'GET':
        config = db.get_system_config()
        return jsonify({
            'scrape_threads': config.get('scrape_threads', 2)
        })

    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        scrape_threads = int(data.get('scrape_threads', 2))

        # ç¡®ä¿çº¿ç¨‹æ•°åœ¨åˆç†èŒƒå›´å†…
        if scrape_threads < 1 or scrape_threads > 10:
            return jsonify({'error': 'æŠ“å–çº¿ç¨‹æ•°å¿…é¡»æ˜¯1-10ä¹‹é—´çš„æ•´æ•°'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('UPDATE system_config SET scrape_threads = ?, updated_at = CURRENT_TIMESTAMP WHERE id = 1',
                          (scrape_threads,))
            conn.commit()

        return jsonify({
            'message': f'æŠ“å–çº¿ç¨‹æ•°å·²è®¾ç½®ä¸º {scrape_threads}',
            'scrape_threads': scrape_threads
        })

    except ValueError as e:
        return jsonify({'error': 'çº¿ç¨‹æ•°å¿…é¡»æ˜¯æ•´æ•°'}), 400
    except Exception as e:
        logger.error(f"æ›´æ–°æŠ“å–çº¿ç¨‹é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°é…ç½®å¤±è´¥'}), 500

@app.route('/api/config/global-reply-delay', methods=['GET'])
def get_global_reply_delay():
    """è·å–å…¨å±€å›å¤å»¶è¿Ÿé…ç½®"""
    try:
        delay_config = db.get_global_reply_config()
        return jsonify({
            'min_delay': delay_config['min_delay'],
            'max_delay': delay_config['max_delay'],
            'description': f'{delay_config["min_delay"]}-{delay_config["max_delay"]}ç§’éšæœºå»¶è¿Ÿ'
        })
    except Exception as e:
        logger.error(f"è·å–å…¨å±€å›å¤å»¶è¿Ÿå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/debug/faiss_status', methods=['GET'])
def get_faiss_status():
    """è·å–FAISSå‘é‡æ•°æ®åº“çŠ¶æ€"""
    try:
        try:
            from vector_engine import get_vector_engine
        except ImportError:
            from .vector_engine import get_vector_engine
        engine = get_vector_engine()
        stats = engine.get_stats()

        # å°è¯•æœç´¢ä¸€ä¸ªæµ‹è¯•å‘é‡
        test_vector = np.zeros(config.VECTOR_DIMENSION, dtype='float32')
        test_results = engine.search(test_vector, top_k=1)

        return jsonify({
            'index_exists': True,
            'entity_count': stats['total_vectors'],
            'test_search_works': len(test_results) > 0,
            'vector_dimension': config.VECTOR_DIMENSION,
            'index_type': stats['index_type'],
            'metric_type': stats['metric_type'],
            'memory_usage_mb': stats['memory_usage_mb'],
            'ef_construction': stats['ef_construction'],
            'ef_search': stats['ef_search']
        })
    except Exception as e:
        logger.error(f"è·å–FAISSçŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'index_exists': False,
            'entity_count': 0
        }), 500


@app.route('/api/config/global-reply-delay', methods=['POST'])
def update_global_reply_delay():
    """æ›´æ–°å…¨å±€å›å¤å»¶è¿Ÿé…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400
        min_delay = float(data.get('min_delay', 3))
        max_delay = float(data.get('max_delay', 8))

        # éªŒè¯èŒƒå›´
        if min_delay < 0 or max_delay < 0:
            return jsonify({'error': 'å»¶è¿Ÿæ—¶é—´ä¸èƒ½ä¸ºè´Ÿæ•°'}), 400
        if min_delay > max_delay:
            return jsonify({'error': 'æœ€å°å»¶è¿Ÿä¸èƒ½å¤§äºæœ€å¤§å»¶è¿Ÿ'}), 400
        if max_delay > 300:
            return jsonify({'error': 'æœ€å¤§å»¶è¿Ÿä¸èƒ½è¶…è¿‡300ç§’'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_global_reply_config(min_delay, max_delay):
            # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
            config.GLOBAL_REPLY_MIN_DELAY = min_delay
            config.GLOBAL_REPLY_MAX_DELAY = max_delay

            logger.info(f"å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®ä¸º: {min_delay}-{max_delay}ç§’")

            return jsonify({
                'success': True,
                'min_delay': min_delay,
                'max_delay': max_delay,
                'description': f'{min_delay}-{max_delay}ç§’éšæœºå»¶è¿Ÿ',
                'message': 'å…¨å±€å›å¤å»¶è¿Ÿè®¾ç½®å·²æ›´æ–°ï¼Œæ‰€æœ‰è‡ªåŠ¨å›å¤å°†ä½¿ç”¨æ­¤è®¾ç½®'
            })
        else:
            return jsonify({'error': 'ä¿å­˜å¤±è´¥'}), 500

    except Exception as e:
        logger.error(f"æ›´æ–°å…¨å±€å›å¤å»¶è¿Ÿå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-channel', methods=['GET'])
def get_discord_channel():
    """è·å–Discordé¢‘é“é…ç½®"""
    try:
        sys_config = db.get_system_config()
        return jsonify({
            'channel_id': sys_config['discord_channel_id'],
            'cnfans_channel_id': sys_config['cnfans_channel_id'],
            'acbuy_channel_id': sys_config['acbuy_channel_id']
        })
    except Exception as e:
        logger.error(f"è·å–Discordé¢‘é“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/discord-channel', methods=['POST'])
def update_discord_channel():
    """æ›´æ–°Discordé¢‘é“é…ç½®"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({'error': 'Invalid request body'}), 400

        channel_id = data.get('channel_id', '').strip()
        cnfans_channel_id = data.get('cnfans_channel_id', '').strip()
        acbuy_channel_id = data.get('acbuy_channel_id', '').strip()

        # éªŒè¯é¢‘é“IDæ ¼å¼ï¼ˆåº”è¯¥æ˜¯æ•°å­—ï¼‰
        for cid_name, cid_value in [('channel_id', channel_id), ('cnfans_channel_id', cnfans_channel_id), ('acbuy_channel_id', acbuy_channel_id)]:
            if cid_value and not cid_value.isdigit():
                return jsonify({'error': f'{cid_name} å¿…é¡»æ˜¯æ•°å­—'}), 400

        # ä¿å­˜åˆ°æ•°æ®åº“
        if db.update_system_config(
            discord_channel_id=channel_id,
            cnfans_channel_id=cnfans_channel_id,
            acbuy_channel_id=acbuy_channel_id
        ):
            # åŒæ—¶æ›´æ–°ç¯å¢ƒå˜é‡å’Œbot_config
            if channel_id:
                os.environ['DISCORD_CHANNEL_ID'] = channel_id
                import bot_config
                bot_config.config.DISCORD_CHANNEL_ID = int(channel_id)
                logger.info(f"Discordé¢‘é“IDè®¾ç½®ä¸º: {channel_id}")
            else:
                os.environ.pop('DISCORD_CHANNEL_ID', None)
                import bot_config
                bot_config.config.DISCORD_CHANNEL_ID = 0
                logger.info("Discordé¢‘é“IDå·²æ¸…é™¤")

            return jsonify({
                'success': True,
                'channel_id': channel_id,
                'message': f'Discordé¢‘é“IDå·²è®¾ç½®ä¸º: {channel_id or "æ— (ç›‘å¬æ‰€æœ‰é¢‘é“)"}'
            })
        else:
            return jsonify({'error': 'ä¿å­˜å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ›´æ–°Discordé¢‘é“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history', methods=['GET'])
def get_search_history():
    """è·å–æœç´¢å†å²è®°å½•ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    try:
        limit = min(int(request.args.get('limit', 20)), 100)  # æœ€å¤š100æ¡
        offset = max(int(request.args.get('offset', 0)), 0)
        page = max(int(request.args.get('page', 1)), 1)

        # å¦‚æœæä¾›äº†pageå‚æ•°ï¼Œè®¡ç®—offset
        if 'page' in request.args and 'offset' not in request.args:
            offset = (page - 1) * limit

        result = db.get_search_history(limit, offset)
        return jsonify(result)
    except Exception as e:
        logger.error(f"è·å–æœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_similar_text', methods=['POST'])
def search_similar_text():
    """æ ¹æ®æ–‡å­—å…³é”®è¯æœç´¢ç›¸ä¼¼å•†å“"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Invalid request body'}), 400

        query = data.get('query', '').strip()
        limit = min(int(data.get('limit', 5)), 20)  # æœ€å¤š20ä¸ªç»“æœ

        if not query:
            return jsonify({'error': 'Query is required'}), 400

        logger.info(f'æ–‡å­—æœç´¢è¯·æ±‚: "{query}", é™åˆ¶: {limit}')

        # åœ¨æ•°æ®åº“ä¸­æœç´¢åŒ…å«å…³é”®è¯çš„å•†å“
        with db.get_connection() as conn:
            cursor = conn.cursor()

            # ä½¿ç”¨LIKEæŸ¥è¯¢åœ¨æ ‡é¢˜å’Œè‹±æ–‡æ ‡é¢˜ä¸­æœç´¢
            cursor.execute("""
                SELECT id, product_url, title, english_title, description,
                       ruleEnabled, min_delay, max_delay, created_at,
                       cnfans_url
                FROM products
                WHERE (title LIKE ? OR english_title LIKE ? OR description LIKE ?)
                  AND ruleEnabled = 1
                ORDER BY created_at DESC
                LIMIT ?
            """, (f'%{query}%', f'%{query}%', f'%{query}%', limit))

            rows = cursor.fetchall()

            products = []
            for row in rows:
                prod = dict(row)
                # è·å–å›¾ç‰‡
                cursor.execute("SELECT image_path FROM product_images WHERE product_id = ? ORDER BY image_index LIMIT 1", (prod['id'],))
                img_row = cursor.fetchone()
                if img_row:
                    prod['image'] = f"/api/image/{prod['id']}/0"
                else:
                    prod['image'] = None

                # æ ¼å¼åŒ–å­—æ®µ
                prod['weidianUrl'] = prod.get('product_url')
                prod['englishTitle'] = prod.get('english_title') or ''
                prod['cnfansUrl'] = prod.get('cnfans_url') or ''
                prod['autoReplyEnabled'] = prod.get('ruleEnabled', True)
                # ä»URLä¸­æå–weidian ID
                try:
                    import re
                    m = re.search(r'itemID=(\d+)', prod.get('product_url') or '')
                    prod['weidianId'] = m.group(1) if m else ''
                except:
                    prod['weidianId'] = ''

                products.append(prod)

        logger.info(f'æ–‡å­—æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(products)} ä¸ªå•†å“')

        return jsonify({
            'success': True,
            'query': query,
            'products': products,
            'total': len(products)
        })

    except Exception as e:
        logger.error(f"æ–‡å­—æœç´¢å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history/<int:history_id>', methods=['DELETE'])
def delete_search_history(history_id):
    """åˆ é™¤æœç´¢å†å²è®°å½•"""
    try:
        if db.delete_search_history(history_id):
            return jsonify({'success': True})
        else:
            return jsonify({'error': 'è®°å½•ä¸å­˜åœ¨'}), 404
    except Exception as e:
        logger.error(f"åˆ é™¤æœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/search_history', methods=['DELETE'])
def clear_search_history():
    """æ¸…ç©ºæ‰€æœ‰æœç´¢å†å²"""
    try:
        if db.clear_search_history():
            return jsonify({'success': True})
        else:
            return jsonify({'error': 'æ¸…ç©ºå¤±è´¥'}), 500
    except Exception as e:
        logger.error(f"æ¸…ç©ºæœç´¢å†å²å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/logs/stream')
def log_stream():
    """Server-Sent Events æ—¥å¿—æµ"""
    import json

    def generate():
        # ä¸ºè¿™ä¸ªå®¢æˆ·ç«¯åˆ›å»ºé˜Ÿåˆ—
        client_queue = queue.Queue(maxsize=100)  # é™åˆ¶é˜Ÿåˆ—å¤§å°
        log_clients.append(client_queue)

        try:
            # å‘é€æœ€è¿‘çš„æ—¥å¿—å†å²
            for log_entry in all_logs[-20:]:  # å‘é€æœ€è¿‘20æ¡å†å²æ—¥å¿—
                yield f"data: {json.dumps(log_entry)}\n\n"

            # æŒç»­ç›‘å¬æ–°æ—¥å¿—
            while True:
                try:
                    # ç­‰å¾…æ–°æ—¥å¿—ï¼Œè¶…æ—¶æ—¶é—´è®¾ä¸º30ç§’
                    log_entry = client_queue.get(timeout=30)
                    yield f"data: {json.dumps(log_entry)}\n\n"
                except queue.Empty:
                    # å‘é€å¿ƒè·³åŒ…ä¿æŒè¿æ¥
                    yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': datetime.now().isoformat()})}\n\n"

        except GeneratorExit:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            pass
        finally:
            # æ¸…ç†å®¢æˆ·ç«¯é˜Ÿåˆ—
            if client_queue in log_clients:
                log_clients.remove(client_queue)

    return Response(generate(), mimetype='text/event-stream',
                   headers={'Cache-Control': 'no-cache',
                           'Access-Control-Allow-Origin': '*',
                           'Access-Control-Allow-Headers': 'Cache-Control'})

@app.route('/api/logs/recent')
def get_recent_logs():
    """è·å–æœ€è¿‘çš„æ—¥å¿—è®°å½•"""
    try:
        # ä»æ—¥å¿—åˆ—è¡¨ä¸­è¿”å›æœ€è¿‘50æ¡æ—¥å¿—
        return jsonify({
            'logs': all_logs[-50:],
            'total': len(all_logs)
        })
    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘æ—¥å¿—å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/logs/add', methods=['POST'])
def add_external_log():
    """æ¥æ”¶å¤–éƒ¨è¿›ç¨‹å‘é€çš„æ—¥å¿—"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Invalid log data'}), 400

        # åˆ›å»ºæ—¥å¿—æ¡ç›®
        log_entry = {
            'timestamp': data.get('timestamp', datetime.now().isoformat()),
            'level': data.get('level', 'INFO'),
            'message': data.get('message', ''),
            'module': data.get('module', 'external'),
            'func': data.get('func', '')
        }

        # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨
        all_logs.append(log_entry)
        if len(all_logs) > 200:
            all_logs.pop(0)

        # æ·»åŠ åˆ°é˜Ÿåˆ—
        log_queue.put(log_entry)

        return jsonify({'success': True})
    except Exception as e:
        print(f"æ·»åŠ å¤–éƒ¨æ—¥å¿—å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

def start_discord_bot(user_id=None):
    """å¯åŠ¨Discordæœºå™¨äºº - æ”¯æŒå¤šè´¦å·"""
    global bot_clients, bot_tasks, bot_running

    if bot_running:
        logger.warning("æœºå™¨äººå·²ç»åœ¨è¿è¡Œä¸­")
        return

    try:
        import asyncio
        from bot import DiscordBotClient

        logger.info(f"æ­£åœ¨å¯åŠ¨Discordæœºå™¨äºº... (ç”¨æˆ·ID: {user_id})")

        # è·å–è´¦å· - å¦‚æœæŒ‡å®šäº†ç”¨æˆ·IDï¼Œåªè·å–è¯¥ç”¨æˆ·çš„è´¦å·
        if user_id:
            accounts = db.get_discord_accounts_by_user(user_id)
        else:
            # è·å–æ‰€æœ‰è´¦å·
            accounts = db.get_discord_accounts_by_user(None)

        if not accounts:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Discordè´¦å·")
            return

        logger.info(f"æ‰¾åˆ° {len(accounts)} ä¸ªDiscordè´¦å·ï¼Œå¼€å§‹å¯åŠ¨...")

        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œæœºå™¨äºº
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # ä¸ºæ¯ä¸ªè´¦å·åˆ›å»ºæœºå™¨äººå®ä¾‹
        for account in accounts:
            account_id = account['id']
            token = account['token']
            username = account.get('username', f'account_{account_id}')
            user_id = account.get('user_id')

            # è·å–ç”¨æˆ·ç®¡ç†çš„åº—é“º
            user_shops = None
            if user_id:
                user = db.get_user_by_id(user_id)
                if user:
                    user_shops = user.get('shops', [])

            # ç¡®å®šè´¦å·è§’è‰²ï¼šæ£€æŸ¥æ˜¯å¦ç»‘å®šäº†ä»»ä½•ç½‘ç«™é…ç½®
            account_bindings = db.get_account_website_bindings(account_id)
            if account_bindings:
                # æ£€æŸ¥è´¦å·æ˜¯å¦æœ‰å‘é€æˆ–ç›‘å¬è§’è‰²
                has_sender = any(b['role'] in ['sender', 'both'] for b in account_bindings)
                has_listener = any(b['role'] in ['listener', 'both'] for b in account_bindings)

                if has_sender and has_listener:
                    role = 'both'
                elif has_sender:
                    role = 'sender'
                elif has_listener:
                    role = 'listener'
                else:
                    role = 'both'  # é»˜è®¤
            else:
                role = 'both'  # æœªç»‘å®šçš„è´¦å·é»˜è®¤ä¸ºboth

            logger.info(f"æ­£åœ¨å¯åŠ¨æœºå™¨äººè´¦å·: {username} (ç”¨æˆ·ID: {user_id}, ç®¡ç†åº—é“º: {user_shops}, è§’è‰²: {role})")

            # åˆ›å»ºæœºå™¨äººå®ä¾‹ï¼Œä¼ å…¥è§’è‰²å‚æ•°
            client = DiscordBotClient(account_id=account_id, user_id=user_id, user_shops=user_shops, role=role)

            # å¯åŠ¨æœºå™¨äºº
            try:
                task = loop.create_task(client.start(token, reconnect=True))
                bot_clients.append(client)
                bot_tasks.append(task)
                logger.info(f"Discordæœºå™¨äººå¯åŠ¨æˆåŠŸ: {username}")
            except Exception as e:
                logger.error(f"å¯åŠ¨æœºå™¨äººå¤±è´¥ {username}: {e}")

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        import threading
        bot_thread = threading.Thread(target=loop.run_forever, daemon=True)
        bot_thread.start()

        if bot_clients:
            bot_running = True
            logger.info(f"å…±å¯åŠ¨äº† {len(bot_clients)} ä¸ªDiscordæœºå™¨äºº")
        else:
            logger.warning("æ²¡æœ‰æˆåŠŸå¯åŠ¨ä»»ä½•æœºå™¨äºº")

    except ImportError as e:
        logger.warning(f"Discordæœºå™¨äººæ¨¡å—ä¸å¯ç”¨: {e}")
        logger.info("Flaskåº”ç”¨å°†ç»§ç»­è¿è¡Œï¼Œä½†æœºå™¨äººåŠŸèƒ½ä¸å¯ç”¨")
    except Exception as e:
        logger.error(f"Discordæœºå™¨äººå¯åŠ¨å¤±è´¥: {e}")
        logger.info("Flaskåº”ç”¨å°†ç»§ç»­è¿è¡Œï¼Œä½†æœºå™¨äººåŠŸèƒ½ä¸å¯ç”¨")

def stop_discord_bot():
    """åœæ­¢Discordæœºå™¨äºº"""
    global bot_clients, bot_tasks, bot_running

    if not bot_running:
        logger.info("æœºå™¨äººæœªåœ¨è¿è¡Œ")
        return

    if bot_clients:
        logger.info(f"æ­£åœ¨åœæ­¢ {len(bot_clients)} ä¸ªDiscordæœºå™¨äºº...")
        try:
            import asyncio
            # åˆ›å»ºä»»åŠ¡æ¥åœæ­¢æ‰€æœ‰æœºå™¨äºº
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            for i, client in enumerate(bot_clients):
                try:
                    if client and not client.is_closed():
                        # æ›´æ–°è´¦å·çŠ¶æ€ä¸ºoffline
                        if hasattr(client, 'account_id') and client.account_id:
                            db.update_account_status(client.account_id, 'offline')
                            logger.info(f"è´¦å· {client.account_id} çŠ¶æ€å·²æ›´æ–°ä¸ºç¦»çº¿")
                        loop.run_until_complete(client.close())
                        logger.info(f"Discordæœºå™¨äºº {i+1} å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"åœæ­¢æœºå™¨äºº {i+1} æ—¶å‡ºé”™: {e}")

            logger.info("æ‰€æœ‰Discordæœºå™¨äººå·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢æœºå™¨äººæ—¶å‡ºé”™: {e}")

    # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
    for task in bot_tasks:
        if task and not task.done():
            task.cancel()

    # æ¸…ç©ºæœºå™¨äººåˆ—è¡¨
    bot_clients.clear()
    bot_tasks.clear()
    bot_running = False

# ===== æœºå™¨äººæ§åˆ¶API =====

@app.route('/api/bot/start', methods=['POST'])
def start_bot():
    """å¯åŠ¨Discordæœºå™¨äºº"""
    if not require_login():
        return jsonify({'error': 'éœ€è¦ç™»å½•'}), 401

    try:
        data = request.get_json()
        user_id = data.get('userId')

        if not user_id:
            return jsonify({'error': 'éœ€è¦ç”¨æˆ·ID'}), 400

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™çš„è´¦å·
        user_accounts = db.get_discord_accounts_by_user(user_id)

        if not user_accounts:
            return jsonify({'error': 'ç”¨æˆ·æ²¡æœ‰Discordè´¦å·ï¼Œè¯·å…ˆæ·»åŠ è´¦å·'}), 400

        # å¯åŠ¨æœºå™¨äººï¼ˆå¯åŠ¨æ‰€æœ‰è´¦å·ï¼Œä¸ç®¡æ˜¯å¦åœ¨çº¿ï¼‰
        start_discord_bot(user_id)

        logger.info(f"ç”¨æˆ· {user_id} å¯åŠ¨æœºå™¨äººæˆåŠŸï¼Œå…±æœ‰ {len(user_accounts)} ä¸ªè´¦å·")
        return jsonify({
            'message': 'è´¦å·å¯åŠ¨æˆåŠŸ',
            'totalAccounts': len(user_accounts)
        })

    except Exception as e:
        logger.error(f"å¯åŠ¨æœºå™¨äººå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/bot/stop', methods=['POST'])
def stop_bot():
    """åœæ­¢Discordæœºå™¨äºº"""
    try:
        stop_discord_bot()
        logger.info("æœºå™¨äººåœæ­¢æˆåŠŸ")
        return jsonify({'message': 'æœºå™¨äººåœæ­¢æˆåŠŸ'})

    except Exception as e:
        logger.error(f"åœæ­¢æœºå™¨äººå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/bot/status', methods=['GET'])
def get_bot_status():
    """è·å–Discordæœºå™¨äººå…¨å±€è¿è¡ŒçŠ¶æ€"""
    try:
        # é€šè¿‡æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰è´¦å·çŠ¶æ€ä¸ºonlineæ¥ç¡®å®šæœºå™¨äººæ˜¯å¦åœ¨è¿è¡Œ
        # è¿™æ ·å¯ä»¥é¿å…ä¾èµ–å†…å­˜ä¸­çš„å…¨å±€å˜é‡ï¼Œåœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸‹æ›´å¯é 
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM discord_accounts WHERE status = 'online'")
            online_count = cursor.fetchone()[0]
            is_running = online_count > 0
        return jsonify({'running': is_running})
    except Exception as e:
        logger.error(f"è·å–æœºå™¨äººçŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'running': False}), 500

@app.route('/api/shop-info', methods=['GET'])
def get_shop_info():
    """è·å–åº—é“ºä¿¡æ¯"""
    try:
        shop_id = request.args.get('shopId')
        if not shop_id:
            return jsonify({'error': 'ç¼ºå°‘shopIdå‚æ•°'}), 400

        shop_id = shop_id.strip()
        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        logger.info(f'è·å–åº—é“ºä¿¡æ¯: {shop_id}')

        # è°ƒç”¨å¾®åº—APIè·å–åº—é“ºä¿¡æ¯
        try:
            param = json.dumps({"shop_id": shop_id, "page_id": 0})
            encoded_param = quote(param)

            api_url = f"https://thor.weidian.com/decorate/customSharePage.getPageInfo/1.0?param={encoded_param}&wdtoken=8ea9315c&_={int(time.time() * 1000)}"

            response = requests.get(api_url, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
                'Origin': 'https://weidian.com',
                'Referer': 'https://weidian.com/',
                'Sec-Ch-Ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"macOS"',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-site',
            }, cookies={
                'wdtoken': '8ea9315c',
                '__spider__visitorid': '0dcf6a5b878847ec',
                'visitor_id': '4d36e980-4128-451c-8178-a976b6303114',
                'v-components/cpn-coupon-dialog@nologinshop': '10',
                '__spider__sessionid': 'e55c6458ac1fdba4'
            }, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if data.get('status', {}).get('code') == 0:
                    shop_name = data.get('result', {}).get('shareTitle', f'åº—é“º {shop_id}')
                    return jsonify({'shopName': shop_name})
                else:
                    logger.warning(f'APIè¿”å›é”™è¯¯çŠ¶æ€: {data}')
            else:
                logger.warning(f'APIè¯·æ±‚å¤±è´¥: {response.status_code}')

        except Exception as e:
            logger.error(f'è·å–åº—é“ºä¿¡æ¯å¤±è´¥: {e}')

        # å¦‚æœAPIå¤±è´¥ï¼Œè¿”å›é»˜è®¤åç§°
        return jsonify({'shopName': f'åº—é“º {shop_id}'})

    except Exception as e:
        logger.error(f'è·å–åº—é“ºä¿¡æ¯å‡ºé”™: {e}')
        return jsonify({'error': 'è·å–åº—é“ºä¿¡æ¯å¤±è´¥'}), 500

# ===== åº—é“ºç®¡ç†API =====

@app.route('/api/shops', methods=['GET'])
def get_shops():
    """è·å–æ‰€æœ‰åº—é“ºåˆ—è¡¨"""
    try:
        shops = db.get_all_shops()
        return jsonify({'shops': shops})
    except Exception as e:
        logger.error(f'è·å–åº—é“ºåˆ—è¡¨å¤±è´¥: {e}')
        return jsonify({'error': 'è·å–åº—é“ºåˆ—è¡¨å¤±è´¥'}), 500

@app.route('/api/shops', methods=['POST'])
def add_shop():
    """æ·»åŠ æ–°åº—é“º"""
    if not can_manage_shops():
        return jsonify({'error': 'éœ€è¦ç®¡ç†åº—é“ºçš„æƒé™'}), 403

    try:
        data = request.get_json()
        if not data or not data.get('shopId') or not data.get('name'):
            return jsonify({'error': 'ç¼ºå°‘shopIdæˆ–nameå‚æ•°'}), 400

        shop_id = data['shopId'].strip()
        name = data['name'].strip()

        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        # è·å–çœŸå®çš„åº—é“ºåç§°
        shop_info = get_shop_info_from_api(shop_id)
        if shop_info and shop_info.get('shopName'):
            name = shop_info['shopName']

        if db.add_shop(shop_id, name):
            return jsonify({'success': True, 'message': 'åº—é“ºæ·»åŠ æˆåŠŸ'})
        else:
            return jsonify({'error': 'åº—é“ºå·²å­˜åœ¨æˆ–æ·»åŠ å¤±è´¥'}), 400
    except Exception as e:
        logger.error(f'æ·»åŠ åº—é“ºå¤±è´¥: {e}')
        return jsonify({'error': 'æ·»åŠ åº—é“ºå¤±è´¥'}), 500

@app.route('/api/shops/<shop_id>', methods=['DELETE'])
def delete_shop(shop_id):
    """åˆ é™¤åº—é“º"""
    if not can_manage_shops():
        return jsonify({'error': 'éœ€è¦ç®¡ç†åº—é“ºçš„æƒé™'}), 403

    try:
        # è·å–åº—é“ºä¿¡æ¯ï¼Œæ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™åˆ é™¤
        shop_info = db.get_shop_by_id(shop_id)
        if not shop_info:
            return jsonify({'error': 'åº—é“ºä¸å­˜åœ¨'}), 404

        current_user = get_current_user()
        # ç®¡ç†å‘˜å¯ä»¥åˆ é™¤ä»»ä½•åº—é“ºï¼Œæ™®é€šç”¨æˆ·åªèƒ½åˆ é™¤åˆ†é…ç»™ä»–ä»¬çš„åº—é“º
        if current_user['role'] != 'admin' and shop_info['shop_id'] not in current_user.get('shops', []):
            return jsonify({'error': 'æ— æƒé™åˆ é™¤æ­¤åº—é“º'}), 403

        if db.delete_shop(shop_id):
            return jsonify({'success': True, 'message': 'åº—é“ºåˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500
    except Exception as e:
        logger.error(f'åˆ é™¤åº—é“ºå¤±è´¥: {e}')
        return jsonify({'error': 'åˆ é™¤åº—é“ºå¤±è´¥'}), 500

def get_shop_info_from_api(shop_id):
    """ä»APIè·å–åº—é“ºä¿¡æ¯"""
    try:
        import json
        from urllib.parse import quote
        import time

        param = json.dumps({"shop_id": shop_id, "page_id": 0})
        encoded_param = quote(param)

        api_url = f"https://thor.weidian.com/decorate/customSharePage.getPageInfo/1.0?param={encoded_param}&wdtoken=8ea9315c&_={int(time.time() * 1000)}"

        response = requests.get(api_url, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
            'Origin': 'https://weidian.com',
            'Referer': 'https://weidian.com/',
            'Sec-Ch-Ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
        }, cookies={
            'wdtoken': '8ea9315c',
            '__spider__visitorid': '0dcf6a5b878847ec',
            'visitor_id': '4d36e980-4128-451c-8178-a976b6303114',
            'v-components/cpn-coupon-dialog@nologinshop': '2',
            '__spider__sessionid': 'c7da7d6e06b1f1ac'
        }, timeout=10, proxies={'http': None, 'https': None})

        if response.status_code == 200:
            data = response.json()
            if data.get('status', {}).get('code') == 0:
                result = data.get('result', {})
                shop_name = result.get('shareTitle', '')
                if shop_name:
                    return {'shopName': shop_name}

    except Exception as e:
        logger.warning(f'è·å–åº—é“ºä¿¡æ¯å¤±è´¥: {e}')

    return None

@app.route('/api/scrape/shop', methods=['POST'])
def scrape_shop():
    """æŠ“å–æ•´ä¸ªåº—é“ºçš„æ‰€æœ‰å•†å“"""
    if not can_manage_shops():
        return jsonify({'error': 'éœ€è¦ç®¡ç†åº—é“ºçš„æƒé™'}), 403

    try:
        data = request.get_json()
        if not data or not data.get('shopId'):
            return jsonify({'error': 'ç¼ºå°‘shopIdå‚æ•°'}), 400

        shop_id = data['shopId'].strip()
        if not shop_id.isdigit():
            return jsonify({'error': 'shopIdå¿…é¡»æ˜¯æ•°å­—'}), 400

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ“å–ä»»åŠ¡åœ¨è¿è¡Œ
        current_status = db.get_scrape_status()
        if current_status.get('is_scraping', False):
            return jsonify({'error': 'å·²æœ‰æŠ“å–ä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•'}), 409

        logger.info(f'å¼€å§‹æŠ“å–åº—é“º: {shop_id}')

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒæŠ“å–ä»»åŠ¡ï¼Œé¿å…é˜»å¡å…¶ä»–æ“ä½œ
        import threading

        def run_scrape_task():
            """åå°æŠ“å–ä»»åŠ¡"""
            try:
                scrape_shop_products(shop_id)
            except Exception as e:
                logger.error(f'æŠ“å–ä»»åŠ¡å¼‚å¸¸: {e}')
            finally:
                # ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
                error_msg = f'æŠ“å–å¼‚å¸¸ç»“æŸ: {str(e)}' if 'e' in locals() else 'æŠ“å–å·²å®Œæˆ'
                db.update_scrape_status(is_scraping=False, message=error_msg)

        # åˆ›å»ºå®ˆæŠ¤çº¿ç¨‹ï¼Œç¡®ä¿ä¸ä¼šé˜»å¡åº”ç”¨é€€å‡º
        scrape_thread = threading.Thread(target=run_scrape_task, daemon=True, name=f'scrape-{shop_id}')
        scrape_thread.start()

        logger.info(f'å·²å¯åŠ¨åå°æŠ“å–çº¿ç¨‹å¤„ç†åº—é“º {shop_id}')

        return jsonify({
            'success': True,
            'message': 'æŠ“å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹è¿›åº¦'
        })

    except Exception as e:
        logger.error(f'åº—é“ºæŠ“å–å¤±è´¥: {e}')
        return jsonify({'error': str(e)        }), 500


@app.route('/api/scrape/shop/control', methods=['POST'])
def control_shop_scrape():
    """æ§åˆ¶æŠ“å–ä»»åŠ¡: start, stop"""
    action = request.json.get('action')
    shop_id = request.json.get('shopId')  # å¯é€‰å‚æ•°

    global current_scrape_thread, scrape_thread_lock, scrape_stop_event

    # è·å–å½“å‰çŠ¶æ€
    current_status = db.get_scrape_status()
    logger.info(f"æ”¶åˆ°æŠ“å–æ§åˆ¶è¯·æ±‚: action={action}, shop_id={shop_id}, å½“å‰çŠ¶æ€: is_scraping={current_status.get('is_scraping')}, stop_signal={current_status.get('stop_signal')}")

    if action == 'stop':
        # ç«‹å³åœæ­¢ - è®¾ç½®åœæ­¢äº‹ä»¶å’Œæ•°æ®åº“çŠ¶æ€
        scrape_stop_event.set()  # è®¾ç½®åœæ­¢äº‹ä»¶ï¼Œé€šçŸ¥çº¿ç¨‹åœæ­¢

        success = db.update_scrape_status(
            is_scraping=False,
            stop_signal=True,
            completed=True,
            message='æŠ“å–å·²åœæ­¢',
            progress=100
        )

        if success:
            logger.info("âœ… æŠ“å–ä»»åŠ¡å·²å¼ºåˆ¶åœæ­¢")

            # ç­‰å¾…çº¿ç¨‹ç»ˆæ­¢ï¼ˆæœ€å¤šç­‰å¾…10ç§’ï¼‰
            with scrape_thread_lock:
                if current_scrape_thread and current_scrape_thread.is_alive():
                    logger.info("ç­‰å¾…æŠ“å–çº¿ç¨‹ç»ˆæ­¢...")
                    current_scrape_thread.join(timeout=10.0)
                    if current_scrape_thread.is_alive():
                        logger.warning("æŠ“å–çº¿ç¨‹æœªèƒ½åœ¨10ç§’å†…ç»ˆæ­¢")
                    current_scrape_thread = None

            updated_status = db.get_scrape_status()
            return jsonify(updated_status)
        else:
            return jsonify({'error': 'åœæ­¢æŠ“å–å¤±è´¥'}), 500

    if action == 'start':
        if current_status.get('is_scraping', False):
            return jsonify({'error': 'å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œ'}), 400

        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹åœ¨è¿è¡Œ
        with scrape_thread_lock:
            if current_scrape_thread and current_scrape_thread.is_alive():
                return jsonify({'error': 'å·²æœ‰çº¿ç¨‹åœ¨è¿è¡Œ'}), 400

        # æ¸…é™¤åœæ­¢äº‹ä»¶ï¼Œä¸ºæ–°ä»»åŠ¡åšå‡†å¤‡
        scrape_stop_event.clear()

        # é‡ç½®çŠ¶æ€
        success = db.update_scrape_status(
            is_scraping=True,
            stop_signal=False,
            current_shop_id=shop_id,
            total=0,
            processed=0,
            success=0,
            progress=0,
            message='åˆå§‹åŒ–æŠ“å–...',
            completed=False,
            thread_id=None
        )

        if not success:
            return jsonify({'error': 'é‡ç½®çŠ¶æ€å¤±è´¥'}), 500

        # å¼‚æ­¥å¯åŠ¨
        with scrape_thread_lock:
            current_scrape_thread = threading.Thread(
                target=run_shop_scrape_task,
                args=(shop_id,),
                daemon=True,
                name=f'scrape-{shop_id}'
            )
            current_scrape_thread.start()

            # æ›´æ–°çº¿ç¨‹IDåˆ°æ•°æ®åº“
            db.update_scrape_status(thread_id=current_scrape_thread.ident)

        updated_status = db.get_scrape_status()
        return jsonify(updated_status)

    return jsonify({'error': 'Invalid action'}), 400

@app.route('/api/scrape/batch', methods=['POST'])
def batch_scrape_products():
    """æ‰¹é‡æŠ“å–å¤šä¸ªå•†å“ï¼ˆé«˜æ€§èƒ½å¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
    # åœ¨å‡½æ•°å¼€å§‹å°±å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—ï¼Œé¿å…å˜é‡ä½œç”¨åŸŸé—®é¢˜
    import concurrent.futures
    import time
    import threading

    # ç¡®ä¿threadingå˜é‡åœ¨å‡½æ•°ä½œç”¨åŸŸå†…å¯ç”¨
    threading = threading

    try:
        data = request.get_json()
        if not data or not data.get('productIds'):
            return jsonify({'error': 'ç¼ºå°‘productIdså‚æ•°'}), 400

        product_ids = data.get('productIds', [])
        if not isinstance(product_ids, list) or len(product_ids) == 0:
            return jsonify({'error': 'productIdså¿…é¡»æ˜¯éç©ºæ•°ç»„'}), 400

        # ====================================================
        # ä¿®å¤ï¼šç¡®ä¿SCRAPE_THREADSä»configæ­£ç¡®è·å–
        # ====================================================
        max_threads = getattr(config, 'SCRAPE_THREADS', 10)

        # åˆ›å»ºåœæ­¢äº‹ä»¶ç”¨äºä¼˜é›…å…³é—­
        shutdown_event = threading.Event()

        logger.info(f"âœ… å¼€å§‹æ‰¹é‡æŠ“å– {len(product_ids)} ä¸ªå•†å“ï¼Œä½¿ç”¨ {max_threads} ä¸ªçº¿ç¨‹")

        results = {
            'total': len(product_ids),
            'processed': 0,
            'success': 0,
            'skipped': 0,
            'cancelled': 0,
            'partial': 0,
            'errors': 0,
            'start_time': time.time()
        }

        def process_single_product_batch(product_id):
            """å¤„ç†å•ä¸ªå•†å“ï¼ˆç”¨äºçº¿ç¨‹æ± ï¼‰"""
            try:
                # === æ£€æŸ¥åœæ­¢ä¿¡å· ===
                current_status = db.get_scrape_status()
                if current_status.get('stop_signal', False):
                    logger.info(f"ğŸ”´ å¤„ç†å•†å“å‰æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå¤„ç†å•†å“ {product_id}")
                    return {'status': 'cancelled', 'product_id': product_id, 'message': 'ä»»åŠ¡å·²å–æ¶ˆ'}

                # è°ƒç”¨ç°æœ‰çš„å•ä¸ªå•†å“å¤„ç†é€»è¾‘
                from app import process_single_product

                # æ„å»ºå•†å“ä¿¡æ¯
                product_info = {
                    'item_id': str(product_id),
                    'item_url': f'https://weidian.com/item.html?itemID={product_id}',
                    'shop_name': 'æ‰¹é‡ä¸Šä¼ '
                }

                # å¤„ç†å•†å“
                product_data = process_single_product(product_info)

                if product_data:
                    # === å†æ¬¡æ£€æŸ¥åœæ­¢ä¿¡å· ===
                    current_status = db.get_scrape_status()
                    if current_status.get('stop_signal', False):
                        logger.info(f"ğŸ”´ è·å–å•†å“æ•°æ®åæ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œè·³è¿‡å•†å“ {product_id}")
                        return {'status': 'cancelled', 'product_id': product_id, 'message': 'ä»»åŠ¡å·²å–æ¶ˆ'}

                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    if db.get_product_by_url(product_data['product_url']):
                        return {'status': 'skipped', 'product_id': product_id, 'message': 'å•†å“å·²å­˜åœ¨'}

                    # å…¥åº“
                    product_id_db = db.insert_product(product_data)

                    # === å†æ¬¡æ£€æŸ¥åœæ­¢ä¿¡å· ===
                    current_status = db.get_scrape_status()
                    if current_status.get('stop_signal', False):
                        logger.info(f"ğŸ”´ å…¥åº“åæ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå•†å“ {product_id} å·²å…¥åº“ä½†è·³è¿‡å›¾ç‰‡å¤„ç†")
                        return {'status': 'partial', 'product_id': product_id, 'message': 'å•†å“å·²å…¥åº“ï¼Œå›¾ç‰‡å¤„ç†è¢«å–æ¶ˆ'}

                    # å¤„ç†å›¾ç‰‡ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„å¤šçº¿ç¨‹å›¾ç‰‡å¤„ç†ï¼‰
                    if product_data.get('images'):
                        save_product_images_unified(product_id_db, product_data['images'], shutdown_event=shutdown_event)

                    return {'status': 'success', 'product_id': product_id, 'message': 'å¤„ç†æˆåŠŸ'}
                else:
                    return {'status': 'error', 'product_id': product_id, 'message': 'è·å–å•†å“æ•°æ®å¤±è´¥'}

            except Exception as e:
                logger.error(f"å¤„ç†å•†å“ {product_id} å¤±è´¥: {e}")
                return {'status': 'error', 'product_id': product_id, 'message': str(e)}

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å•†å“
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_product = {
                executor.submit(process_single_product_batch, pid): pid
                for pid in product_ids
            }

            # æ”¶é›†ç»“æœ - æ”¯æŒä¼˜é›…åœæ­¢
            pending_futures = set(future_to_product.keys())
            stop_detected = False

            try:
                while pending_futures:
                    # æ£€æŸ¥æ˜¯å¦æœ‰åœæ­¢ä¿¡å·æˆ–å…³é—­äº‹ä»¶
                    current_status = db.get_scrape_status()
                    should_stop = (current_status.get('stop_signal', False) or
                                 (shutdown_event and shutdown_event.is_set()))

                    if should_stop and not stop_detected:
                        logger.info("ğŸ”´ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ç­‰å¾…å·²æäº¤çš„ä»»åŠ¡å®Œæˆ...")
                        db.update_scrape_status(message='æ­£åœ¨ç­‰å¾…å½“å‰å•†å“å®Œæˆ...')
                        stop_detected = True
                        # ä¸å…³é—­çº¿ç¨‹æ± ï¼Œè®©å·²æäº¤çš„ä»»åŠ¡ç»§ç»­å®Œæˆ

                    # ç­‰å¾…ä»»æ„ä¸€ä¸ªä»»åŠ¡å®Œæˆ
                    done, pending_futures = concurrent.futures.wait(
                        pending_futures,
                        timeout=1.0,
                        return_when=concurrent.futures.FIRST_COMPLETED
                    )

                    # å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                    for future in done:
                        product_id = future_to_product[future]
                        try:
                            result = future.result()
                            results['processed'] += 1

                            if result['status'] == 'success':
                                results['success'] += 1
                                logger.info(f"å•†å“ {product_id} å¤„ç†æˆåŠŸ")
                            elif result['status'] == 'skipped':
                                results['skipped'] += 1
                                logger.info(f"å•†å“ {product_id} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                            elif result['status'] == 'cancelled':
                                results['cancelled'] += 1
                                logger.info(f"å•†å“ {product_id} å¤„ç†è¢«å–æ¶ˆ")
                            elif result['status'] == 'partial':
                                results['partial'] += 1
                                logger.info(f"å•†å“ {product_id} éƒ¨åˆ†å®Œæˆï¼ˆå·²å…¥åº“ï¼Œå›¾ç‰‡å¤„ç†è¢«å–æ¶ˆï¼‰")
                            else:
                                results['errors'] += 1
                                logger.error(f"å•†å“ {product_id} å¤„ç†å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

                        except Exception as e:
                            results['processed'] += 1
                            results['errors'] += 1
                            logger.error(f"å¤„ç†å•†å“ {product_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

                    # å¦‚æœæ£€æµ‹åˆ°åœæ­¢ä¿¡å·ä¸”æ²¡æœ‰å¾…å¤„ç†çš„ä»»åŠ¡ï¼Œé€€å‡ºå¾ªç¯
                    if stop_detected and len(pending_futures) == 0:
                        logger.info("âœ… æ‰€æœ‰å·²æäº¤çš„ä»»åŠ¡å·²å®Œæˆï¼Œé€€å‡ºæ‰¹é‡å¤„ç†")
                        break

            except KeyboardInterrupt:
                logger.warning("æ”¶åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
                executor.shutdown(wait=True, timeout=10.0)
                raise
            finally:
                # ç¡®ä¿çº¿ç¨‹æ± è¢«æ­£ç¡®å…³é—­
                if not executor._shutdown:
                    executor.shutdown(wait=False)

        # è®¡ç®—å¤„ç†æ—¶é—´
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']

        logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {results}")

        # æ³¨æ„ï¼šæ‰¹é‡æŠ“å–ä¸åº”è¯¥é‡ç½®åº—é“ºæŠ“å–çš„çŠ¶æ€
        # æ‰¹é‡æŠ“å–æœ‰è‡ªå·±çš„çŠ¶æ€ç®¡ç†ï¼Œä¸å½±å“åº—é“ºæŠ“å–çš„çŠ¶æ€æ˜¾ç¤º

        return jsonify({
            'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {results["total"]} ä¸ªå•†å“ï¼ŒæˆåŠŸ {results["success"]} ä¸ªï¼Œè·³è¿‡ {results["skipped"]} ä¸ªï¼Œå–æ¶ˆ {results["cancelled"]} ä¸ªï¼Œéƒ¨åˆ†å®Œæˆ {results["partial"]} ä¸ªï¼Œå¤±è´¥ {results["errors"]} ä¸ª',
            'results': results
        })

    except Exception as e:
        logger.error(f"æ‰¹é‡æŠ“å–å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯å‘ç”Ÿåœ¨: {e.__class__.__name__}")
        import traceback
        logger.error(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        return jsonify({'error': f'æ‰¹é‡æŠ“å–å¤±è´¥: {str(e)}'}), 500

@app.route('/api/scrape/shop/status', methods=['GET'])
def get_scrape_status():
    """è·å–æŠ“å–çŠ¶æ€"""
    try:
        status = db.get_scrape_status()

        # ç¡®ä¿è¿”å›å¿…è¦çš„å­—æ®µï¼ˆå…¼å®¹å‰ç«¯æœŸæœ›çš„å­—æ®µåï¼‰
        result = {
            'is_scraping': status.get('is_scraping', False),
            'progress': status.get('progress', 0),
            'total': status.get('total', 0),
            'current': status.get('processed', 0),  # å‰ç«¯æœŸæœ›currentå­—æ®µ
            'processed': status.get('processed', 0),
            'success': status.get('success', 0),
            'message': status.get('message', ''),
            'completed': status.get('completed', False),
            'current_shop_id': status.get('current_shop_id'),
            'thread_id': status.get('thread_id')
        }

        # è°ƒè¯•æ—¥å¿—
        logger.debug(f"DEBUG: Scrape status - is_scraping: {result.get('is_scraping')}, message: {result.get('message')}")

        return jsonify(result)
    except Exception as e:
        logger.error(f'è·å–æŠ“å–çŠ¶æ€å¤±è´¥: {e}')
        return jsonify({
            'is_scraping': False,
            'progress': 0,
            'total': 0,
            'current': 0,
            'processed': 0,
            'success': 0,
            'message': 'è·å–çŠ¶æ€å¤±è´¥',
            'completed': False,
            'current_shop_id': None,
            'thread_id': None
        })

@app.route('/api/products/count', methods=['GET'])
def get_products_count():
    """è·å–å•†å“æ€»æ•°"""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM products")
            count = cursor.fetchone()[0]
            return jsonify({'count': count})
    except Exception as e:
        logger.error(f"è·å–å•†å“æ•°é‡å¤±è´¥: {e}")
        return jsonify({'count': 0}), 500

@app.route('/api/debug/user_permissions', methods=['GET'])
def debug_user_permissions():
    """è°ƒè¯•ç”¨æˆ·æƒé™å’Œå•†å“åˆ†é…ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    if not require_admin():
        return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403

    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()

            # è·å–æ‰€æœ‰ç”¨æˆ·
            cursor.execute('SELECT id, username, role FROM users')
            users = []
            for row in cursor.fetchall():
                user_dict = dict(row)
                user_dict['shops'] = db.get_user_shops(user_dict['id'])
                users.append(user_dict)

            # è·å–æ‰€æœ‰åº—é“º
            cursor.execute('SELECT id, name FROM shops')
            shops = [dict(row) for row in cursor.fetchall()]

            # è·å–å•†å“ç»Ÿè®¡
            cursor.execute('SELECT shop_name, COUNT(*) as count FROM products GROUP BY shop_name')
            product_stats = [dict(row) for row in cursor.fetchall()]

            # è·å–ç”¨æˆ·åº—é“ºæƒé™ç»Ÿè®¡
            cursor.execute('SELECT user_id, COUNT(*) as shop_count FROM user_shop_permissions GROUP BY user_id')
            permission_stats = []
            for row in cursor.fetchall():
                user_id, shop_count = row
                user = next((u for u in users if u['id'] == user_id), None)
                if user:
                    permission_stats.append({
                        'username': user['username'],
                        'shop_count': shop_count,
                        'shops': user['shops']
                    })

            return jsonify({
                'users': users,
                'shops': shops,
                'product_stats': product_stats,
                'permission_stats': permission_stats
            })
    except Exception as e:
        logger.error(f"è°ƒè¯•ç”¨æˆ·æƒé™å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

def run_shop_scrape_task(shop_id):
    """åå°ä»»åŠ¡åŒ…è£…å™¨ - è°ƒç”¨çœŸæ­£çš„æŠ“å–é€»è¾‘"""
    try:
        logger.info(f"ğŸ§µ åå°æŠ“å–çº¿ç¨‹å¯åŠ¨: {shop_id}")
        scrape_shop_products(shop_id)
    except Exception as e:
        logger.error(f"âŒ åå°æŠ“å–çº¿ç¨‹å´©æºƒ: {e}")
        db.update_scrape_status(message=f"ç³»ç»Ÿé”™è¯¯: {str(e)}")
    finally:
        # ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
        final_status = db.get_scrape_status()
        db.update_scrape_status(
            is_scraping=False,
            completed=True
        )
        if not final_status.get('stop_signal', False):
            db.update_scrape_status(message='ä»»åŠ¡ç»“æŸ')
        logger.info("ğŸ§µ åå°æŠ“å–çº¿ç¨‹ç»“æŸ")

def scrape_shop_products(shop_id):
    """æŠ“å–åº—é“ºæ‰€æœ‰å•†å“çš„å®ç° (å…¨å±€çº¿ç¨‹æ± é«˜æ€§èƒ½ç‰ˆ - æ¯ä¸ªå•†å“ä¸€ä¸ªçº¿ç¨‹)"""
    import requests
    import time
    from weidian_scraper import get_weidian_scraper
    import concurrent.futures

    # è·å–é…ç½®çš„çº¿ç¨‹æ•°
    try:
        from config import config
        max_threads = config.SCRAPE_THREADS
    except:
        max_threads = 2

    # å¯¼å…¥å…¨å±€åœæ­¢äº‹ä»¶
    global scrape_stop_event

    scraper = get_weidian_scraper()
    unique_product_tasks = {}  # ä½¿ç”¨å­—å…¸å»é‡ï¼šitem_id -> product_info
    offset = 0
    limit = 20
    page_count = 0

    # åˆå§‹åŒ–çŠ¶æ€
    db.update_scrape_status(
        is_scraping=True,
        paused=False,
        stop_signal=False,
        progress=0,
        total=0,
        processed=0,
        success=0,
        message='æ­£åœ¨åˆå§‹åŒ–...'
    )

    # è·å–åº—é“ºåç§°
    shop_info = get_shop_info_from_api(shop_id)
    shop_name = shop_info.get('shopName', f'åº—é“º {shop_id}') if shop_info else f'åº—é“º {shop_id}'

    db.update_scrape_status(message=f'æ­£åœ¨æŠ“å–åº—é“º: {shop_name}')
    logger.info(f"å¼€å§‹æ”¶é›†å•†å“åˆ—è¡¨ï¼Œåº—é“º: {shop_name}")

    # ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æ‰€æœ‰å•†å“ä¿¡æ¯ï¼ˆå•çº¿ç¨‹ï¼Œé¿å…APIå‹åŠ›ï¼‰
    while True:
        # æ£€æŸ¥åœæ­¢äº‹ä»¶æˆ–åœæ­¢ä¿¡å·
        if scrape_stop_event.is_set():
            logger.info("ğŸ”´ åœæ­¢äº‹ä»¶è§¦å‘ï¼Œé€€å‡ºæ”¶é›†")
            break

        current_status = db.get_scrape_status()
        if current_status.get('stop_signal', False):
            logger.info("ğŸ”´ åœæ­¢ä¿¡å·è§¦å‘ï¼Œé€€å‡ºæ”¶é›†")
            break

        try:
            # API è¯·æ±‚å•†å“åˆ—è¡¨
            url = f"https://thor.weidian.com/decorate/shopDetail.tab.getItemList/1.0"
            param_encoded = quote(f'{{"shopId":"{shop_id}","tabId":0,"sortOrder":"desc","offset":{offset},"limit":{limit},"from":"h5","showItemTag":true}}')
            full_url = f"{url}?param={param_encoded}&wdtoken=8ea9315c&_={int(time.time()*1000)}"

            response = scraper.session.get(full_url, timeout=10)
            if response.status_code != 200:
                logger.warning(f'APIè¯·æ±‚å¤±è´¥: {response.status_code}')
                break

            data = response.json()
            if data.get('status', {}).get('code') != 0:
                logger.warning('APIå“åº”çŠ¶æ€ç ä¸ä¸º0')
                break

            result = data.get('result', {})
            if not result.get('hasData', False):
                logger.info('æ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œæ”¶é›†å®Œæˆ')
                break

            items = result.get('itemList', [])
            if not items:
                logger.info('å•†å“åˆ—è¡¨ä¸ºç©ºï¼Œæ”¶é›†å®Œæˆ')
                break

            # æ”¶é›†å½“å‰é¡µçš„å•†å“ä»»åŠ¡ (å†…å­˜å»é‡)
            page_new_count = 0
            for item in items:
                item_id = item.get('itemId', '')
                if item_id and item_id not in unique_product_tasks:  # å†…å­˜å»é‡
                    # å†æ¬¡æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨ (é¿å…å¤„ç†å·²æŠ“è¿‡çš„)
                    if not db.get_product_by_item_id(item_id):
                        product_info = {
                            'item_id': item_id,
                            'item_url': item.get('itemUrl', ''),
                            'shop_name': shop_name
                        }
                        unique_product_tasks[item_id] = product_info
                        page_new_count += 1

            # === æ–°å¢ï¼šå®æ—¶æ›´æ–°æ”¶é›†è¿›åº¦åˆ°æ•°æ®åº“ï¼Œè®©å‰ç«¯èƒ½çœ‹åˆ° ===
            current_total = len(unique_product_tasks)
            db.update_scrape_status(
                total=current_total,
                message=f'æ­£åœ¨æ”¶é›†å•†å“... ç¬¬{page_count + 1}é¡µï¼Œå·²æ‰¾åˆ° {current_total} ä¸ªæ–°å•†å“'
            )
            # =================================================

            logger.info(f'ç¬¬ {page_count + 1} é¡µæ”¶é›†äº† {len(items)} ä¸ªå•†å“ï¼Œå…¶ä¸­ {page_new_count} ä¸ªæ–°å•†å“ï¼Œæ€»è®¡ {len(unique_product_tasks)} ä¸ªå¾…å¤„ç†å•†å“')

            page_count += 1
            offset += limit
            time.sleep(0.5)  # ç¨å¾®æ­‡ä¸€ä¸‹é˜²æ­¢å°IP

        except Exception as e:
            logger.error(f'æ”¶é›†å•†å“åˆ—è¡¨å‡ºé”™: {e}')
            break

    # è½¬å›åˆ—è¡¨ç”¨äºå¤„ç†
    all_product_tasks = list(unique_product_tasks.values())
    total_products = len(all_product_tasks)
    logger.info(f"âœ… å•†å“æ”¶é›†å®Œæˆï¼Œå»é‡åå¾…å¤„ç† {total_products} ä¸ªå•†å“ï¼Œå‡†å¤‡ä½¿ç”¨ {max_threads} ä¸ªçº¿ç¨‹å¹¶å‘å¤„ç†")

    # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹å¤„ç†
    db.update_scrape_status(
        total=total_products,
        progress=0, # é‡ç½®è¿›åº¦æ¡ä¸º0ï¼Œå¼€å§‹ç¬¬äºŒé˜¶æ®µ
        message=f'æ”¶é›†å®Œæˆï¼Œå‡†å¤‡å¹¶å‘å¤„ç† {total_products} ä¸ªå•†å“...'
    )

    # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨å…¨å±€çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰€æœ‰å•†å“
    processed_count = 0
    success_count = 0

    if all_product_tasks:
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
            # æäº¤æ‰€æœ‰å•†å“ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            future_to_product = {
                executor.submit(process_and_save_single_product_sync, product_info): product_info
                for product_info in all_product_tasks
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in concurrent.futures.as_completed(future_to_product):
                # æ£€æŸ¥åœæ­¢äº‹ä»¶æˆ–åœæ­¢ä¿¡å·
                if scrape_stop_event.is_set() or db.get_scrape_status().get('stop_signal', False):
                    logger.info("ğŸ”´ æ£€æµ‹åˆ°åœæ­¢äº‹ä»¶/ä¿¡å·ï¼Œæ­£åœ¨å–æ¶ˆå‰©ä½™ä»»åŠ¡...")
                    # å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
                    for f in future_to_product:
                        if not f.done():
                            f.cancel()
                    break

                try:
                    product_info = future_to_product[future]
                    success = future.result()
                    processed_count += 1

                    if success:
                        success_count += 1

                    # æ”¹ä¸ºæ¯5ä¸ªæ›´æ–°ä¸€æ¬¡ï¼Œåé¦ˆæ›´åŠæ—¶
                    if processed_count % 5 == 0 or processed_count == total_products:
                        # è®¡ç®—è¿›åº¦ (é¿å…é™¤ä»¥0)
                        progress = int((processed_count / total_products) * 100) if total_products > 0 else 100
                        db.update_scrape_status(
                            processed=processed_count,
                            success=success_count,
                            progress=progress,
                            message=f'æ­£åœ¨æŠ“å–è¯¦æƒ…ä¸å›¾ç‰‡... ({processed_count}/{total_products})'
                        )
                        logger.info(f'å·²å¤„ç† {processed_count}/{total_products} ä¸ªå•†å“ï¼ŒæˆåŠŸ {success_count} ä¸ª')

                except Exception as e:
                    logger.error(f"å•†å“å¤„ç†å¼‚å¸¸: {e}")
                    processed_count += 1

    # ç»“æŸ
    db.update_scrape_status(
        is_scraping=False,
        completed=True,
        progress=100,
        message=f'æŠ“å–å®Œæˆï¼Œå…±å¤„ç† {processed_count} ä¸ªå•†å“ï¼ŒæˆåŠŸ {success_count} ä¸ª'
    )
    logger.info(f"âœ… åº—é“º {shop_id} æŠ“å–ä»»åŠ¡å®Œæˆ: {success_count}/{processed_count} å•†å“æˆåŠŸå¤„ç†")

    return {
        "total_products": processed_count,
        "success_count": success_count,
        "pages_processed": page_count
    }

def process_and_save_single_product_sync(product_info):
    """åŒæ­¥å¤„ç†å•ä¸ªå•†å“ï¼Œé¿å…é‡å¤å¤„ç†"""
    try:
        item_id = product_info.get('item_id', '')

        # === æ£€æŸ¥åœæ­¢äº‹ä»¶æˆ–åœæ­¢ä¿¡å· ===
        global scrape_stop_event
        if scrape_stop_event.is_set():
            logger.info(f"ğŸ”´ å¤„ç†å•†å“å‰æ£€æµ‹åˆ°åœæ­¢äº‹ä»¶ï¼Œå–æ¶ˆå¤„ç†å•†å“ {item_id}")
            return False

        current_status = db.get_scrape_status()
        if current_status.get('stop_signal', False):
            logger.info(f"ğŸ”´ å¤„ç†å•†å“å‰æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå¤„ç†å•†å“ {item_id}")
            return False

        # === 0. åŸºäºitem_idçš„å¼ºåŠ›å»é‡ ===
        if db.get_product_by_item_id(item_id):
            logger.info(f"â­ï¸ å•†å“ {item_id} å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤å¤„ç†")
            return True  # å·²å­˜åœ¨ç®—å¤„ç†æˆåŠŸ

        # 1. æŠ“å–è¯¦æƒ…
        from app import process_single_product  # å¼•ç”¨ app.py ä¸­çš„é€»è¾‘
        product_data = process_single_product(product_info)

        if not product_data:
            return False

        # === å†æ¬¡æ£€æŸ¥åœæ­¢çŠ¶æ€ ===
        current_status = db.get_scrape_status()
        if current_status.get('stop_signal', False):
            logger.info(f"ğŸ”´ æŠ“å–è¯¦æƒ…åæ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå¤„ç†å•†å“ {item_id}")
            return False

        # 2. å†æ¬¡æŸ¥é‡ (åŒé‡ä¿é™©)
        if db.get_product_by_url(product_data['product_url']):
            logger.info(f"â­ï¸ å•†å“URLå·²å­˜åœ¨: {product_data['product_url']}")
            return True  # å·²å­˜åœ¨ç®—å¤„ç†æˆåŠŸ

        # 3. å…¥åº“ (æ·»åŠ item_idå­—æ®µ)
        product_data['item_id'] = item_id  # ç¡®ä¿item_idè¢«ä¿å­˜
        product_id = db.insert_product(product_data)

        logger.info(f"âœ… å•†å“ {item_id} æˆåŠŸå…¥åº“ï¼Œæ•°æ®åº“ID: {product_id}")

        # === å†æ¬¡æ£€æŸ¥åœæ­¢çŠ¶æ€ ===
        current_status = db.get_scrape_status()
        if current_status.get('stop_signal', False):
            logger.info(f"ğŸ”´ å…¥åº“åæ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå•†å“ {item_id} å·²å…¥åº“ä½†è·³è¿‡å›¾ç‰‡å¤„ç†")
            return True  # å•†å“å·²å…¥åº“ï¼Œç®—æˆåŠŸ

        # 4. å›¾ç‰‡å¤„ç† (ä½¿ç”¨å¤šçº¿ç¨‹ç‰ˆæœ¬)
        if product_data.get('images'):
            from app import save_product_images_unified
            processed_count = save_product_images_unified(product_id, product_data['images'])
            logger.info(f"ğŸ–¼ï¸ å•†å“ {item_id} å›¾ç‰‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {processed_count} å¼ å›¾ç‰‡")

        return True
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å•†å“å‡ºé”™ {product_info.get('item_id')}: {e}")
        return False

def scrape_product_info(product_url):
    """æ ¹æ®å•†å“URLè·å–å•†å“è¯¦ç»†ä¿¡æ¯"""
    try:
        from weidian_scraper import get_weidian_scraper

        scraper = get_weidian_scraper()
        product_info = scraper.scrape_product_info(product_url)

        if product_info:
            # é‡æ–°æ ¼å¼åŒ–è¿”å›æ•°æ®
            return {
                'title': product_info.get('title', ''),
                'description': product_info.get('description', ''),
                # ä¿®å¤ï¼šç§»é™¤ [:5] é™åˆ¶ï¼Œè¿”å›æ‰€æœ‰æŠ“å–åˆ°çš„å›¾ç‰‡
                'images': product_info.get('images', []),
                'shop_name': product_info.get('shop_name', '')
            }

        return None

    except Exception as e:
        logger.error(f'è·å–å•†å“è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}')
        return None

def generate_acbuy_url(weidian_url):
    """ç”ŸæˆAcBuyé“¾æ¥"""
    if not weidian_url:
        return ''

    try:
        import re
        item_id_match = re.search(r'itemID=(\d+)', weidian_url)
        if item_id_match:
            item_id = item_id_match.group(1)
            # æ„å»ºacbuyé“¾æ¥
            encoded_url = weidian_url.replace(':', '%3A').replace('/', '%2F').replace('?', '%3F').replace('=', '%3D').replace('&', '%26')
            return f'https://www.acbuy.com/product?url={encoded_url}&id={item_id}&source=WD'
    except Exception as e:
        logger.error(f'ç”ŸæˆAcBuyé“¾æ¥å¤±è´¥: {e}')

    return ''

def generate_cnfans_url(item_id):
    """ç”ŸæˆCNFansé“¾æ¥"""
    if not item_id:
        return ''
    return f"https://cnfans.com/product?id={item_id}&platform=WEIDIAN"

def generate_english_title(chinese_title):
    """å°†ä¸­æ–‡æ ‡é¢˜ç¿»è¯‘ä¸ºè‹±æ–‡æ ‡é¢˜"""
    if not chinese_title:
        return ''

    try:
        import re
        import requests

        # é¦–å…ˆå°è¯•æå–å·²æœ‰çš„è‹±æ–‡éƒ¨åˆ†
        english_parts = re.findall(r'[a-zA-Z\s]+', chinese_title)
        if english_parts and len(' '.join(english_parts).strip()) > 5:
            # å¦‚æœè‹±æ–‡éƒ¨åˆ†è¶³å¤Ÿé•¿ï¼Œç›´æ¥è¿”å›
            return ' '.join(english_parts).strip()

        # å“ç‰Œåç§°æ˜ å°„ï¼ˆæ‰©å±•ç‰ˆï¼‰
        brand_mappings = {
            'Nike': 'Nike', 'é˜¿è¿ª': 'Adidas', 'Adidas': 'Adidas', 'æå®': 'LiNing',
            'å®‰è¸': 'Anta', 'åŒ¹å…‹': 'Peak', 'ä¹”ä¸¹': 'Jordan', 'New Balance': 'New Balance',
            'Converse': 'Converse', 'Vans': 'Vans', 'Supreme': 'Supreme', 'BAPE': 'BAPE',
            'Palace': 'Palace', 'Stone Island': 'Stone Island', 'Off-White': 'Off-White',
            'Balenciaga': 'Balenciaga', 'Gucci': 'Gucci', 'Louis Vuitton': 'Louis Vuitton',
            'Chanel': 'Chanel', 'Dior': 'Dior', 'Yeezy': 'Yeezy', 'Puma': 'Puma',
            'Reebok': 'Reebok', 'Under Armour': 'Under Armour', 'Fila': 'Fila',
            'The North Face': 'The North Face', 'Columbia': 'Columbia', 'Patagonia': 'Patagonia',
            'Arc\'teryx': 'Arc\'teryx', 'Canada Goose': 'Canada Goose', 'Moncler': 'Moncler',
            'Burberry': 'Burberry', 'Prada': 'Prada', 'Versace': 'Versace', 'Fendi': 'Fendi',
            'Hermes': 'Hermes', 'Rolex': 'Rolex', 'Cartier': 'Cartier', 'Omega': 'Omega',
            'IWC': 'IWC', 'Jaeger-LeCoultre': 'Jaeger-LeCoultre', 'Patek Philippe': 'Patek Philippe'
        }

        # åº”ç”¨å“ç‰Œæ˜ å°„
        title = chinese_title
        for zh, en in brand_mappings.items():
            title = title.replace(zh, en)

        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸­æ–‡å­—ç¬¦
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in title)

        if has_chinese:
            # ä½¿ç”¨ç™¾åº¦ç¿»è¯‘APIæˆ–å…¶ä»–å…è´¹ç¿»è¯‘æœåŠ¡
            try:
                # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„ç¿»è¯‘APIç¤ºä¾‹
                # å®é™…éƒ¨ç½²æ—¶éœ€è¦æ›¿æ¢ä¸ºç¨³å®šçš„ç¿»è¯‘æœåŠ¡
                api_url = "https://api.mymemory.translated.net/get"
                params = {
                    'q': chinese_title,
                    'langpair': 'zh-CN|en-US',
                    'de': 'your-email@example.com'  # MyMemoryè¦æ±‚æä¾›é‚®ç®±
                }

                response = requests.get(api_url, params=params, timeout=5, proxies={'http': None, 'https': None})
                if response.status_code == 200:
                    data = response.json()
                    translated = data.get('responseData', {}).get('translatedText', '')
                    if translated and translated != chinese_title:
                        # æ¸…ç†ç¿»è¯‘ç»“æœ
                        translated = re.sub(r'[^\w\s\-]', '', translated)
                        return translated.strip()

            except Exception as e:
                logger.warning(f'åœ¨çº¿ç¿»è¯‘å¤±è´¥: {e}')

            # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œè¿”å›æå–çš„è‹±æ–‡éƒ¨åˆ†æˆ–åŸæ ‡é¢˜
            english_parts = re.findall(r'[a-zA-Z\s\-]+', title)
            if english_parts:
                result = ' '.join(english_parts).strip()
                if len(result) > 3:
                    return result

        # å¦‚æœæ²¡æœ‰ä¸­æ–‡æˆ–ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›å¤„ç†åçš„æ ‡é¢˜
        return re.sub(r'[^\w\s\-]', '', title).strip()

    except Exception as e:
        logger.error(f'ç”Ÿæˆè‹±æ–‡æ ‡é¢˜å¤±è´¥: {e}')
        return chinese_title

def process_single_product(product_info):
    """å¤„ç†å•ä¸ªå•†å“çš„è¯¦æƒ…æŠ“å–"""
    try:
        item_id = product_info['item_id']
        item_url = product_info['item_url']
        shop_name = product_info['shop_name']

        # æ£€æŸ¥åœæ­¢äº‹ä»¶
        global scrape_stop_event
        if scrape_stop_event.is_set():
            logger.info(f"ğŸ”´ å¤„ç†å•†å“ {item_id} æ—¶æ£€æµ‹åˆ°åœæ­¢äº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†")
            return None

        # è·å–å•†å“è¯¦ç»†ä¿¡æ¯
        product_details = scrape_product_info(item_url)

        if product_details:
            # ç”Ÿæˆè‹±æ–‡æ ‡é¢˜
            english_title = generate_english_title(product_details.get('title', ''))

            return {
                'product_url': item_url,
                'title': product_details.get('title', ''),
                'description': product_details.get('description', ''),
                'english_title': english_title,
                'cnfans_url': generate_cnfans_url(item_id),
                'acbuy_url': generate_acbuy_url(item_url),
                'shop_name': shop_name,
                'images': product_details.get('images', []),
                'ruleEnabled': True
            }
        return None

    except Exception as e:
        logger.error(f'å¤„ç†å•†å“å¤±è´¥: {e}')
        return None

def process_products_multithreaded(products_list):
    """å¤šçº¿ç¨‹å¤„ç†å•†å“è¯¦æƒ…æŠ“å–"""
    import concurrent.futures

    processed_products = []

    # è·å–é…ç½®çš„çº¿ç¨‹æ•°
    max_workers = config.DOWNLOAD_THREADS

    logger.info(f'å¼€å§‹å¤šçº¿ç¨‹å¤„ç† {len(products_list)} ä¸ªå•†å“ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹')

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_product = {
            executor.submit(process_single_product, product): product
            for product in products_list
        }

        # æ”¶é›†ç»“æœ
        for future in concurrent.futures.as_completed(future_to_product):
            try:
                result = future.result()
                if result:
                    processed_products.append(result)
            except Exception as e:
                logger.error(f'å•†å“å¤„ç†ä»»åŠ¡å¤±è´¥: {e}')

    logger.info(f'å¤šçº¿ç¨‹å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(processed_products)} ä¸ªå•†å“')
    return processed_products

def process_page_multithreaded(products_list, page_num):
    """
    å¤šçº¿ç¨‹å¤„ç†æ•´ä¸ªé¡µé¢ï¼šè·å–è¯¦æƒ… + æ’å…¥æ•°æ®åº“ + ä¸‹è½½å›¾ç‰‡
    æ¯ä¸ªçº¿ç¨‹è´Ÿè´£ä¸€ä¸ªå•†å“çš„å®Œæ•´å¤„ç†æµç¨‹
    """
    import concurrent.futures

    processed_count = 0

    # è·å–é…ç½®çš„çº¿ç¨‹æ•°
    max_workers = config.DOWNLOAD_THREADS

    logger.info(f'ç¬¬ {page_num} é¡µå¼€å§‹å¤šçº¿ç¨‹å¤„ç† {len(products_list)} ä¸ªå•†å“')

    def process_and_save_product(product):
        """å¤„ç†å•ä¸ªå•†å“çš„å®Œæ•´æµç¨‹ï¼šè·å–è¯¦æƒ… -> æ’å…¥æ•°æ®åº“ -> ä¸‹è½½å›¾ç‰‡"""
        try:
            # 1. è·å–å•†å“è¯¦æƒ…
            product_data = process_single_product(product)
            if not product_data:
                logger.warning(f'å•†å“è¯¦æƒ…è·å–å¤±è´¥: {product}')
                return 0

            # 2. æ£€æŸ¥å•†å“æ˜¯å¦å·²å­˜åœ¨
            existing = db.get_product_by_url(product_data['product_url'])
            if existing:
                logger.info(f'å•†å“å·²å­˜åœ¨ï¼Œè·³è¿‡: {product_data["title"]} (URL: {product_data["product_url"]})')
                return 0

            # 3. æ’å…¥å•†å“åˆ°æ•°æ®åº“
            product_id = db.insert_product(product_data)
            logger.info(f'âœ… æˆåŠŸæ’å…¥æ–°å•†å“: {product_data["title"]} (ID: {product_id})')

            # 4. ä¸‹è½½å¹¶ä¿å­˜å›¾ç‰‡
            if product_data.get('images'):
                save_product_images(product_id, product_data['images'])
                logger.info(f'ğŸ“¸ å•†å“å›¾ç‰‡ä¸‹è½½å®Œæˆ: {product_data["title"]} ({len(product_data["images"])}å¼ )')

            return 1  # æˆåŠŸå¤„ç†ä¸€ä¸ªå•†å“

        except Exception as e:
            logger.error(f'å¤„ç†å•†å“å¤±è´¥: {e}')
            return 0

    # é™ä½å¹¶å‘æ•°é¿å…å†…å­˜çˆ†ç‚¸ï¼ŒYOLOæ¨¡å‹ç°åœ¨æ˜¯å•ä¾‹æ¨¡å¼
    max_workers_page = min(2, len(products_list))  # æœ€å¤š2ä¸ªå¹¶å‘
    logger.info(f"é¡µé¢å¤„ç†ä½¿ç”¨ {max_workers_page} ä¸ªçº¿ç¨‹")

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers_page) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼Œæ¯ä¸ªå•†å“ä¸€ä¸ªä»»åŠ¡
        future_to_product = {
            executor.submit(process_and_save_product, product): product
            for product in products_list
        }

        # æ”¶é›†ç»“æœ
        for future in concurrent.futures.as_completed(future_to_product):
            try:
                result = future.result()
                processed_count += result
            except Exception as e:
                logger.error(f'é¡µé¢å¤„ç†ä»»åŠ¡å¤±è´¥: {e}')

    logger.info(f'ç¬¬ {page_num} é¡µå¤„ç†å®Œæˆï¼ŒæˆåŠŸæ–°å¢ {processed_count} ä¸ªå•†å“')
    return processed_count

def save_product_images(product_id, image_urls):
    """
    ç»Ÿä¸€çš„å›¾ç‰‡ä¿å­˜å…¥å£ï¼ˆå‘åå…¼å®¹çš„åˆ«åï¼‰
    å®é™…è°ƒç”¨ save_product_images_unified
    """
    return save_product_images_unified(product_id, image_urls)

def save_product_images_unified(product_id, image_urls, max_workers=None, shutdown_event=None):
    """
    ç»Ÿä¸€çš„æ‰¹é‡å›¾ç‰‡å¤„ç†å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼šå»¶è¿ŸFAISSä¿å­˜ï¼Œæé«˜æ€§èƒ½ï¼‰
    """
    if not image_urls:
        return 0

    try:
        import concurrent.futures

        # åŠ¨æ€å†³å®šçº¿ç¨‹æ•° (é»˜è®¤ä½¿ç”¨é…ç½®ï¼Œä½†å…è®¸è¦†ç›–)
        if max_workers is None:
            max_workers = min(config.DOWNLOAD_THREADS, len(image_urls))

        # è·å–ç°æœ‰ç‰¹å¾å‘é‡ç”¨äºæŸ¥é‡
        existing_images = db.get_product_images(product_id)
        existing_feats = [img['features'] for img in existing_images if img['features']]
        logger.info(f'å•†å“ {product_id} å·²å­˜åœ¨ {len(existing_feats)} å¼ å›¾ç‰‡çš„å‘é‡æ•°æ®')

        # å¤„ç†ç»“æœè®¡æ•°
        processed_images = 0

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡ï¼šæ³¨æ„è¿™é‡Œ save_faiss_immediately=Falseï¼Œå› ä¸ºæˆ‘ä»¬è¦æ‰¹é‡ä¿å­˜
            futures = [executor.submit(process_and_save_image_core, product_id, url, idx, existing_feats, save_faiss_immediately=False)
                       for idx, url in enumerate(image_urls)]

            # ç­‰å¾…å®Œæˆ (æ”¯æŒä¼˜é›…å…³é—­)
            for future in concurrent.futures.as_completed(futures):
                try:
                    # æ£€æŸ¥åœæ­¢ä¿¡å·
                    if shutdown_event and shutdown_event.is_set():
                        logger.info("æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ç­‰å¾…å›¾ç‰‡å¤„ç†å®Œæˆ...")
                        executor.shutdown(wait=True, timeout=15.0)
                        break

                    result = future.result()
                    if result and result.get('success'):
                        processed_images += 1  # è®¡æ•°æˆåŠŸå¤„ç†çš„å›¾ç‰‡

                except Exception as e:
                    logger.error(f'ä¸€ä¸ªå›¾ç‰‡å¤„ç†å¤±è´¥: {e}')

        # æ‰¹é‡æ“ä½œç»“æŸåç»Ÿä¸€ä¿å­˜ FAISSï¼ˆæ€§èƒ½æå¤§æå‡ï¼‰
        if processed_images > 0:
            try:
                from vector_engine import get_vector_engine
                get_vector_engine().save()
                logger.info(f"FAISSç´¢å¼•å·²æ‰¹é‡ä¿å­˜ï¼Œæœ¬æ¬¡æ–°å¢ {processed_images} å¼ å›¾ç‰‡")

            except Exception as faiss_err:
                logger.error(f"FAISSä¿å­˜å¤±è´¥: {faiss_err}")

        logger.info(f"å•†å“ {product_id} æˆåŠŸå¤„ç† {processed_images}/{len(image_urls)} å¼ å›¾ç‰‡")
        return processed_images

    except Exception as e:
        logger.error(f"æ‰¹é‡ä¿å­˜å•†å“ {product_id} å›¾ç‰‡å¤±è´¥: {e}")
        return 0

def save_product_images_multithreaded(product_id, image_urls):
    """å‘åå…¼å®¹çš„åˆ«å"""
    return save_product_images_unified(product_id, image_urls)

if __name__ == '__main__':
    import atexit
    import threading
    import signal
    import time

    # å…¨å±€å˜é‡ç”¨äºæ§åˆ¶ä¼˜é›…å…³é—­
    shutdown_event = threading.Event()

    def signal_handler(signum, frame):
        """å¤„ç†ä¸­æ–­ä¿¡å·ï¼Œä¼˜é›…å…³é—­"""
        print(f"\nğŸ›‘ Received signal {signum}, initiating graceful shutdown...")
        shutdown_event.set()

        # è®¾ç½®æŠ“å–çŠ¶æ€ä¸ºåœæ­¢
        current_status = db.get_scrape_status()
        if current_status.get('is_scraping', False):
            db.update_scrape_status(
                stop_signal=True,
                message='ç³»ç»Ÿæ­£åœ¨å…³é—­ï¼Œå·²åœæ­¢æŠ“å–ä»»åŠ¡'
            )
            print("â¹ï¸  å·²åœæ­¢æ‰€æœ‰æŠ“å–ä»»åŠ¡")

        # ç­‰å¾…æŠ“å–çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤šç­‰å¾…10ç§’ï¼‰
        global current_scrape_thread, scrape_thread_lock
        with scrape_thread_lock:
            if current_scrape_thread and current_scrape_thread.is_alive():
                print("â³ ç­‰å¾…æŠ“å–çº¿ç¨‹ç»“æŸ...")
                current_scrape_thread.join(timeout=10.0)
                if current_scrape_thread.is_alive():
                    print("âš ï¸ æŠ“å–çº¿ç¨‹æœªèƒ½åœ¨10ç§’å†…ç»“æŸ")
                else:
                    print("âœ… æŠ“å–çº¿ç¨‹å·²ç»“æŸ")

        # ç«‹å³åœæ­¢Discordæœºå™¨äºº
        stop_discord_bot()

        # çŸ­æš‚ç­‰å¾…è®©å…¶ä»–çº¿ç¨‹æœ‰æœºä¼šæ¸…ç†
        time.sleep(0.2)
        print("ğŸ’¥ Force exiting...")
        import os
        os._exit(0)

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # æ³¨å†Œé€€å‡ºæ—¶åœæ­¢æœºå™¨äººçš„å‡½æ•°
    atexit.register(stop_discord_bot)

    # ====================================================
    # æ–°å¢ä¿®å¤ï¼šå¯åŠ¨æ—¶å¼ºåˆ¶é‡ç½®æ•°æ®åº“æŠ“å–çŠ¶æ€
    # ====================================================
    print("ğŸ§¹ [ç³»ç»Ÿ] æ­£åœ¨é‡ç½®æŠ“å–ä»»åŠ¡çŠ¶æ€...")
    try:
        # å¼ºåˆ¶å°†æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„çŠ¶æ€é‡ç½®ä¸ºåœæ­¢
        db.update_scrape_status(
            is_scraping=False,
            stop_signal=False,
            message='ç³»ç»Ÿé‡å¯ï¼Œä»»åŠ¡çŠ¶æ€å·²é‡ç½®'
        )
        print("âœ… [ç³»ç»Ÿ] æŠ“å–çŠ¶æ€å·²é‡ç½®ï¼Œéšæ—¶å¯ä»¥å¼€å§‹æ–°ä»»åŠ¡")
    except Exception as e:
        print(f"âš ï¸ [ç³»ç»Ÿ] çŠ¶æ€é‡ç½®å¤±è´¥ (å¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œæ•°æ®åº“æœªåˆå§‹åŒ–): {e}")

    # 3. åœ¨ä¸»çº¿ç¨‹é¢„åŠ è½½æ¨¡å‹ (å…³é”®)
    print("ğŸ¤– [ç³»ç»Ÿ] æ­£åœ¨é¢„çƒ­ AI å¼•æ“ï¼Œè¯·ç¨å€™...")
    try:
        from feature_extractor import get_feature_extractor
        # å¼ºåˆ¶è·å–ä¸€æ¬¡å®ä¾‹ï¼Œè§¦å‘åˆå§‹åŒ–
        get_feature_extractor()
        print("âœ… [ç³»ç»Ÿ] AI å¼•æ“é¢„çƒ­å®Œæˆï¼Œå¤šçº¿ç¨‹ä»»åŠ¡å°†å…±äº«æ­¤å®ä¾‹")
    except Exception as e:
        print(f"âš ï¸ [ç³»ç»Ÿ] AI é¢„çƒ­å¤±è´¥: {e}")

    # 4. å¯åŠ¨ Flask
    print("ğŸš€ æœåŠ¡å¯åŠ¨ä¸­...")
    try:
        # å…³é—­ debug æ¨¡å¼ï¼Œé¿å… Flask é‡è½½å™¨å¯¼è‡´åŒé‡åˆå§‹åŒ–
        app.run(host='0.0.0.0', port=5001, debug=False, threaded=True)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Received KeyboardInterrupt, shutting down...")
        signal_handler(signal.SIGINT, None)
    except Exception as e:
        print(f"\nğŸ’¥ Unexpected error: {e}")
        signal_handler(signal.SIGINT, None)
    finally:
        print("ğŸ‘‹ Flask API shutdown complete")
